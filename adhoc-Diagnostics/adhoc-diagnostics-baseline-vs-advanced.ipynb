{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0484007",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T08:27:14.523957Z",
     "start_time": "2025-10-03T08:27:14.375624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ROW COUNT DISCREPANCY DEBUGGER\n",
      "================================================================================\n",
      "\n",
      "1. LOADING DATASETS\n",
      "--------------------------------------------------------------------------------\n",
      "Baseline shape: (360, 68)\n",
      "Advanced shape: (359, 68)\n",
      "Difference: 1 rows\n",
      "\n",
      "2. DATE RANGE COMPARISON\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Baseline:\n",
      "  Start: 2025-09-21 00:00:00\n",
      "  End:   2026-09-15 00:00:00\n",
      "  Days:  360\n",
      "\n",
      "Advanced:\n",
      "  Start: 2025-09-21 00:00:00\n",
      "  End:   2026-09-14 00:00:00\n",
      "  Days:  359\n",
      "\n",
      "3. IDENTIFYING MISSING DATES\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Dates in BASELINE but NOT in ADVANCED (1):\n",
      "  2026-09-15\n",
      "\n",
      "4. CHECKING FOR DUPLICATE DATES\n",
      "--------------------------------------------------------------------------------\n",
      "Baseline duplicates: 0\n",
      "Advanced duplicates: 0\n",
      "\n",
      "5. CHECKING FOR NULL DATES\n",
      "--------------------------------------------------------------------------------\n",
      "Baseline null dates: 0\n",
      "Advanced null dates: 0\n",
      "\n",
      "6. MISSING VALUES IN KEY COLUMNS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Baseline:\n",
      "date         0\n",
      "base_rate    0\n",
      "dtype: int64\n",
      "\n",
      "Advanced:\n",
      "date         0\n",
      "base_rate    0\n",
      "dtype: int64\n",
      "\n",
      "7. CHECKING SOURCE DATA (BEFORE LAG CREATION)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Could not load baseline source: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Nandan Hegde\\\\OneDrive\\\\Documents\\\\Open_Source_projects\\\\PricingService.ai\\\\Dynamic-Pricing-Model-Experiments\\\\Predictive-Models\\\\data\\\\dataprocessed\\\\competitor_price_matrix.csv'\n",
      "\n",
      "Could not load advanced source: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Nandan Hegde\\\\OneDrive\\\\Documents\\\\Open_Source_projects\\\\PricingService.ai\\\\Dynamic-Pricing-Model-Experiments\\\\Predictive-Models\\\\data\\\\dataprocessed\\\\competitor_price_matrix_advanced_imputation.csv'\n",
      "\n",
      "================================================================================\n",
      "DIAGNOSIS\n",
      "================================================================================\n",
      "\n",
      "ROOT CAUSE: Advanced imputation is missing specific dates\n",
      "LOCATION: Either in imputation or lag creation process\n",
      "ACTION: Check why these dates were dropped\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DEBUG: Row Count Discrepancy Between Baseline and Advanced Imputation\n",
    "=====================================================================\n",
    "This script identifies why the two datasets have different row counts\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ROW COUNT DISCREPANCY DEBUGGER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "data_path = Path().cwd().parent /'Predictive-Models'/ 'data' / 'dataprocessed'\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD BOTH DATASETS\n",
    "# ============================================================================\n",
    "print(\"\\n1. LOADING DATASETS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "df_baseline = pd.read_csv(data_path / 'lagged_predictive_dataset.csv')\n",
    "df_baseline['date'] = pd.to_datetime(df_baseline['date'])\n",
    "\n",
    "df_advanced = pd.read_csv(data_path / 'lagged_predictive_dataset_advanced_imputation.csv')\n",
    "df_advanced['date'] = pd.to_datetime(df_advanced['date'])\n",
    "\n",
    "print(f\"Baseline shape: {df_baseline.shape}\")\n",
    "print(f\"Advanced shape: {df_advanced.shape}\")\n",
    "print(f\"Difference: {df_baseline.shape[0] - df_advanced.shape[0]} rows\")\n",
    "\n",
    "# ============================================================================\n",
    "# COMPARE DATE RANGES\n",
    "# ============================================================================\n",
    "print(\"\\n2. DATE RANGE COMPARISON\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(f\"\\nBaseline:\")\n",
    "print(f\"  Start: {df_baseline['date'].min()}\")\n",
    "print(f\"  End:   {df_baseline['date'].max()}\")\n",
    "print(f\"  Days:  {(df_baseline['date'].max() - df_baseline['date'].min()).days + 1}\")\n",
    "\n",
    "print(f\"\\nAdvanced:\")\n",
    "print(f\"  Start: {df_advanced['date'].min()}\")\n",
    "print(f\"  End:   {df_advanced['date'].max()}\")\n",
    "print(f\"  Days:  {(df_advanced['date'].max() - df_advanced['date'].min()).days + 1}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FIND MISSING DATES\n",
    "# ============================================================================\n",
    "print(\"\\n3. IDENTIFYING MISSING DATES\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "baseline_dates = set(df_baseline['date'])\n",
    "advanced_dates = set(df_advanced['date'])\n",
    "\n",
    "dates_only_in_baseline = baseline_dates - advanced_dates\n",
    "dates_only_in_advanced = advanced_dates - baseline_dates\n",
    "\n",
    "if dates_only_in_baseline:\n",
    "    print(f\"\\nDates in BASELINE but NOT in ADVANCED ({len(dates_only_in_baseline)}):\")\n",
    "    for date in sorted(dates_only_in_baseline):\n",
    "        print(f\"  {date.date()}\")\n",
    "        \n",
    "if dates_only_in_advanced:\n",
    "    print(f\"\\nDates in ADVANCED but NOT in BASELINE ({len(dates_only_in_advanced)}):\")\n",
    "    for date in sorted(dates_only_in_advanced):\n",
    "        print(f\"  {date.date()}\")\n",
    "\n",
    "if not dates_only_in_baseline and not dates_only_in_advanced:\n",
    "    print(\"\\nBoth datasets have the same dates!\")\n",
    "    print(\"Issue must be in how rows are counted/filtered\")\n",
    "\n",
    "# ============================================================================\n",
    "# CHECK FOR DUPLICATES\n",
    "# ============================================================================\n",
    "print(\"\\n4. CHECKING FOR DUPLICATE DATES\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "baseline_dupes = df_baseline['date'].duplicated().sum()\n",
    "advanced_dupes = df_advanced['date'].duplicated().sum()\n",
    "\n",
    "print(f\"Baseline duplicates: {baseline_dupes}\")\n",
    "print(f\"Advanced duplicates: {advanced_dupes}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CHECK FOR NULL VALUES IN DATE COLUMN\n",
    "# ============================================================================\n",
    "print(\"\\n5. CHECKING FOR NULL DATES\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "baseline_null_dates = df_baseline['date'].isnull().sum()\n",
    "advanced_null_dates = df_advanced['date'].isnull().sum()\n",
    "\n",
    "print(f\"Baseline null dates: {baseline_null_dates}\")\n",
    "print(f\"Advanced null dates: {advanced_null_dates}\")\n",
    "\n",
    "# ============================================================================\n",
    "# COMPARE MISSING VALUES IN KEY COLUMNS\n",
    "# ============================================================================\n",
    "print(\"\\n6. MISSING VALUES IN KEY COLUMNS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(\"\\nBaseline:\")\n",
    "print(df_baseline[['date', 'base_rate']].isnull().sum())\n",
    "\n",
    "print(\"\\nAdvanced:\")\n",
    "print(df_advanced[['date', 'base_rate']].isnull().sum())\n",
    "\n",
    "# ============================================================================\n",
    "# CHECK SOURCE DATA (BEFORE LAG CREATION)\n",
    "# ============================================================================\n",
    "print(\"\\n7. CHECKING SOURCE DATA (BEFORE LAG CREATION)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Load the price matrices that were used as input\n",
    "try:\n",
    "    matrix_baseline = pd.read_csv(data_path / 'competitor_price_matrix.csv')\n",
    "    matrix_baseline['date'] = pd.to_datetime(matrix_baseline['date'])\n",
    "    print(f\"\\nBaseline source (competitor_price_matrix.csv): {matrix_baseline.shape}\")\n",
    "    print(f\"  Date range: {matrix_baseline['date'].min()} to {matrix_baseline['date'].max()}\")\n",
    "    print(f\"  Total days: {len(matrix_baseline)}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nCould not load baseline source: {e}\")\n",
    "\n",
    "try:\n",
    "    matrix_advanced = pd.read_csv(data_path / 'competitor_price_matrix_advanced_imputation.csv')\n",
    "    matrix_advanced['date'] = pd.to_datetime(matrix_advanced['date'])\n",
    "    print(f\"\\nAdvanced source (competitor_price_matrix_advanced_imputation.csv): {matrix_advanced.shape}\")\n",
    "    print(f\"  Date range: {matrix_advanced['date'].min()} to {matrix_advanced['date'].max()}\")\n",
    "    print(f\"  Total days: {len(matrix_advanced)}\")\n",
    "    \n",
    "    # Compare source data\n",
    "    if 'matrix_baseline' in locals():\n",
    "        source_baseline_dates = set(matrix_baseline['date'])\n",
    "        source_advanced_dates = set(matrix_advanced['date'])\n",
    "        \n",
    "        source_diff = source_baseline_dates - source_advanced_dates\n",
    "        if source_diff:\n",
    "            print(f\"\\nDates in baseline source but NOT in advanced source:\")\n",
    "            for date in sorted(source_diff):\n",
    "                print(f\"  {date.date()}\")\n",
    "        else:\n",
    "            print(\"\\nBoth source matrices have identical dates\")\n",
    "            print(\"Row count difference happens during LAG CREATION process\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"\\nCould not load advanced source: {e}\")\n",
    "\n",
    "# ============================================================================\n",
    "# TRACE THE PROBLEM\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DIAGNOSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if dates_only_in_baseline:\n",
    "    print(\"\\nROOT CAUSE: Advanced imputation is missing specific dates\")\n",
    "    print(\"LOCATION: Either in imputation or lag creation process\")\n",
    "    print(\"ACTION: Check why these dates were dropped\")\n",
    "elif dates_only_in_advanced:\n",
    "    print(\"\\nROOT CAUSE: Baseline is missing specific dates\")\n",
    "    print(\"LOCATION: Baseline processing dropped dates\")\n",
    "    print(\"ACTION: Check baseline lag creation logic\")\n",
    "elif baseline_dupes > 0 or advanced_dupes > 0:\n",
    "    print(\"\\nROOT CAUSE: Duplicate dates in one dataset\")\n",
    "    print(\"ACTION: Check for duplicate date handling in processing\")\n",
    "elif 'matrix_baseline' in locals() and 'matrix_advanced' in locals():\n",
    "    if len(matrix_baseline) != len(matrix_advanced):\n",
    "        print(\"\\nROOT CAUSE: Source data has different row counts BEFORE lag creation\")\n",
    "        print(\"LOCATION: In the imputation process itself\")\n",
    "        print(\"ACTION: Check imputation scripts for row dropping\")\n",
    "    else:\n",
    "        print(\"\\nROOT CAUSE: Lag creation process handles the two datasets differently\")\n",
    "        print(\"LOCATION: In lagged_data_preparation scripts\")\n",
    "        print(\"ACTION: Compare lag creation logic between baseline and advanced versions\")\n",
    "else:\n",
    "    print(\"\\nCannot determine root cause. Need to check source files.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8912a7a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T08:40:20.639133Z",
     "start_time": "2025-10-03T08:40:20.505876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline matrix: 365 rows\n",
      "  Date range: 2025-09-16 00:00:00 to 2026-09-15 00:00:00\n",
      "\n",
      "Advanced matrix: 364 rows\n",
      "  Date range: 2025-09-16 00:00:00 to 2026-09-14 00:00:00\n",
      "\n",
      "Missing in ADVANCED matrix:\n",
      "  2026-09-15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path().cwd().parent / 'data' / 'dataprocessed'\n",
    "\n",
    "# Load both source matrices\n",
    "baseline_matrix = pd.read_csv(data_path / 'competitor_price_matrix.csv')\n",
    "baseline_matrix['date'] = pd.to_datetime(baseline_matrix['stay_date'])\n",
    "\n",
    "advanced_matrix = pd.read_csv(data_path / 'competitor_price_matrix_advanced_imputation.csv')\n",
    "advanced_matrix['date'] = pd.to_datetime(advanced_matrix['stay_date'])\n",
    "\n",
    "print(f\"Baseline matrix: {len(baseline_matrix)} rows\")\n",
    "print(f\"  Date range: {baseline_matrix['date'].min()} to {baseline_matrix['date'].max()}\")\n",
    "\n",
    "print(f\"\\nAdvanced matrix: {len(advanced_matrix)} rows\")\n",
    "print(f\"  Date range: {advanced_matrix['date'].min()} to {advanced_matrix['date'].max()}\")\n",
    "\n",
    "# Find missing dates\n",
    "baseline_dates = set(baseline_matrix['date'])\n",
    "advanced_dates = set(advanced_matrix['date'])\n",
    "\n",
    "missing_in_advanced = baseline_dates - advanced_dates\n",
    "if missing_in_advanced:\n",
    "    print(f\"\\nMissing in ADVANCED matrix:\")\n",
    "    for date in sorted(missing_in_advanced):\n",
    "        print(f\"  {date.date()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
