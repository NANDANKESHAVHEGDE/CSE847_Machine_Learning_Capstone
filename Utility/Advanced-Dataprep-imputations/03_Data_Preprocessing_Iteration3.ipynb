{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002d6cc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T22:32:13.484716Z",
     "start_time": "2025-10-07T22:32:02.851347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focal: 365 days\n",
      "Compset: 5 hotels\n",
      "\n",
      "================================================================================\n",
      "CREATING PRICE MATRIX\n",
      "================================================================================\n",
      "Matrix shape: (364, 6)\n",
      "Missing: 30 / 2184 (1.4%)\n",
      "\n",
      "================================================================================\n",
      "APPLYING MATRIX COMPLETION\n",
      "================================================================================\n",
      "Method: IterativeImputer\n",
      "Correlation preserved: 99.0%\n",
      "\n",
      "================================================================================\n",
      "SAVING RESULTS\n",
      "================================================================================\n",
      "Saved: matrix_completion_imputed.csv\n",
      "Saved: focal_matrix_completion.csv\n",
      "Saved: competitors_matrix_completion.csv\n",
      "Saved: competitor_price_matrix_matrix_completion.csv\n",
      "\n",
      "Done. Ready for lagged feature creation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MATRIX COMPLETION IMPUTATION\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_path = Path('../../data/dataraw')\n",
    "\n",
    "# Load focal\n",
    "focal = pd.read_csv(data_path / 'data-1757985699237.csv')\n",
    "focal['stay_date'] = pd.to_datetime(focal['stay_date'])\n",
    "focal = focal.groupby('stay_date')['price'].min().reset_index()\n",
    "focal.columns = ['date', 'base_rate']\n",
    "focal = focal.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(f\"Focal: {len(focal)} days\")\n",
    "\n",
    "# Load compset\n",
    "compset = pd.read_csv(data_path / 'data-1757985744315.csv')\n",
    "compset['stay_date'] = pd.to_datetime(compset['stay_date'])\n",
    "compset = compset.groupby(['stay_date', 'hotel_id'])['price'].min().reset_index()\n",
    "compset.columns = ['date', 'hotel_id', 'competitor_price']\n",
    "\n",
    "print(f\"Compset: {compset['hotel_id'].nunique()} hotels\")\n",
    "\n",
    "# Create price matrix\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING PRICE MATRIX\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comp_matrix = compset.pivot(index='date', columns='hotel_id', values='competitor_price')\n",
    "merged = focal[['date', 'base_rate']].merge(comp_matrix, on='date', how='inner')\n",
    "merged = merged.sort_values('date').reset_index(drop=True)\n",
    "hotel_names = ['base_rate'] + list(comp_matrix.columns)\n",
    "\n",
    "price_matrix = merged.drop('date', axis=1).values\n",
    "dates = merged['date'].values\n",
    "\n",
    "print(f\"Matrix shape: {price_matrix.shape}\")\n",
    "print(f\"Missing: {np.isnan(price_matrix).sum()} / {price_matrix.size} ({100 * np.isnan(price_matrix).sum() / price_matrix.size:.1f}%)\")\n",
    "\n",
    "# Apply matrix completion\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"APPLYING MATRIX COMPLETION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    from fancyimpute import SoftImpute\n",
    "    max_rank = min(3, min(price_matrix.shape) - 1)\n",
    "    imputer = SoftImpute(max_rank=max_rank, verbose=False)\n",
    "    completed_matrix = imputer.fit_transform(price_matrix)\n",
    "    method_used = \"Soft-Impute\"\n",
    "    print(f\"Method: Soft-Impute (max_rank={max_rank})\")\n",
    "except ImportError:\n",
    "    from sklearn.experimental import enable_iterative_imputer\n",
    "    from sklearn.impute import IterativeImputer\n",
    "    from sklearn.linear_model import BayesianRidge\n",
    "    imputer = IterativeImputer(estimator=BayesianRidge(), max_iter=10, random_state=42, verbose=0)\n",
    "    completed_matrix = imputer.fit_transform(price_matrix)\n",
    "    method_used = \"IterativeImputer\"\n",
    "    print(\"Method: IterativeImputer\")\n",
    "\n",
    "# Handle remaining missing values\n",
    "remaining_missing = np.isnan(completed_matrix).sum()\n",
    "if remaining_missing > 0:\n",
    "    for i in range(completed_matrix.shape[1]):\n",
    "        col_mean = np.nanmean(completed_matrix[:, i])\n",
    "        if np.isnan(col_mean):\n",
    "            col_mean = np.nanmean(completed_matrix)\n",
    "        completed_matrix[np.isnan(completed_matrix[:, i]), i] = col_mean\n",
    "\n",
    "# Clip negative values\n",
    "if (completed_matrix < 0).sum() > 0:\n",
    "    completed_matrix = np.maximum(completed_matrix, 0)\n",
    "\n",
    "# Calculate correlations\n",
    "original_df = pd.DataFrame(price_matrix, columns=hotel_names)\n",
    "completed_df_temp = pd.DataFrame(completed_matrix, columns=hotel_names)\n",
    "original_corr = original_df.corr()\n",
    "completed_corr = completed_df_temp.corr()\n",
    "corr_diff = np.abs(original_corr - completed_corr)\n",
    "valid_corr = ~(original_corr.isna() | completed_corr.isna())\n",
    "avg_corr_diff = corr_diff[valid_corr].mean().mean()\n",
    "\n",
    "print(f\"Correlation preserved: {(1 - avg_corr_diff)*100:.1f}%\")\n",
    "\n",
    "# Save results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "completed_df = pd.DataFrame(completed_matrix, columns=hotel_names)\n",
    "completed_df.insert(0, 'date', dates)\n",
    "\n",
    "# Save full matrix\n",
    "output_path = Path('../../data/dataprocessed')\n",
    "completed_df.to_csv(output_path / 'matrix_completion_imputed.csv', index=False)\n",
    "print(\"Saved: matrix_completion_imputed.csv\")\n",
    "\n",
    "# Save focal\n",
    "focal_completed = completed_df[['date', 'base_rate']].copy()\n",
    "focal_completed.to_csv(output_path / 'focal_matrix_completion.csv', index=False)\n",
    "print(\"Saved: focal_matrix_completion.csv\")\n",
    "\n",
    "# Save competitors\n",
    "comp_completed = completed_df.drop('base_rate', axis=1).copy()\n",
    "comp_melted = comp_completed.melt(id_vars='date', var_name='hotel_id', value_name='competitor_price')\n",
    "comp_melted.to_csv(output_path / 'competitors_matrix_completion.csv', index=False)\n",
    "print(\"Saved: competitors_matrix_completion.csv\")\n",
    "\n",
    "# Save competitor matrix\n",
    "comp_matrix_completed = comp_completed.set_index('date').T\n",
    "comp_matrix_completed.to_csv(output_path / 'competitor_price_matrix_matrix_completion.csv')\n",
    "print(\"Saved: competitor_price_matrix_matrix_completion.csv\")\n",
    "\n",
    "print(\"\\nDone. Ready for lagged feature creation.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
