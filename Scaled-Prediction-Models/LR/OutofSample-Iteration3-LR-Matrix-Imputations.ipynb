{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daa19a08",
   "metadata": {},
   "source": [
    "# Without Cross Validations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c7d235",
   "metadata": {},
   "source": [
    "## LR with past data - Iteration1 - Detrending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb9698bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T06:36:56.060811Z",
     "start_time": "2025-10-21T06:36:56.048025Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from pathlib import Path\n",
    "# from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# import json\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# # Configuration\n",
    "# processed_data_path = Path('../data/full-data/processed')\n",
    "# output_path = Path('../data/full-data/final_temporal_models_regularization')\n",
    "# output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# mapping_df = pd.read_csv('../data/full-data/hotel_mapping.csv')\n",
    "# hotel_list = mapping_df['masked_id'].tolist()\n",
    "\n",
    "# # Temporal split configuration\n",
    "# TRAIN_PCT = 0.60\n",
    "# VAL_PCT = 0.20\n",
    "# TEST_PCT = 0.20\n",
    "\n",
    "# # Regularization parameters to test\n",
    "# MODELS = {\n",
    "#     'Ridge_1.0': Ridge(alpha=1.0, random_state=42),\n",
    "#     'Ridge_10': Ridge(alpha=10.0, random_state=42),\n",
    "#     'Ridge_100': Ridge(alpha=100.0, random_state=42),\n",
    "#     'Lasso_0.1': Lasso(alpha=0.1, random_state=42, max_iter=10000),\n",
    "#     'Lasso_1.0': Lasso(alpha=1.0, random_state=42, max_iter=10000),\n",
    "#     'Lasso_10': Lasso(alpha=10.0, random_state=42, max_iter=10000),\n",
    "#     'ElasticNet_0.1': ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42, max_iter=10000),\n",
    "#     'ElasticNet_1.0': ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42, max_iter=10000),\n",
    "#     'ElasticNet_10': ElasticNet(alpha=10.0, l1_ratio=0.5, random_state=42, max_iter=10000)\n",
    "# }\n",
    "\n",
    "# print(\"=\"*100)\n",
    "# print(\"LINEAR MODELS WITH MULTIPLE REGULARIZATION METHODS\")\n",
    "# print(\"=\"*100)\n",
    "# print(f\"Temporal Split: {TRAIN_PCT*100:.0f}% Train / {VAL_PCT*100:.0f}% Val / {TEST_PCT*100:.0f}% Test\")\n",
    "# print(f\"Data Source: lagged_dataset.csv\")\n",
    "# print(f\"Testing {len(MODELS)} regularization configurations:\")\n",
    "# for name in MODELS.keys():\n",
    "#     print(f\"  - {name}\")\n",
    "# print(\"-\" * 100)\n",
    "\n",
    "# def detrend_series(series, window=30):\n",
    "#     \"\"\"Detrend using rolling mean subtraction\"\"\"\n",
    "#     if series.notna().sum() < window:\n",
    "#         return series.fillna(0)\n",
    "    \n",
    "#     trend = series.rolling(window=window, min_periods=1, center=False).mean()\n",
    "#     detrended = series - trend\n",
    "#     return detrended.fillna(0)\n",
    "\n",
    "# def prepare_features(df):\n",
    "#     \"\"\"Prepare all features with detrending\"\"\"\n",
    "#     df_processed = df.copy()\n",
    "    \n",
    "#     # All competitor columns\n",
    "#     all_comp_cols = [col for col in df.columns \n",
    "#                      if any(currency in col for currency in ['-USD', '-EUR', '-HKD', '-CNY'])]\n",
    "    \n",
    "#     comp_base_cols = [col for col in all_comp_cols if '_lag_' not in col]\n",
    "#     comp_lag_cols = [col for col in all_comp_cols if '_lag_' in col]\n",
    "    \n",
    "#     # Detrend base competitor prices\n",
    "#     for col in comp_base_cols:\n",
    "#         if col in df_processed.columns:\n",
    "#             df_processed[f'{col}_detrended'] = detrend_series(df_processed[col], window=30)\n",
    "    \n",
    "#     # Detrend competitor lags\n",
    "#     for col in comp_lag_cols:\n",
    "#         if col in df_processed.columns:\n",
    "#             df_processed[f'{col}_detrended'] = detrend_series(df_processed[col], window=30)\n",
    "    \n",
    "#     # Detrend own price lags\n",
    "#     for lag in [1, 2, 3, 4, 5]:\n",
    "#         lag_col = f'base_rate_lag_{lag}'\n",
    "#         if lag_col in df_processed.columns:\n",
    "#             df_processed[f'{lag_col}_detrended'] = detrend_series(df_processed[lag_col], window=30)\n",
    "    \n",
    "#     # Feature columns\n",
    "#     feature_cols = []\n",
    "    \n",
    "#     detrended_comp_base = [f'{col}_detrended' for col in comp_base_cols if f'{col}_detrended' in df_processed.columns]\n",
    "#     feature_cols.extend(detrended_comp_base)\n",
    "    \n",
    "#     detrended_comp_lags = [f'{col}_detrended' for col in comp_lag_cols if f'{col}_detrended' in df_processed.columns]\n",
    "#     feature_cols.extend(detrended_comp_lags)\n",
    "    \n",
    "#     detrended_own_lags = [f'base_rate_lag_{i}_detrended' for i in range(1, 6) \n",
    "#                          if f'base_rate_lag_{i}_detrended' in df_processed.columns]\n",
    "#     feature_cols.extend(detrended_own_lags)\n",
    "    \n",
    "#     temporal_cols = ['day_of_week', 'month', 'is_weekend', 'is_peak_season', \n",
    "#                     'week_of_year', 'quarter', 'is_holiday_period', 'day_of_year',\n",
    "#                     'sin_day_of_week', 'cos_day_of_week', 'sin_month', 'cos_month',\n",
    "#                     'sin_day_of_year', 'cos_day_of_year']\n",
    "#     temporal_cols = [col for col in temporal_cols if col in df_processed.columns]\n",
    "#     feature_cols.extend(temporal_cols)\n",
    "    \n",
    "#     return df_processed, feature_cols\n",
    "\n",
    "# def train_all_models_hotel(hotel_id):\n",
    "#     \"\"\"Train all regularization models for a single hotel\"\"\"\n",
    "#     result = {\n",
    "#         'hotel_id': hotel_id,\n",
    "#         'status': 'training',\n",
    "#         'models': {}\n",
    "#     }\n",
    "    \n",
    "#     try:\n",
    "#         data_file = processed_data_path / f'{hotel_id}_lagged_dataset.csv'\n",
    "        \n",
    "#         if not data_file.exists():\n",
    "#             result['status'] = 'missing_file'\n",
    "#             return result\n",
    "        \n",
    "#         df = pd.read_csv(data_file)\n",
    "#         df['date'] = pd.to_datetime(df['date'])\n",
    "#         df = df.sort_values('date').reset_index(drop=True)\n",
    "        \n",
    "#         min_date = df['date'].min()\n",
    "#         max_date = df['date'].max()\n",
    "        \n",
    "#         if len(df) < 150:\n",
    "#             result['status'] = 'insufficient_data'\n",
    "#             return result\n",
    "        \n",
    "#         # Prepare features\n",
    "#         df_processed, feature_cols = prepare_features(df)\n",
    "        \n",
    "#         if len(feature_cols) == 0:\n",
    "#             result['status'] = 'no_features'\n",
    "#             return result\n",
    "        \n",
    "#         result['n_features'] = len(feature_cols)\n",
    "        \n",
    "#         # Split data\n",
    "#         n_rows = len(df_processed)\n",
    "#         train_end_idx = int(n_rows * TRAIN_PCT)\n",
    "#         val_end_idx = int(n_rows * (TRAIN_PCT + VAL_PCT))\n",
    "        \n",
    "#         train_end_date = df_processed.iloc[train_end_idx - 1]['date']\n",
    "#         val_end_date = df_processed.iloc[val_end_idx - 1]['date']\n",
    "        \n",
    "#         train_mask = df_processed['date'] <= train_end_date\n",
    "#         val_mask = (df_processed['date'] > train_end_date) & (df_processed['date'] <= val_end_date)\n",
    "#         test_mask = df_processed['date'] > val_end_date\n",
    "        \n",
    "#         df_train = df_processed[train_mask].copy()\n",
    "#         df_val = df_processed[val_mask].copy()\n",
    "#         df_test = df_processed[test_mask].copy()\n",
    "        \n",
    "#         if len(df_train) < 30 or len(df_val) < 10 or len(df_test) < 10:\n",
    "#             result['status'] = 'insufficient_split_data'\n",
    "#             return result\n",
    "        \n",
    "#         # Prepare data\n",
    "#         X_train = df_train[feature_cols].fillna(0)\n",
    "#         y_train = df_train['base_rate'].fillna(method='ffill').fillna(method='bfill')\n",
    "        \n",
    "#         X_val = df_val[feature_cols].fillna(0)\n",
    "#         y_val = df_val['base_rate'].fillna(method='ffill').fillna(method='bfill')\n",
    "        \n",
    "#         X_test = df_test[feature_cols].fillna(0)\n",
    "#         y_test = df_test['base_rate'].fillna(method='ffill').fillna(method='bfill')\n",
    "        \n",
    "#         # Standardize\n",
    "#         scaler = StandardScaler()\n",
    "#         X_train_scaled = scaler.fit_transform(X_train)\n",
    "#         X_val_scaled = scaler.transform(X_val)\n",
    "#         X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "#         # Train all models\n",
    "#         for model_name, model in MODELS.items():\n",
    "#             try:\n",
    "#                 model.fit(X_train_scaled, y_train)\n",
    "                \n",
    "#                 y_train_pred = model.predict(X_train_scaled)\n",
    "#                 y_val_pred = model.predict(X_val_scaled)\n",
    "#                 y_test_pred = model.predict(X_test_scaled)\n",
    "                \n",
    "#                 result['models'][model_name] = {\n",
    "#                     'train_r2': float(r2_score(y_train, y_train_pred)),\n",
    "#                     'train_rmse': float(np.sqrt(mean_squared_error(y_train, y_train_pred))),\n",
    "#                     'val_r2': float(r2_score(y_val, y_val_pred)),\n",
    "#                     'val_rmse': float(np.sqrt(mean_squared_error(y_val, y_val_pred))),\n",
    "#                     'test_r2': float(r2_score(y_test, y_test_pred)),\n",
    "#                     'test_rmse': float(np.sqrt(mean_squared_error(y_test, y_test_pred))),\n",
    "#                     'test_mae': float(mean_absolute_error(y_test, y_test_pred))\n",
    "#                 }\n",
    "#             except Exception as e:\n",
    "#                 result['models'][model_name] = {\n",
    "#                     'error': str(e)\n",
    "#                 }\n",
    "        \n",
    "#         result['status'] = 'success'\n",
    "#         return result\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         result['status'] = 'error'\n",
    "#         result['error'] = str(e)\n",
    "#         return result\n",
    "\n",
    "# # Train all hotels\n",
    "# print(\"\\nTraining all regularization models for all hotels...\")\n",
    "# print(\"-\" * 100)\n",
    "\n",
    "# all_results = {}\n",
    "# for idx, hotel_id in enumerate(hotel_list, 1):\n",
    "#     print(f\"[{idx}/{len(hotel_list)}] {hotel_id}...\", end='\\r')\n",
    "#     result = train_all_models_hotel(hotel_id)\n",
    "#     all_results[hotel_id] = result\n",
    "\n",
    "# successful = [h for h, r in all_results.items() if r['status'] == 'success']\n",
    "# print(f\"\\n\\nSuccessfully trained: {len(successful)}/{len(hotel_list)} hotels\")\n",
    "\n",
    "# # Save results\n",
    "# with open(output_path / 'regularization_comparison_results.json', 'w') as f:\n",
    "#     json.dump(all_results, f, indent=2)\n",
    "\n",
    "# # Generate comparison report\n",
    "# print(\"\\n\" + \"=\"*100)\n",
    "# print(\"REGULARIZATION COMPARISON REPORT\")\n",
    "# print(\"=\"*100)\n",
    "\n",
    "# if len(successful) > 0:\n",
    "#     # Compare models\n",
    "#     model_comparison = {}\n",
    "    \n",
    "#     for model_name in MODELS.keys():\n",
    "#         test_r2s = []\n",
    "#         val_r2s = []\n",
    "#         test_rmses = []\n",
    "        \n",
    "#         for hotel_id in successful:\n",
    "#             if model_name in all_results[hotel_id]['models']:\n",
    "#                 model_result = all_results[hotel_id]['models'][model_name]\n",
    "#                 if 'test_r2' in model_result:\n",
    "#                     test_r2s.append(model_result['test_r2'])\n",
    "#                     val_r2s.append(model_result['val_r2'])\n",
    "#                     test_rmses.append(model_result['test_rmse'])\n",
    "        \n",
    "#         if len(test_r2s) > 0:\n",
    "#             model_comparison[model_name] = {\n",
    "#                 'median_test_r2': np.median(test_r2s),\n",
    "#                 'mean_test_r2': np.mean(test_r2s),\n",
    "#                 'median_val_r2': np.median(val_r2s),\n",
    "#                 'median_test_rmse': np.median(test_rmses),\n",
    "#                 'n_excellent': sum(1 for r in test_r2s if r > 0.70),\n",
    "#                 'n_good': sum(1 for r in test_r2s if 0.40 < r <= 0.70),\n",
    "#                 'n_poor': sum(1 for r in test_r2s if r <= 0.20)\n",
    "#             }\n",
    "    \n",
    "#     # Sort by median test R²\n",
    "#     sorted_models = sorted(model_comparison.items(), key=lambda x: x[1]['median_test_r2'], reverse=True)\n",
    "    \n",
    "#     print(\"\\nModel Comparison (sorted by Median Test R²):\")\n",
    "#     print(\"-\" * 100)\n",
    "#     print(f\"{'Model':<20} {'Med Test R²':<15} {'Med Val R²':<15} {'Med RMSE':<12} {'Excellent':<12} {'Good':<8} {'Poor':<8}\")\n",
    "#     print(\"-\" * 100)\n",
    "    \n",
    "#     for model_name, metrics in sorted_models:\n",
    "#         print(f\"{model_name:<20} {metrics['median_test_r2']:>14.4f} {metrics['median_val_r2']:>14.4f} \"\n",
    "#               f\"{metrics['median_test_rmse']:>11.2f} {metrics['n_excellent']:>11} \"\n",
    "#               f\"{metrics['n_good']:>7} {metrics['n_poor']:>7}\")\n",
    "    \n",
    "#     # Best model\n",
    "#     best_model = sorted_models[0][0]\n",
    "#     print(f\"\\nBest Model: {best_model}\")\n",
    "#     print(f\"Median Test R²: {sorted_models[0][1]['median_test_r2']:.4f}\")\n",
    "    \n",
    "#     # Create summary CSV\n",
    "#     summary_data = []\n",
    "#     for hotel_id in successful:\n",
    "#         hotel_row = {'hotel_id': hotel_id}\n",
    "#         for model_name in MODELS.keys():\n",
    "#             if model_name in all_results[hotel_id]['models']:\n",
    "#                 model_result = all_results[hotel_id]['models'][model_name]\n",
    "#                 if 'test_r2' in model_result:\n",
    "#                     hotel_row[f'{model_name}_test_r2'] = model_result['test_r2']\n",
    "#                     hotel_row[f'{model_name}_val_r2'] = model_result['val_r2']\n",
    "#         summary_data.append(hotel_row)\n",
    "    \n",
    "#     summary_df = pd.DataFrame(summary_data)\n",
    "#     summary_df.to_csv(output_path / 'regularization_comparison_summary.csv', index=False)\n",
    "    \n",
    "#     print(f\"\\nFiles saved to: {output_path}/\")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*100)\n",
    "# print(\"SUMMARY\")\n",
    "# print(\"=\"*100)\n",
    "# print(f\"Tested {len(MODELS)} regularization configurations\")\n",
    "# print(f\"Successfully trained: {len(successful)}/{len(hotel_list)} hotels\")\n",
    "# print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c836d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T00:17:03.992940Z",
     "start_time": "2025-10-21T00:17:03.990117Z"
    }
   },
   "source": [
    "## LR with past data - Iteration2 - Log transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d53fe4b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T06:36:56.101820Z",
     "start_time": "2025-10-21T06:36:56.090926Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from pathlib import Path\n",
    "# from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# import json\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# # Configuration\n",
    "# processed_data_path = Path('../data/full-data/processed')\n",
    "# output_path = Path('../data/full-data/final_log_strong_regularization')\n",
    "# output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# mapping_df = pd.read_csv('../data/full-data/hotel_mapping.csv')\n",
    "# hotel_list = mapping_df['masked_id'].tolist()\n",
    "\n",
    "# # Temporal split configuration\n",
    "# TRAIN_PCT = 0.60\n",
    "# VAL_PCT = 0.20\n",
    "# TEST_PCT = 0.20\n",
    "\n",
    "# # Best regularization models from previous analysis\n",
    "# MODELS = {\n",
    "#     'Ridge_100': Ridge(alpha=100.0, random_state=42),\n",
    "#     'ElasticNet_1.0': ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42, max_iter=10000),\n",
    "#     'Lasso_1.0': Lasso(alpha=1.0, random_state=42, max_iter=10000)\n",
    "# }\n",
    "\n",
    "# print(\"=\"*100)\n",
    "# print(\"LINEAR MODELS WITH LOG TRANSFORMATION + STRONG REGULARIZATION\")\n",
    "# print(\"=\"*100)\n",
    "# print(f\"Temporal Split: {TRAIN_PCT*100:.0f}% Train / {VAL_PCT*100:.0f}% Val / {TEST_PCT*100:.0f}% Test\")\n",
    "# print(f\"Data Source: lagged_dataset.csv (full feature set)\")\n",
    "# print(f\"Transformation: log1p (log(1 + x))\")\n",
    "# print(f\"Testing 3 best regularization methods:\")\n",
    "# for name in MODELS.keys():\n",
    "#     print(f\"  - {name}\")\n",
    "# print(\"-\" * 100)\n",
    "\n",
    "# def detrend_series_log(series, window=30):\n",
    "#     \"\"\"Detrend in log space using rolling mean subtraction\"\"\"\n",
    "#     if series.notna().sum() < window:\n",
    "#         return series.fillna(0)\n",
    "    \n",
    "#     # Apply log1p first\n",
    "#     log_series = np.log1p(series.clip(lower=0))\n",
    "    \n",
    "#     # Detrend in log space\n",
    "#     trend = log_series.rolling(window=window, min_periods=1, center=False).mean()\n",
    "#     detrended = log_series - trend\n",
    "    \n",
    "#     return detrended.fillna(0)\n",
    "\n",
    "# def prepare_features_log(df):\n",
    "#     \"\"\"Prepare all features with log transformation and detrending\"\"\"\n",
    "#     df_processed = df.copy()\n",
    "    \n",
    "#     # All competitor columns\n",
    "#     all_comp_cols = [col for col in df.columns \n",
    "#                      if any(currency in col for currency in ['-USD', '-EUR', '-HKD', '-CNY'])]\n",
    "    \n",
    "#     comp_base_cols = [col for col in all_comp_cols if '_lag_' not in col]\n",
    "#     comp_lag_cols = [col for col in all_comp_cols if '_lag_' in col]\n",
    "    \n",
    "#     # Log transform + detrend base competitor prices\n",
    "#     for col in comp_base_cols:\n",
    "#         if col in df_processed.columns:\n",
    "#             df_processed[f'{col}_log_detrended'] = detrend_series_log(df_processed[col], window=30)\n",
    "    \n",
    "#     # Log transform + detrend competitor lags\n",
    "#     for col in comp_lag_cols:\n",
    "#         if col in df_processed.columns:\n",
    "#             df_processed[f'{col}_log_detrended'] = detrend_series_log(df_processed[col], window=30)\n",
    "    \n",
    "#     # Log transform + detrend own price lags\n",
    "#     for lag in [1, 2, 3, 4, 5]:\n",
    "#         lag_col = f'base_rate_lag_{lag}'\n",
    "#         if lag_col in df_processed.columns:\n",
    "#             df_processed[f'{lag_col}_log_detrended'] = detrend_series_log(df_processed[lag_col], window=30)\n",
    "    \n",
    "#     # Feature columns\n",
    "#     feature_cols = []\n",
    "    \n",
    "#     log_detrended_comp_base = [f'{col}_log_detrended' for col in comp_base_cols \n",
    "#                                 if f'{col}_log_detrended' in df_processed.columns]\n",
    "#     feature_cols.extend(log_detrended_comp_base)\n",
    "    \n",
    "#     log_detrended_comp_lags = [f'{col}_log_detrended' for col in comp_lag_cols \n",
    "#                                 if f'{col}_log_detrended' in df_processed.columns]\n",
    "#     feature_cols.extend(log_detrended_comp_lags)\n",
    "    \n",
    "#     log_detrended_own_lags = [f'base_rate_lag_{i}_log_detrended' for i in range(1, 6) \n",
    "#                               if f'base_rate_lag_{i}_log_detrended' in df_processed.columns]\n",
    "#     feature_cols.extend(log_detrended_own_lags)\n",
    "    \n",
    "#     temporal_cols = ['day_of_week', 'month', 'is_weekend', 'is_peak_season', \n",
    "#                     'week_of_year', 'quarter', 'is_holiday_period', 'day_of_year',\n",
    "#                     'sin_day_of_week', 'cos_day_of_week', 'sin_month', 'cos_month',\n",
    "#                     'sin_day_of_year', 'cos_day_of_year']\n",
    "#     temporal_cols = [col for col in temporal_cols if col in df_processed.columns]\n",
    "#     feature_cols.extend(temporal_cols)\n",
    "    \n",
    "#     return df_processed, feature_cols\n",
    "\n",
    "# def train_all_models_hotel(hotel_id):\n",
    "#     \"\"\"Train all log-transformed models for a single hotel\"\"\"\n",
    "#     result = {\n",
    "#         'hotel_id': hotel_id,\n",
    "#         'status': 'training',\n",
    "#         'models': {}\n",
    "#     }\n",
    "    \n",
    "#     try:\n",
    "#         data_file = processed_data_path / f'{hotel_id}_lagged_dataset.csv'\n",
    "        \n",
    "#         if not data_file.exists():\n",
    "#             result['status'] = 'missing_file'\n",
    "#             return result\n",
    "        \n",
    "#         df = pd.read_csv(data_file)\n",
    "#         df['date'] = pd.to_datetime(df['date'])\n",
    "#         df = df.sort_values('date').reset_index(drop=True)\n",
    "        \n",
    "#         if len(df) < 150:\n",
    "#             result['status'] = 'insufficient_data'\n",
    "#             return result\n",
    "        \n",
    "#         # Prepare features with log transformation\n",
    "#         df_processed, feature_cols = prepare_features_log(df)\n",
    "        \n",
    "#         if len(feature_cols) == 0:\n",
    "#             result['status'] = 'no_features'\n",
    "#             return result\n",
    "        \n",
    "#         result['n_features'] = len(feature_cols)\n",
    "        \n",
    "#         # Split data (percentage-based)\n",
    "#         n_rows = len(df_processed)\n",
    "#         train_end_idx = int(n_rows * TRAIN_PCT)\n",
    "#         val_end_idx = int(n_rows * (TRAIN_PCT + VAL_PCT))\n",
    "        \n",
    "#         train_end_date = df_processed.iloc[train_end_idx - 1]['date']\n",
    "#         val_end_date = df_processed.iloc[val_end_idx - 1]['date']\n",
    "        \n",
    "#         train_mask = df_processed['date'] <= train_end_date\n",
    "#         val_mask = (df_processed['date'] > train_end_date) & (df_processed['date'] <= val_end_date)\n",
    "#         test_mask = df_processed['date'] > val_end_date\n",
    "        \n",
    "#         df_train = df_processed[train_mask].copy()\n",
    "#         df_val = df_processed[val_mask].copy()\n",
    "#         df_test = df_processed[test_mask].copy()\n",
    "        \n",
    "#         if len(df_train) < 30 or len(df_val) < 10 or len(df_test) < 10:\n",
    "#             result['status'] = 'insufficient_split_data'\n",
    "#             return result\n",
    "        \n",
    "#         # Store split info\n",
    "#         result['split_info'] = {\n",
    "#             'train_start': str(df_train['date'].min()),\n",
    "#             'train_end': str(df_train['date'].max()),\n",
    "#             'train_rows': len(df_train),\n",
    "#             'val_start': str(df_val['date'].min()),\n",
    "#             'val_end': str(df_val['date'].max()),\n",
    "#             'val_rows': len(df_val),\n",
    "#             'test_start': str(df_test['date'].min()),\n",
    "#             'test_end': str(df_test['date'].max()),\n",
    "#             'test_rows': len(df_test)\n",
    "#         }\n",
    "        \n",
    "#         # Prepare data\n",
    "#         X_train = df_train[feature_cols].fillna(0)\n",
    "#         # Target in log space\n",
    "#         y_train_original = df_train['base_rate'].fillna(method='ffill').fillna(method='bfill')\n",
    "#         y_train = np.log1p(y_train_original.clip(lower=0))\n",
    "        \n",
    "#         X_val = df_val[feature_cols].fillna(0)\n",
    "#         y_val_original = df_val['base_rate'].fillna(method='ffill').fillna(method='bfill')\n",
    "#         y_val = np.log1p(y_val_original.clip(lower=0))\n",
    "        \n",
    "#         X_test = df_test[feature_cols].fillna(0)\n",
    "#         y_test_original = df_test['base_rate'].fillna(method='ffill').fillna(method='bfill')\n",
    "#         y_test = np.log1p(y_test_original.clip(lower=0))\n",
    "        \n",
    "#         # Standardize features\n",
    "#         scaler = StandardScaler()\n",
    "#         X_train_scaled = scaler.fit_transform(X_train)\n",
    "#         X_val_scaled = scaler.transform(X_val)\n",
    "#         X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "#         # Train all models\n",
    "#         for model_name, model in MODELS.items():\n",
    "#             try:\n",
    "#                 model.fit(X_train_scaled, y_train)\n",
    "                \n",
    "#                 # Predictions in log space\n",
    "#                 y_train_pred_log = model.predict(X_train_scaled)\n",
    "#                 y_val_pred_log = model.predict(X_val_scaled)\n",
    "#                 y_test_pred_log = model.predict(X_test_scaled)\n",
    "                \n",
    "#                 # Transform back to original space\n",
    "#                 y_train_pred = np.expm1(y_train_pred_log)\n",
    "#                 y_val_pred = np.expm1(y_val_pred_log)\n",
    "#                 y_test_pred = np.expm1(y_test_pred_log)\n",
    "                \n",
    "#                 # Calculate metrics in original space\n",
    "#                 result['models'][model_name] = {\n",
    "#                     'train_r2': float(r2_score(y_train_original, y_train_pred)),\n",
    "#                     'train_rmse': float(np.sqrt(mean_squared_error(y_train_original, y_train_pred))),\n",
    "#                     'val_r2': float(r2_score(y_val_original, y_val_pred)),\n",
    "#                     'val_rmse': float(np.sqrt(mean_squared_error(y_val_original, y_val_pred))),\n",
    "#                     'test_r2': float(r2_score(y_test_original, y_test_pred)),\n",
    "#                     'test_rmse': float(np.sqrt(mean_squared_error(y_test_original, y_test_pred))),\n",
    "#                     'test_mae': float(mean_absolute_error(y_test_original, y_test_pred)),\n",
    "#                     'train_test_gap': float(r2_score(y_train_original, y_train_pred) - r2_score(y_test_original, y_test_pred))\n",
    "#                 }\n",
    "                \n",
    "#                 # Save predictions for best model (Ridge_100)\n",
    "#                 if model_name == 'Ridge_100':\n",
    "#                     predictions_df = pd.DataFrame({\n",
    "#                         'date': df_test['date'],\n",
    "#                         'actual_price': y_test_original,\n",
    "#                         'predicted_price': y_test_pred,\n",
    "#                         'error': y_test_original - y_test_pred,\n",
    "#                         'abs_error': np.abs(y_test_original - y_test_pred),\n",
    "#                         'pct_error': 100 * (y_test_original - y_test_pred) / y_test_original\n",
    "#                     })\n",
    "#                     predictions_df.to_csv(output_path / f'{hotel_id}_log_ridge100_predictions.csv', index=False)\n",
    "                \n",
    "#             except Exception as e:\n",
    "#                 result['models'][model_name] = {\n",
    "#                     'error': str(e)\n",
    "#                 }\n",
    "        \n",
    "#         result['status'] = 'success'\n",
    "#         return result\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         result['status'] = 'error'\n",
    "#         result['error'] = str(e)\n",
    "#         return result\n",
    "\n",
    "# # Train all hotels\n",
    "# print(\"\\nTraining log-transformed models with strong regularization...\")\n",
    "# print(\"-\" * 100)\n",
    "\n",
    "# all_results = {}\n",
    "# for idx, hotel_id in enumerate(hotel_list, 1):\n",
    "#     print(f\"[{idx}/{len(hotel_list)}] {hotel_id}...\", end='\\r')\n",
    "#     result = train_all_models_hotel(hotel_id)\n",
    "#     all_results[hotel_id] = result\n",
    "\n",
    "# successful = [h for h, r in all_results.items() if r['status'] == 'success']\n",
    "# print(f\"\\n\\nSuccessfully trained: {len(successful)}/{len(hotel_list)} hotels\")\n",
    "\n",
    "# # Save results\n",
    "# with open(output_path / 'log_strong_regularization_results.json', 'w') as f:\n",
    "#     json.dump(all_results, f, indent=2)\n",
    "\n",
    "# # Generate comparison report\n",
    "# print(\"\\n\" + \"=\"*100)\n",
    "# print(\"LOG TRANSFORMATION + STRONG REGULARIZATION REPORT\")\n",
    "# print(\"=\"*100)\n",
    "\n",
    "# if len(successful) > 0:\n",
    "#     # Compare models\n",
    "#     model_comparison = {}\n",
    "    \n",
    "#     for model_name in MODELS.keys():\n",
    "#         test_r2s = []\n",
    "#         val_r2s = []\n",
    "#         train_r2s = []\n",
    "#         gaps = []\n",
    "        \n",
    "#         for hotel_id in successful:\n",
    "#             if model_name in all_results[hotel_id]['models']:\n",
    "#                 model_result = all_results[hotel_id]['models'][model_name]\n",
    "#                 if 'test_r2' in model_result:\n",
    "#                     test_r2s.append(model_result['test_r2'])\n",
    "#                     val_r2s.append(model_result['val_r2'])\n",
    "#                     train_r2s.append(model_result['train_r2'])\n",
    "#                     gaps.append(model_result['train_test_gap'])\n",
    "        \n",
    "#         if len(test_r2s) > 0:\n",
    "#             test_r2s_sorted = sorted(test_r2s)\n",
    "#             model_comparison[model_name] = {\n",
    "#                 'median_test_r2': np.median(test_r2s),\n",
    "#                 'mean_test_r2': np.mean(test_r2s),\n",
    "#                 'median_val_r2': np.median(val_r2s),\n",
    "#                 'median_train_r2': np.median(train_r2s),\n",
    "#                 'median_gap': np.median(gaps),\n",
    "#                 'n_excellent': sum(1 for r in test_r2s if r > 0.70),\n",
    "#                 'n_good': sum(1 for r in test_r2s if 0.40 < r <= 0.70),\n",
    "#                 'n_moderate': sum(1 for r in test_r2s if 0.20 < r <= 0.40),\n",
    "#                 'n_poor': sum(1 for r in test_r2s if r <= 0.20)\n",
    "#             }\n",
    "    \n",
    "#     # Sort by median test R²\n",
    "#     sorted_models = sorted(model_comparison.items(), key=lambda x: x[1]['median_test_r2'], reverse=True)\n",
    "    \n",
    "#     print(\"\\nModel Comparison (sorted by Median Test R²):\")\n",
    "#     print(\"-\" * 100)\n",
    "#     print(f\"{'Model':<20} {'Med Test R²':<15} {'Med Val R²':<15} {'Med Gap':<12} {'Excellent':<12} {'Good':<8} {'Poor':<8}\")\n",
    "#     print(\"-\" * 100)\n",
    "    \n",
    "#     for model_name, metrics in sorted_models:\n",
    "#         print(f\"{model_name:<20} {metrics['median_test_r2']:>14.4f} {metrics['median_val_r2']:>14.4f} \"\n",
    "#               f\"{metrics['median_gap']:>11.4f} {metrics['n_excellent']:>11} \"\n",
    "#               f\"{metrics['n_good']:>7} {metrics['n_poor']:>7}\")\n",
    "    \n",
    "#     # Best model\n",
    "#     best_model = sorted_models[0][0]\n",
    "#     print(f\"\\nBest Model: {best_model}\")\n",
    "#     print(f\"Median Test R²: {sorted_models[0][1]['median_test_r2']:.4f}\")\n",
    "#     print(f\"Overfitting Gap: {sorted_models[0][1]['median_gap']:.4f}\")\n",
    "    \n",
    "#     # Top performers\n",
    "#     print(\"\\n\" + \"=\"*100)\n",
    "#     print(\"TOP 10 HOTELS (by Ridge_100 test R²)\")\n",
    "#     print(\"=\"*100)\n",
    "    \n",
    "#     top_hotels = []\n",
    "#     for hotel_id in successful:\n",
    "#         if 'Ridge_100' in all_results[hotel_id]['models']:\n",
    "#             model_result = all_results[hotel_id]['models']['Ridge_100']\n",
    "#             if 'test_r2' in model_result:\n",
    "#                 top_hotels.append({\n",
    "#                     'hotel_id': hotel_id,\n",
    "#                     'test_r2': model_result['test_r2'],\n",
    "#                     'val_r2': model_result['val_r2'],\n",
    "#                     'train_r2': model_result['train_r2'],\n",
    "#                     'gap': model_result['train_test_gap'],\n",
    "#                     'test_rmse': model_result['test_rmse']\n",
    "#                 })\n",
    "    \n",
    "#     top_hotels.sort(key=lambda x: x['test_r2'], reverse=True)\n",
    "    \n",
    "#     print(f\"{'Hotel':<12} {'Test R²':<12} {'Val R²':<12} {'Train R²':<12} {'Gap':<12} {'RMSE':<12}\")\n",
    "#     print(\"-\" * 100)\n",
    "#     for h in top_hotels[:10]:\n",
    "#         print(f\"{h['hotel_id']:<12} {h['test_r2']:>11.4f} {h['val_r2']:>11.4f} \"\n",
    "#               f\"{h['train_r2']:>11.4f} {h['gap']:>11.4f} {h['test_rmse']:>11.2f}\")\n",
    "    \n",
    "#     # Create summary CSV\n",
    "#     summary_data = []\n",
    "#     for hotel_id in successful:\n",
    "#         hotel_row = {'hotel_id': hotel_id}\n",
    "#         for model_name in MODELS.keys():\n",
    "#             if model_name in all_results[hotel_id]['models']:\n",
    "#                 model_result = all_results[hotel_id]['models'][model_name]\n",
    "#                 if 'test_r2' in model_result:\n",
    "#                     hotel_row[f'{model_name}_test_r2'] = model_result['test_r2']\n",
    "#                     hotel_row[f'{model_name}_val_r2'] = model_result['val_r2']\n",
    "#                     hotel_row[f'{model_name}_gap'] = model_result['train_test_gap']\n",
    "#         summary_data.append(hotel_row)\n",
    "    \n",
    "#     summary_df = pd.DataFrame(summary_data)\n",
    "#     summary_df.to_csv(output_path / 'log_strong_regularization_summary.csv', index=False)\n",
    "    \n",
    "#     print(f\"\\nFiles saved to: {output_path}/\")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*100)\n",
    "# print(\"SUMMARY\")\n",
    "# print(\"=\"*100)\n",
    "# print(f\"Successfully trained: {len(successful)}/{len(hotel_list)} hotels\")\n",
    "# print(f\"Using log1p transformation + 30-day detrending in log space\")\n",
    "# print(f\"Testing 3 best regularization methods from previous analysis\")\n",
    "# print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72416ba",
   "metadata": {},
   "source": [
    "## LR with past data - Iteration3 - Quantile Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21de0bab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T06:36:56.131846Z",
     "start_time": "2025-10-21T06:36:56.116230Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from pathlib import Path\n",
    "# from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "# from sklearn.preprocessing import QuantileTransformer, StandardScaler\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# import json\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# # Configuration\n",
    "# processed_data_path = Path('../data/full-data/processed')\n",
    "# output_path = Path('../data/full-data/final_quantile_normalization')\n",
    "# output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# mapping_df = pd.read_csv('../data/full-data/hotel_mapping.csv')\n",
    "# hotel_list = mapping_df['masked_id'].tolist()\n",
    "\n",
    "# # Temporal split configuration\n",
    "# TRAIN_PCT = 0.60\n",
    "# VAL_PCT = 0.20\n",
    "# TEST_PCT = 0.20\n",
    "\n",
    "# # Best regularization models\n",
    "# MODELS = {\n",
    "#     'Ridge_100': Ridge(alpha=100.0, random_state=42),\n",
    "#     'Ridge_10': Ridge(alpha=10.0, random_state=42),\n",
    "#     'ElasticNet_1.0': ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42, max_iter=10000),\n",
    "#     'Lasso_1.0': Lasso(alpha=1.0, random_state=42, max_iter=10000)\n",
    "# }\n",
    "\n",
    "# print(\"=\"*100)\n",
    "# print(\"LINEAR MODELS WITH QUANTILE NORMALIZATION + STRONG REGULARIZATION\")\n",
    "# print(\"=\"*100)\n",
    "# print(f\"Temporal Split: {TRAIN_PCT*100:.0f}% Train / {VAL_PCT*100:.0f}% Val / {TEST_PCT*100:.0f}% Test\")\n",
    "# print(f\"Data Source: lagged_dataset.csv (full feature set)\")\n",
    "# print(f\"Transformation: QuantileTransformer (output='normal', robust to outliers)\")\n",
    "# print(f\"Testing 4 regularization methods:\")\n",
    "# for name in MODELS.keys():\n",
    "#     print(f\"  - {name}\")\n",
    "# print(\"\\nQuantile Normalization Benefits:\")\n",
    "# print(\"  - Maps features to normal distribution (Gaussian)\")\n",
    "# print(\"  - Handles outliers robustly\")\n",
    "# print(\"  - Makes features comparable across different scales\")\n",
    "# print(\"  - Non-linear transformation preserving rank order\")\n",
    "# print(\"-\" * 100)\n",
    "\n",
    "# def detrend_series(series, window=30):\n",
    "#     \"\"\"Detrend using rolling mean subtraction (in original space)\"\"\"\n",
    "#     if series.notna().sum() < window:\n",
    "#         return series.fillna(0)\n",
    "    \n",
    "#     trend = series.rolling(window=window, min_periods=1, center=False).mean()\n",
    "#     detrended = series - trend\n",
    "#     return detrended.fillna(0)\n",
    "\n",
    "# def prepare_features_quantile(df):\n",
    "#     \"\"\"Prepare all features with detrending (quantile transform applied later)\"\"\"\n",
    "#     df_processed = df.copy()\n",
    "    \n",
    "#     # All competitor columns\n",
    "#     all_comp_cols = [col for col in df.columns \n",
    "#                      if any(currency in col for currency in ['-USD', '-EUR', '-HKD', '-CNY'])]\n",
    "    \n",
    "#     comp_base_cols = [col for col in all_comp_cols if '_lag_' not in col]\n",
    "#     comp_lag_cols = [col for col in all_comp_cols if '_lag_' in col]\n",
    "    \n",
    "#     # Detrend base competitor prices\n",
    "#     for col in comp_base_cols:\n",
    "#         if col in df_processed.columns:\n",
    "#             df_processed[f'{col}_detrended'] = detrend_series(df_processed[col], window=30)\n",
    "    \n",
    "#     # Detrend competitor lags\n",
    "#     for col in comp_lag_cols:\n",
    "#         if col in df_processed.columns:\n",
    "#             df_processed[f'{col}_detrended'] = detrend_series(df_processed[col], window=30)\n",
    "    \n",
    "#     # Detrend own price lags\n",
    "#     for lag in [1, 2, 3, 4, 5]:\n",
    "#         lag_col = f'base_rate_lag_{lag}'\n",
    "#         if lag_col in df_processed.columns:\n",
    "#             df_processed[f'{lag_col}_detrended'] = detrend_series(df_processed[lag_col], window=30)\n",
    "    \n",
    "#     # Feature columns\n",
    "#     feature_cols = []\n",
    "    \n",
    "#     detrended_comp_base = [f'{col}_detrended' for col in comp_base_cols \n",
    "#                           if f'{col}_detrended' in df_processed.columns]\n",
    "#     feature_cols.extend(detrended_comp_base)\n",
    "    \n",
    "#     detrended_comp_lags = [f'{col}_detrended' for col in comp_lag_cols \n",
    "#                           if f'{col}_detrended' in df_processed.columns]\n",
    "#     feature_cols.extend(detrended_comp_lags)\n",
    "    \n",
    "#     detrended_own_lags = [f'base_rate_lag_{i}_detrended' for i in range(1, 6) \n",
    "#                          if f'base_rate_lag_{i}_detrended' in df_processed.columns]\n",
    "#     feature_cols.extend(detrended_own_lags)\n",
    "    \n",
    "#     temporal_cols = ['day_of_week', 'month', 'is_weekend', 'is_peak_season', \n",
    "#                     'week_of_year', 'quarter', 'is_holiday_period', 'day_of_year',\n",
    "#                     'sin_day_of_week', 'cos_day_of_week', 'sin_month', 'cos_month',\n",
    "#                     'sin_day_of_year', 'cos_day_of_year']\n",
    "#     temporal_cols = [col for col in temporal_cols if col in df_processed.columns]\n",
    "#     feature_cols.extend(temporal_cols)\n",
    "    \n",
    "#     return df_processed, feature_cols\n",
    "\n",
    "# def train_all_models_hotel(hotel_id):\n",
    "#     \"\"\"Train all quantile-normalized models for a single hotel\"\"\"\n",
    "#     result = {\n",
    "#         'hotel_id': hotel_id,\n",
    "#         'status': 'training',\n",
    "#         'models': {}\n",
    "#     }\n",
    "    \n",
    "#     try:\n",
    "#         data_file = processed_data_path / f'{hotel_id}_lagged_dataset.csv'\n",
    "        \n",
    "#         if not data_file.exists():\n",
    "#             result['status'] = 'missing_file'\n",
    "#             return result\n",
    "        \n",
    "#         df = pd.read_csv(data_file)\n",
    "#         df['date'] = pd.to_datetime(df['date'])\n",
    "#         df = df.sort_values('date').reset_index(drop=True)\n",
    "        \n",
    "#         if len(df) < 150:\n",
    "#             result['status'] = 'insufficient_data'\n",
    "#             return result\n",
    "        \n",
    "#         # Prepare features with detrending\n",
    "#         df_processed, feature_cols = prepare_features_quantile(df)\n",
    "        \n",
    "#         if len(feature_cols) == 0:\n",
    "#             result['status'] = 'no_features'\n",
    "#             return result\n",
    "        \n",
    "#         result['n_features'] = len(feature_cols)\n",
    "        \n",
    "#         # Split data (percentage-based)\n",
    "#         n_rows = len(df_processed)\n",
    "#         train_end_idx = int(n_rows * TRAIN_PCT)\n",
    "#         val_end_idx = int(n_rows * (TRAIN_PCT + VAL_PCT))\n",
    "        \n",
    "#         train_end_date = df_processed.iloc[train_end_idx - 1]['date']\n",
    "#         val_end_date = df_processed.iloc[val_end_idx - 1]['date']\n",
    "        \n",
    "#         train_mask = df_processed['date'] <= train_end_date\n",
    "#         val_mask = (df_processed['date'] > train_end_date) & (df_processed['date'] <= val_end_date)\n",
    "#         test_mask = df_processed['date'] > val_end_date\n",
    "        \n",
    "#         df_train = df_processed[train_mask].copy()\n",
    "#         df_val = df_processed[val_mask].copy()\n",
    "#         df_test = df_processed[test_mask].copy()\n",
    "        \n",
    "#         if len(df_train) < 30 or len(df_val) < 10 or len(df_test) < 10:\n",
    "#             result['status'] = 'insufficient_split_data'\n",
    "#             return result\n",
    "        \n",
    "#         # Store split info\n",
    "#         result['split_info'] = {\n",
    "#             'train_start': str(df_train['date'].min()),\n",
    "#             'train_end': str(df_train['date'].max()),\n",
    "#             'train_rows': len(df_train),\n",
    "#             'val_start': str(df_val['date'].min()),\n",
    "#             'val_end': str(df_val['date'].max()),\n",
    "#             'val_rows': len(df_val),\n",
    "#             'test_start': str(df_test['date'].min()),\n",
    "#             'test_end': str(df_test['date'].max()),\n",
    "#             'test_rows': len(df_test)\n",
    "#         }\n",
    "        \n",
    "#         # Prepare data\n",
    "#         X_train = df_train[feature_cols].fillna(0)\n",
    "#         y_train = df_train['base_rate'].fillna(method='ffill').fillna(method='bfill')\n",
    "        \n",
    "#         X_val = df_val[feature_cols].fillna(0)\n",
    "#         y_val = df_val['base_rate'].fillna(method='ffill').fillna(method='bfill')\n",
    "        \n",
    "#         X_test = df_test[feature_cols].fillna(0)\n",
    "#         y_test = df_test['base_rate'].fillna(method='ffill').fillna(method='bfill')\n",
    "        \n",
    "#         # Apply Quantile Transformation\n",
    "#         # output='normal' maps to Gaussian distribution\n",
    "#         # n_quantiles should be <= n_samples, use min of 1000 or train size\n",
    "#         n_quantiles = min(1000, len(X_train))\n",
    "        \n",
    "#         quantile_transformer = QuantileTransformer(\n",
    "#             n_quantiles=n_quantiles,\n",
    "#             output_distribution='normal',\n",
    "#             random_state=42\n",
    "#         )\n",
    "        \n",
    "#         # Fit on training data only\n",
    "#         X_train_quantile = quantile_transformer.fit_transform(X_train)\n",
    "#         X_val_quantile = quantile_transformer.transform(X_val)\n",
    "#         X_test_quantile = quantile_transformer.transform(X_test)\n",
    "        \n",
    "#         # Train all models\n",
    "#         for model_name, model in MODELS.items():\n",
    "#             try:\n",
    "#                 model.fit(X_train_quantile, y_train)\n",
    "                \n",
    "#                 # Predictions\n",
    "#                 y_train_pred = model.predict(X_train_quantile)\n",
    "#                 y_val_pred = model.predict(X_val_quantile)\n",
    "#                 y_test_pred = model.predict(X_test_quantile)\n",
    "                \n",
    "#                 # Calculate metrics\n",
    "#                 result['models'][model_name] = {\n",
    "#                     'train_r2': float(r2_score(y_train, y_train_pred)),\n",
    "#                     'train_rmse': float(np.sqrt(mean_squared_error(y_train, y_train_pred))),\n",
    "#                     'val_r2': float(r2_score(y_val, y_val_pred)),\n",
    "#                     'val_rmse': float(np.sqrt(mean_squared_error(y_val, y_val_pred))),\n",
    "#                     'test_r2': float(r2_score(y_test, y_test_pred)),\n",
    "#                     'test_rmse': float(np.sqrt(mean_squared_error(y_test, y_test_pred))),\n",
    "#                     'test_mae': float(mean_absolute_error(y_test, y_test_pred)),\n",
    "#                     'train_test_gap': float(r2_score(y_train, y_train_pred) - r2_score(y_test, y_test_pred))\n",
    "#                 }\n",
    "                \n",
    "#                 # Save predictions for best model (Ridge_100)\n",
    "#                 if model_name == 'Ridge_100':\n",
    "#                     predictions_df = pd.DataFrame({\n",
    "#                         'date': df_test['date'],\n",
    "#                         'actual_price': y_test,\n",
    "#                         'predicted_price': y_test_pred,\n",
    "#                         'error': y_test - y_test_pred,\n",
    "#                         'abs_error': np.abs(y_test - y_test_pred),\n",
    "#                         'pct_error': 100 * (y_test - y_test_pred) / y_test\n",
    "#                     })\n",
    "#                     predictions_df.to_csv(output_path / f'{hotel_id}_quantile_ridge100_predictions.csv', index=False)\n",
    "                \n",
    "#             except Exception as e:\n",
    "#                 result['models'][model_name] = {\n",
    "#                     'error': str(e)\n",
    "#                 }\n",
    "        \n",
    "#         result['status'] = 'success'\n",
    "#         return result\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         result['status'] = 'error'\n",
    "#         result['error'] = str(e)\n",
    "#         return result\n",
    "\n",
    "# # Train all hotels\n",
    "# print(\"\\nTraining quantile-normalized models with strong regularization...\")\n",
    "# print(\"-\" * 100)\n",
    "\n",
    "# all_results = {}\n",
    "# for idx, hotel_id in enumerate(hotel_list, 1):\n",
    "#     print(f\"[{idx}/{len(hotel_list)}] {hotel_id}...\", end='\\r')\n",
    "#     result = train_all_models_hotel(hotel_id)\n",
    "#     all_results[hotel_id] = result\n",
    "\n",
    "# successful = [h for h, r in all_results.items() if r['status'] == 'success']\n",
    "# print(f\"\\n\\nSuccessfully trained: {len(successful)}/{len(hotel_list)} hotels\")\n",
    "\n",
    "# # Save results\n",
    "# with open(output_path / 'quantile_normalization_results.json', 'w') as f:\n",
    "#     json.dump(all_results, f, indent=2)\n",
    "\n",
    "# # Generate comparison report\n",
    "# print(\"\\n\" + \"=\"*100)\n",
    "# print(\"QUANTILE NORMALIZATION + STRONG REGULARIZATION REPORT\")\n",
    "# print(\"=\"*100)\n",
    "\n",
    "# if len(successful) > 0:\n",
    "#     # Compare models\n",
    "#     model_comparison = {}\n",
    "    \n",
    "#     for model_name in MODELS.keys():\n",
    "#         test_r2s = []\n",
    "#         val_r2s = []\n",
    "#         train_r2s = []\n",
    "#         gaps = []\n",
    "        \n",
    "#         for hotel_id in successful:\n",
    "#             if model_name in all_results[hotel_id]['models']:\n",
    "#                 model_result = all_results[hotel_id]['models'][model_name]\n",
    "#                 if 'test_r2' in model_result:\n",
    "#                     test_r2s.append(model_result['test_r2'])\n",
    "#                     val_r2s.append(model_result['val_r2'])\n",
    "#                     train_r2s.append(model_result['train_r2'])\n",
    "#                     gaps.append(model_result['train_test_gap'])\n",
    "        \n",
    "#         if len(test_r2s) > 0:\n",
    "#             test_r2s_sorted = sorted(test_r2s)\n",
    "#             model_comparison[model_name] = {\n",
    "#                 'median_test_r2': np.median(test_r2s),\n",
    "#                 'mean_test_r2': np.mean(test_r2s),\n",
    "#                 'median_val_r2': np.median(val_r2s),\n",
    "#                 'median_train_r2': np.median(train_r2s),\n",
    "#                 'median_gap': np.median(gaps),\n",
    "#                 'n_excellent': sum(1 for r in test_r2s if r > 0.70),\n",
    "#                 'n_good': sum(1 for r in test_r2s if 0.40 < r <= 0.70),\n",
    "#                 'n_moderate': sum(1 for r in test_r2s if 0.20 < r <= 0.40),\n",
    "#                 'n_poor': sum(1 for r in test_r2s if r <= 0.20)\n",
    "#             }\n",
    "    \n",
    "#     # Sort by median test R²\n",
    "#     sorted_models = sorted(model_comparison.items(), key=lambda x: x[1]['median_test_r2'], reverse=True)\n",
    "    \n",
    "#     print(\"\\nModel Comparison (sorted by Median Test R²):\")\n",
    "#     print(\"-\" * 100)\n",
    "#     print(f\"{'Model':<20} {'Med Test R²':<15} {'Med Val R²':<15} {'Med Gap':<12} {'Excellent':<12} {'Good':<8} {'Poor':<8}\")\n",
    "#     print(\"-\" * 100)\n",
    "    \n",
    "#     for model_name, metrics in sorted_models:\n",
    "#         print(f\"{model_name:<20} {metrics['median_test_r2']:>14.4f} {metrics['median_val_r2']:>14.4f} \"\n",
    "#               f\"{metrics['median_gap']:>11.4f} {metrics['n_excellent']:>11} \"\n",
    "#               f\"{metrics['n_good']:>7} {metrics['n_poor']:>7}\")\n",
    "    \n",
    "#     # Best model\n",
    "#     best_model = sorted_models[0][0]\n",
    "#     print(f\"\\nBest Model: {best_model}\")\n",
    "#     print(f\"Median Test R²: {sorted_models[0][1]['median_test_r2']:.4f}\")\n",
    "#     print(f\"Overfitting Gap: {sorted_models[0][1]['median_gap']:.4f}\")\n",
    "    \n",
    "#     # Top performers\n",
    "#     print(\"\\n\" + \"=\"*100)\n",
    "#     print(\"TOP 10 HOTELS (by Ridge_100 test R²)\")\n",
    "#     print(\"=\"*100)\n",
    "    \n",
    "#     top_hotels = []\n",
    "#     for hotel_id in successful:\n",
    "#         if 'Ridge_100' in all_results[hotel_id]['models']:\n",
    "#             model_result = all_results[hotel_id]['models']['Ridge_100']\n",
    "#             if 'test_r2' in model_result:\n",
    "#                 top_hotels.append({\n",
    "#                     'hotel_id': hotel_id,\n",
    "#                     'test_r2': model_result['test_r2'],\n",
    "#                     'val_r2': model_result['val_r2'],\n",
    "#                     'train_r2': model_result['train_r2'],\n",
    "#                     'gap': model_result['train_test_gap'],\n",
    "#                     'test_rmse': model_result['test_rmse']\n",
    "#                 })\n",
    "    \n",
    "#     top_hotels.sort(key=lambda x: x['test_r2'], reverse=True)\n",
    "    \n",
    "#     print(f\"{'Hotel':<12} {'Test R²':<12} {'Val R²':<12} {'Train R²':<12} {'Gap':<12} {'RMSE':<12}\")\n",
    "#     print(\"-\" * 100)\n",
    "#     for h in top_hotels[:10]:\n",
    "#         print(f\"{h['hotel_id']:<12} {h['test_r2']:>11.4f} {h['val_r2']:>11.4f} \"\n",
    "#               f\"{h['train_r2']:>11.4f} {h['gap']:>11.4f} {h['test_rmse']:>11.2f}\")\n",
    "    \n",
    "#     # Create summary CSV\n",
    "#     summary_data = []\n",
    "#     for hotel_id in successful:\n",
    "#         hotel_row = {'hotel_id': hotel_id}\n",
    "#         for model_name in MODELS.keys():\n",
    "#             if model_name in all_results[hotel_id]['models']:\n",
    "#                 model_result = all_results[hotel_id]['models'][model_name]\n",
    "#                 if 'test_r2' in model_result:\n",
    "#                     hotel_row[f'{model_name}_test_r2'] = model_result['test_r2']\n",
    "#                     hotel_row[f'{model_name}_val_r2'] = model_result['val_r2']\n",
    "#                     hotel_row[f'{model_name}_gap'] = model_result['train_test_gap']\n",
    "#         summary_data.append(hotel_row)\n",
    "    \n",
    "#     summary_df = pd.DataFrame(summary_data)\n",
    "#     summary_df.to_csv(output_path / 'quantile_normalization_summary.csv', index=False)\n",
    "    \n",
    "#     print(f\"\\nFiles saved to: {output_path}/\")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*100)\n",
    "# print(\"SUMMARY\")\n",
    "# print(\"=\"*100)\n",
    "# print(f\"Successfully trained: {len(successful)}/{len(hotel_list)} hotels\")\n",
    "# print(f\"Using QuantileTransformer (output='normal') + 30-day detrending\")\n",
    "# print(f\"Testing 4 regularization methods\")\n",
    "# print(\"\\nQuantile Normalization transforms features to Gaussian distribution\")\n",
    "# print(\"This handles outliers and makes features comparable across scales\")\n",
    "# print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9809ff89",
   "metadata": {},
   "source": [
    "# With Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d623ed42",
   "metadata": {},
   "source": [
    "## LR with past data - Iteration1 - Detrending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ffe7f38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T06:37:01.612917Z",
     "start_time": "2025-10-21T06:36:56.155149Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================================================\n",
      "LINEAR REGRESSION + DETRENDING - OUT-OF-SAMPLE CROSS-VALIDATION\n",
      "============================================================================================================================================\n",
      "Model: Ridge Regression (α=100.0)\n",
      "Preprocessing: 30-day detrending + StandardScaler\n",
      "Features: Competitor prices + temporal features ONLY (NO own price lags)\n",
      "CV Strategy: Expanding window (min 300 days, test window 50 days)\n",
      "Testing 44 hotels\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Processing hotels with expanding window CV...\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[44/44] Hotel_44...\n",
      "\n",
      "Successfully processed: 34/44 hotels\n",
      "\n",
      "============================================================================================================================================\n",
      "DETAILED RESULTS - OUT-OF-SAMPLE CROSS-VALIDATION\n",
      "============================================================================================================================================\n",
      "\n",
      "1. TOP 10 HOTELS - FOLD-BY-FOLD METRICS\n",
      "============================================================================================================================================\n",
      "\n",
      "HOTEL_35\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Observations: 393, Features: 50, CV Folds: 1\n",
      "\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Train MAE   Test MAE    Train MAPE%  Test MAPE%   Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.7802     0.7159       27.96       19.14      21.05      15.58        9.60        7.43    0.0644\n",
      "\n",
      "CV Summary: Mean Train R²=0.7802, Mean Test R²=0.7159, Std Test R²=0.0000, Mean Gap=0.0644\n",
      "\n",
      "HOTEL_40\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Observations: 441, Features: 45, CV Folds: 2\n",
      "\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Train MAE   Test MAE    Train MAPE%  Test MAPE%   Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.7199     0.5890       18.52       21.99      14.42      16.97        5.24        5.32    0.1309\n",
      "2      350          50              0.7642     0.7046       18.18       18.35      14.09      13.56        5.06        4.70    0.0595\n",
      "\n",
      "CV Summary: Mean Train R²=0.7420, Mean Test R²=0.6468, Std Test R²=0.0578, Mean Gap=0.0952\n",
      "\n",
      "HOTEL_06\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Observations: 373, Features: 40, CV Folds: 1\n",
      "\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Train MAE   Test MAE    Train MAPE%  Test MAPE%   Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.8093     0.6231       34.24       23.37      24.32      18.37        7.43        6.77    0.1862\n",
      "\n",
      "CV Summary: Mean Train R²=0.8093, Mean Test R²=0.6231, Std Test R²=0.0000, Mean Gap=0.1862\n",
      "\n",
      "HOTEL_27\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Observations: 425, Features: 35, CV Folds: 2\n",
      "\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Train MAE   Test MAE    Train MAPE%  Test MAPE%   Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.8154     0.5627       39.71       55.39      25.19      43.47       11.01       12.25    0.2527\n",
      "2      350          50              0.8447     0.6646       40.89       46.11      27.69      36.83       11.46       11.39    0.1800\n",
      "\n",
      "CV Summary: Mean Train R²=0.8300, Mean Test R²=0.6137, Std Test R²=0.0510, Mean Gap=0.2164\n",
      "\n",
      "HOTEL_41\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Observations: 425, Features: 40, CV Folds: 2\n",
      "\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Train MAE   Test MAE    Train MAPE%  Test MAPE%   Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.7794     0.4150       28.11       59.14      20.10      42.10        6.84       10.53    0.3643\n",
      "2      350          50              0.7718     0.7681       33.11       21.35      23.12      14.63        7.42        4.23    0.0037\n",
      "\n",
      "CV Summary: Mean Train R²=0.7756, Mean Test R²=0.5916, Std Test R²=0.1766, Mean Gap=0.1840\n",
      "\n",
      "HOTEL_03\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Observations: 396, Features: 55, CV Folds: 1\n",
      "\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Train MAE   Test MAE    Train MAPE%  Test MAPE%   Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.8805     0.5232       57.35       53.85      40.71      40.49       11.76       16.62    0.3573\n",
      "\n",
      "CV Summary: Mean Train R²=0.8805, Mean Test R²=0.5232, Std Test R²=0.0000, Mean Gap=0.3573\n",
      "\n",
      "HOTEL_02\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Observations: 425, Features: 30, CV Folds: 2\n",
      "\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Train MAE   Test MAE    Train MAPE%  Test MAPE%   Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.6710     0.5810        8.24        6.45       5.29       5.66        5.86        6.68    0.0901\n",
      "2      350          50              0.6741     0.4535        7.90       13.83       5.27      12.16        5.92       13.59    0.2206\n",
      "\n",
      "CV Summary: Mean Train R²=0.6726, Mean Test R²=0.5172, Std Test R²=0.0637, Mean Gap=0.1553\n",
      "\n",
      "HOTEL_22\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Observations: 670, Features: 55, CV Folds: 7\n",
      "\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Train MAE   Test MAE    Train MAPE%  Test MAPE%   Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.6890     0.5369       16.83       12.79      12.74      10.07        6.28        4.57    0.1521\n",
      "2      350          50              0.7008     0.5186       16.19       10.20      12.15       8.19        5.93        3.83    0.1822\n",
      "3      400          50              0.7045     0.4047       15.41       10.39      11.43       8.08        5.56        3.77    0.2998\n",
      "4      450          50              0.7133     0.7524       14.72        6.70      10.74       5.46        5.21        2.49   -0.0391\n",
      "5      500          50              0.7229     0.6446       14.06        8.03      10.10       6.35        4.89        2.93    0.0783\n",
      "6      550          50              0.7274    -0.3650       13.58       20.98       9.63      15.60        4.64        7.12    1.0924\n",
      "7      600          50              0.7165     0.4504       13.69       13.31       9.52      10.38        4.55        4.70    0.2661\n",
      "\n",
      "CV Summary: Mean Train R²=0.7106, Mean Test R²=0.4204, Std Test R²=0.3384, Mean Gap=0.2903\n",
      "\n",
      "HOTEL_37\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Observations: 393, Features: 35, CV Folds: 1\n",
      "\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Train MAE   Test MAE    Train MAPE%  Test MAPE%   Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.6082     0.3915       20.40       32.41      11.80      25.74        6.90       14.30    0.2167\n",
      "\n",
      "CV Summary: Mean Train R²=0.6082, Mean Test R²=0.3915, Std Test R²=0.0000, Mean Gap=0.2167\n",
      "\n",
      "HOTEL_25\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Observations: 669, Features: 60, CV Folds: 7\n",
      "\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Train MAE   Test MAE    Train MAPE%  Test MAPE%   Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.7982     0.0740       21.97       36.35      16.61      28.72       10.37       16.14    0.7242\n",
      "2      350          50              0.7660     0.4622       23.08       20.45      17.72      15.10       10.98        8.36    0.3038\n",
      "3      400          50              0.7584    -0.6070       22.50       17.17      17.12      14.20       10.55        9.15    1.3655\n",
      "4      450          50              0.7495     0.6878       21.85       10.88      16.54       8.76       10.31        5.09    0.0617\n",
      "5      500          50              0.7509     0.7207       20.92       11.75      15.66       8.48        9.74        4.59    0.0302\n",
      "6      550          50              0.7556     0.5590       20.14       17.12      14.89      12.82        9.21        6.17    0.1966\n",
      "7      600          50              0.7709     0.7822       19.69       10.95      14.47       8.11        8.85        4.28   -0.0113\n",
      "\n",
      "CV Summary: Mean Train R²=0.7642, Mean Test R²=0.3827, Std Test R²=0.4597, Mean Gap=0.3815\n",
      "\n",
      "============================================================================================================================================\n",
      "2. SUMMARY TABLE - ALL HOTELS\n",
      "============================================================================================================================================\n",
      "\n",
      "Hotel        Obs      Features   Folds   Mean Train R²   Mean Test R²    Std Test R²   Mean Gap    \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Hotel_35     393      50         1               0.7802         0.7159       0.0000      0.0644\n",
      "Hotel_40     441      45         2               0.7420         0.6468       0.0578      0.0952\n",
      "Hotel_06     373      40         1               0.8093         0.6231       0.0000      0.1862\n",
      "Hotel_27     425      35         2               0.8300         0.6137       0.0510      0.2164\n",
      "Hotel_41     425      40         2               0.7756         0.5916       0.1766      0.1840\n",
      "Hotel_03     396      55         1               0.8805         0.5232       0.0000      0.3573\n",
      "Hotel_02     425      30         2               0.6726         0.5172       0.0637      0.1553\n",
      "Hotel_22     670      55         7               0.7106         0.4204       0.3384      0.2903\n",
      "Hotel_37     393      35         1               0.6082         0.3915       0.0000      0.2167\n",
      "Hotel_25     669      60         7               0.7642         0.3827       0.4597      0.3815\n",
      "Hotel_04     620      30         6               0.6097         0.3600       0.2086      0.2496\n",
      "Hotel_38     357      45         1               0.8722         0.3336       0.0000      0.5386\n",
      "Hotel_12     439      55         2               0.4890         0.3173       0.1713      0.1717\n",
      "Hotel_05     675      60         7               0.9118         0.3026       0.3935      0.6092\n",
      "Hotel_18     369      40         1               0.4774         0.2615       0.0000      0.2159\n",
      "Hotel_33     675      40         7               0.4362         0.0997       0.6545      0.3365\n",
      "Hotel_21     640      60         6               0.5993         0.0831       0.2581      0.5162\n",
      "Hotel_07     675      50         7               0.7878         0.0486       0.7604      0.7392\n",
      "Hotel_39     350      60         1               0.4599        -0.0026       0.0000      0.4625\n",
      "Hotel_32     597      35         5               0.5385        -0.0346       0.1352      0.5730\n",
      "Hotel_36     675      40         7               0.8801        -0.0367       0.4832      0.9167\n",
      "Hotel_10     602      55         6               0.8020        -0.0798       0.1783      0.8818\n",
      "Hotel_34     603      45         6               0.7381        -0.0812       0.4515      0.8193\n",
      "Hotel_13     615      55         6               0.8618        -0.2365       0.7871      1.0982\n",
      "Hotel_15     400      35         2               0.8975        -0.2566       0.0692      1.1540\n",
      "Hotel_26     670      60         7               0.7022        -0.3107       1.1692      1.0129\n",
      "Hotel_23     676      60         7               0.7246        -0.3360       0.6709      1.0606\n",
      "Hotel_31     676      40         7               0.5930        -0.3558       1.3778      0.9488\n",
      "Hotel_30     675      25         7               0.5366        -0.6636       1.7656      1.2002\n",
      "Hotel_17     593      50         5               0.6526        -0.6899       2.4797      1.3426\n",
      "Hotel_24     609      60         6               0.5788        -1.6383       2.3006      2.2171\n",
      "Hotel_28     595      40         5               0.7468        -1.7920       2.0408      2.5387\n",
      "Hotel_14     676      35         7               0.6800        -3.3600       5.5725      4.0400\n",
      "Hotel_01     554      35         5               0.8921        -5.7821      10.6410      6.6742\n",
      "\n",
      "============================================================================================================================================\n",
      "3. PERFORMANCE DISTRIBUTION\n",
      "============================================================================================================================================\n",
      "\n",
      "Category             Count      Percentage  \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Excellent (R²>0.40)  8                23.5%\n",
      "Good (0.25-0.40)     7                20.6%\n",
      "Acceptable (0.15-0.25) 0                 0.0%\n",
      "Poor (R²<0.15)       19               55.9%\n",
      "TOTAL                34              100.0%\n",
      "\n",
      "============================================================================================================================================\n",
      "4. AGGREGATE STATISTICS\n",
      "============================================================================================================================================\n",
      "\n",
      "Mean Test R²:     -0.2478\n",
      "Median Test R²:   0.0659\n",
      "Std Test R²:      1.2545\n",
      "\n",
      "Mean Train R²:    0.7071\n",
      "Median Train R²:  0.7314\n",
      "\n",
      "Mean Overfitting Gap: 0.9549\n",
      "Median Overfitting Gap: 0.5558\n",
      "\n",
      "============================================================================================================================================\n",
      "5. EXPORTING RESULTS\n",
      "============================================================================================================================================\n",
      "\n",
      "✓ Hotel summary: ..\\data\\full-data\\linear_detrending_oos_cv_clean\\hotel_summary.csv\n",
      "✓ Fold details: ..\\data\\full-data\\linear_detrending_oos_cv_clean\\fold_details.csv\n",
      "✓ Individual results: ..\\data\\full-data\\linear_detrending_oos_cv_clean\\[hotel_id]_cv_results.json\n",
      "\n",
      "============================================================================================================================================\n",
      "PROCESSING COMPLETE\n",
      "============================================================================================================================================\n",
      "Successful: 34/44 hotels\n",
      "Results saved to: ..\\data\\full-data\\linear_detrending_oos_cv_clean/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\"\"\"\n",
    "LINEAR + DETRENDING - OUT-OF-SAMPLE CROSS-VALIDATION\n",
    "=====================================================\n",
    "ONLY competitor prices + temporal features (NO own price lags)\n",
    "Expanding window strategy\n",
    "\"\"\"\n",
    "\n",
    "# Configuration\n",
    "processed_data_path = Path('../data/full-data/processed')\n",
    "output_path = Path('../data/full-data/linear_detrending_oos_cv_clean')\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "mapping_df = pd.read_csv('../data/full-data/hotel_mapping.csv')\n",
    "hotel_list = mapping_df['masked_id'].tolist()\n",
    "\n",
    "# CV Configuration\n",
    "MIN_TRAIN_DAYS = 300\n",
    "TEST_WINDOW = 50\n",
    "TREND_WINDOW = 30\n",
    "ALPHA = 100.0\n",
    "\n",
    "print(\"=\"*140)\n",
    "print(\"LINEAR REGRESSION + DETRENDING - OUT-OF-SAMPLE CROSS-VALIDATION\")\n",
    "print(\"=\"*140)\n",
    "print(f\"Model: Ridge Regression (α={ALPHA})\")\n",
    "print(f\"Preprocessing: 30-day detrending + StandardScaler\")\n",
    "print(f\"Features: Competitor prices + temporal features ONLY (NO own price lags)\")\n",
    "print(f\"CV Strategy: Expanding window (min {MIN_TRAIN_DAYS} days, test window {TEST_WINDOW} days)\")\n",
    "print(f\"Testing {len(hotel_list)} hotels\")\n",
    "print(\"-\" * 140)\n",
    "\n",
    "def detrend_series(series, window=30):\n",
    "    \"\"\"Detrend using rolling mean subtraction\"\"\"\n",
    "    trend = series.rolling(window=window, min_periods=1, center=False).mean()\n",
    "    detrended = series - trend\n",
    "    return detrended, trend\n",
    "\n",
    "def prepare_features(df):\n",
    "    \"\"\"Prepare features - ONLY competitor prices + temporal, NO own lags\"\"\"\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Get all competitor columns (base prices and lags)\n",
    "    all_comp_cols = [col for col in df.columns \n",
    "                     if any(currency in col for currency in ['-USD', '-EUR', '-HKD', '-CNY'])]\n",
    "    \n",
    "    comp_base_cols = [col for col in all_comp_cols if '_lag_' not in col]\n",
    "    comp_lag_cols = [col for col in all_comp_cols if '_lag_' in col]\n",
    "    \n",
    "    # Detrend base competitor prices\n",
    "    for col in comp_base_cols:\n",
    "        if col in df_processed.columns:\n",
    "            detrended, _ = detrend_series(df_processed[col], window=TREND_WINDOW)\n",
    "            df_processed[f'{col}_detrended'] = detrended\n",
    "    \n",
    "    # Detrend competitor lags\n",
    "    for col in comp_lag_cols:\n",
    "        if col in df_processed.columns:\n",
    "            detrended, _ = detrend_series(df_processed[col], window=TREND_WINDOW)\n",
    "            df_processed[f'{col}_detrended'] = detrended\n",
    "    \n",
    "    # Build feature list - ONLY COMPETITORS + TEMPORAL\n",
    "    feature_cols = []\n",
    "    \n",
    "    # Detrended competitor lags\n",
    "    detrended_comp_lags = [f'{col}_detrended' for col in comp_lag_cols \n",
    "                          if f'{col}_detrended' in df_processed.columns]\n",
    "    feature_cols.extend(detrended_comp_lags)\n",
    "    \n",
    "    # Temporal features only\n",
    "    temporal_cols = ['day_of_week', 'month', 'is_weekend', 'is_peak_season', \n",
    "                    'week_of_year', 'quarter', 'is_holiday_period', 'day_of_year',\n",
    "                    'sin_day_of_week', 'cos_day_of_week', 'sin_month', 'cos_month',\n",
    "                    'sin_day_of_year', 'cos_day_of_year']\n",
    "    temporal_cols = [col for col in temporal_cols if col in df_processed.columns]\n",
    "    feature_cols.extend(temporal_cols)\n",
    "    \n",
    "    # Target - detrend base_rate\n",
    "    y_original = df_processed['base_rate']\n",
    "    y_detrended, y_trend = detrend_series(y_original, window=TREND_WINDOW)\n",
    "    \n",
    "    # Get feature matrix\n",
    "    X = df_processed[feature_cols]\n",
    "    \n",
    "    return X, y_detrended, y_trend, y_original, feature_cols\n",
    "\n",
    "def expanding_window_cv_splits(df, min_train_days, test_window):\n",
    "    \"\"\"Create expanding window splits\"\"\"\n",
    "    n = len(df)\n",
    "    splits = []\n",
    "    train_end = min_train_days\n",
    "    \n",
    "    while train_end + test_window <= n:\n",
    "        splits.append({\n",
    "            'train_idx': list(range(0, train_end)),\n",
    "            'test_idx': list(range(train_end, min(train_end + test_window, n)))\n",
    "        })\n",
    "        train_end += test_window\n",
    "    \n",
    "    return splits\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate all metrics\"\"\"\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    # MAPE\n",
    "    mask = y_true > 0\n",
    "    if mask.sum() > 0:\n",
    "        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    else:\n",
    "        mape = np.nan\n",
    "    \n",
    "    return {\n",
    "        'r2': float(r2),\n",
    "        'rmse': float(rmse),\n",
    "        'mae': float(mae),\n",
    "        'mape': float(mape)\n",
    "    }\n",
    "\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test, \n",
    "                       y_trend_train, y_trend_test, \n",
    "                       y_original_train, y_original_test, fold_num):\n",
    "    \"\"\"Train Ridge model and calculate train + test metrics\"\"\"\n",
    "    \n",
    "    # Standardize\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train model\n",
    "    model = Ridge(alpha=ALPHA, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # TRAIN PREDICTIONS\n",
    "    y_pred_train_detrended = model.predict(X_train_scaled)\n",
    "    y_pred_train_absolute = y_trend_train.values + y_pred_train_detrended\n",
    "    train_metrics = calculate_metrics(y_original_train.values, y_pred_train_absolute)\n",
    "    \n",
    "    # TEST PREDICTIONS\n",
    "    y_pred_test_detrended = model.predict(X_test_scaled)\n",
    "    y_pred_test_absolute = y_trend_test.values + y_pred_test_detrended\n",
    "    test_metrics = calculate_metrics(y_original_test.values, y_pred_test_absolute)\n",
    "    \n",
    "    return {\n",
    "        'fold': fold_num,\n",
    "        'train_size': len(X_train),\n",
    "        'test_size': len(X_test),\n",
    "        'train_r2': train_metrics['r2'],\n",
    "        'train_rmse': train_metrics['rmse'],\n",
    "        'train_mae': train_metrics['mae'],\n",
    "        'train_mape': train_metrics['mape'],\n",
    "        'test_r2': test_metrics['r2'],\n",
    "        'test_rmse': test_metrics['rmse'],\n",
    "        'test_mae': test_metrics['mae'],\n",
    "        'test_mape': test_metrics['mape'],\n",
    "        'overfitting_gap': train_metrics['r2'] - test_metrics['r2']\n",
    "    }\n",
    "\n",
    "def process_hotel(hotel_id):\n",
    "    \"\"\"Process single hotel with expanding window CV\"\"\"\n",
    "    \n",
    "    try:\n",
    "        data_file = processed_data_path / f'{hotel_id}_lagged_dataset.csv'\n",
    "        \n",
    "        if not data_file.exists():\n",
    "            return {'hotel_id': hotel_id, 'status': 'missing_file'}\n",
    "        \n",
    "        df = pd.read_csv(data_file)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df.sort_values('date').reset_index(drop=True)\n",
    "        \n",
    "        if len(df) < MIN_TRAIN_DAYS + TEST_WINDOW:\n",
    "            return {'hotel_id': hotel_id, 'status': 'insufficient_data'}\n",
    "        \n",
    "        # Prepare features\n",
    "        X_all, y_detrended, y_trend, y_original, feature_cols = prepare_features(df)\n",
    "        \n",
    "        if len(feature_cols) == 0:\n",
    "            return {'hotel_id': hotel_id, 'status': 'no_features'}\n",
    "        \n",
    "        # Create CV splits\n",
    "        cv_splits = expanding_window_cv_splits(df, MIN_TRAIN_DAYS, TEST_WINDOW)\n",
    "        \n",
    "        if len(cv_splits) == 0:\n",
    "            return {'hotel_id': hotel_id, 'status': 'insufficient_cv_data'}\n",
    "        \n",
    "        # Run CV\n",
    "        cv_results = []\n",
    "        for fold_idx, split in enumerate(cv_splits, 1):\n",
    "            X_train = X_all.iloc[split['train_idx']]\n",
    "            y_train = y_detrended.iloc[split['train_idx']]\n",
    "            X_test = X_all.iloc[split['test_idx']]\n",
    "            y_test = y_detrended.iloc[split['test_idx']]\n",
    "            y_trend_train = y_trend.iloc[split['train_idx']]\n",
    "            y_trend_test = y_trend.iloc[split['test_idx']]\n",
    "            y_original_train = y_original.iloc[split['train_idx']]\n",
    "            y_original_test = y_original.iloc[split['test_idx']]\n",
    "            \n",
    "            fold_result = train_and_evaluate(\n",
    "                X_train, y_train, X_test, y_test,\n",
    "                y_trend_train, y_trend_test,\n",
    "                y_original_train, y_original_test,\n",
    "                fold_idx\n",
    "            )\n",
    "            cv_results.append(fold_result)\n",
    "        \n",
    "        # Calculate summary statistics\n",
    "        train_r2_scores = [r['train_r2'] for r in cv_results]\n",
    "        test_r2_scores = [r['test_r2'] for r in cv_results]\n",
    "        \n",
    "        cv_summary = {\n",
    "            'mean_train_r2': float(np.mean(train_r2_scores)),\n",
    "            'mean_test_r2': float(np.mean(test_r2_scores)),\n",
    "            'median_test_r2': float(np.median(test_r2_scores)),\n",
    "            'std_test_r2': float(np.std(test_r2_scores)),\n",
    "            'min_test_r2': float(np.min(test_r2_scores)),\n",
    "            'max_test_r2': float(np.max(test_r2_scores)),\n",
    "            'mean_overfitting_gap': float(np.mean([r['overfitting_gap'] for r in cv_results])),\n",
    "            'mean_test_rmse': float(np.mean([r['test_rmse'] for r in cv_results])),\n",
    "            'mean_test_mape': float(np.mean([r['test_mape'] for r in cv_results]))\n",
    "        }\n",
    "        \n",
    "        result = {\n",
    "            'hotel_id': hotel_id,\n",
    "            'status': 'success',\n",
    "            'n_features': len(feature_cols),\n",
    "            'n_observations': len(df),\n",
    "            'cv_folds': len(cv_results),\n",
    "            'fold_results': cv_results,\n",
    "            'cv_summary': cv_summary\n",
    "        }\n",
    "        \n",
    "        # Save individual hotel results\n",
    "        with open(output_path / f'{hotel_id}_cv_results.json', 'w') as f:\n",
    "            json.dump(result, f, indent=2)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'hotel_id': hotel_id,\n",
    "            'status': 'error',\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "# Process all hotels\n",
    "print(\"\\nProcessing hotels with expanding window CV...\")\n",
    "print(\"-\"*140)\n",
    "\n",
    "all_results = {}\n",
    "for idx, hotel_id in enumerate(hotel_list, 1):\n",
    "    print(f\"[{idx}/{len(hotel_list)}] {hotel_id}...\", end='\\r')\n",
    "    result = process_hotel(hotel_id)\n",
    "    all_results[hotel_id] = result\n",
    "\n",
    "successful = [h for h, r in all_results.items() if r.get('status') == 'success']\n",
    "print(f\"\\n\\nSuccessfully processed: {len(successful)}/{len(hotel_list)} hotels\")\n",
    "\n",
    "# Generate detailed report\n",
    "print(\"\\n\" + \"=\"*140)\n",
    "print(\"DETAILED RESULTS - OUT-OF-SAMPLE CROSS-VALIDATION\")\n",
    "print(\"=\"*140)\n",
    "\n",
    "if len(successful) > 0:\n",
    "    # Sort by mean test R²\n",
    "    successful_sorted = sorted(successful, \n",
    "                              key=lambda h: all_results[h]['cv_summary']['mean_test_r2'], \n",
    "                              reverse=True)\n",
    "    \n",
    "    print(\"\\n1. TOP 10 HOTELS - FOLD-BY-FOLD METRICS\")\n",
    "    print(\"=\"*140)\n",
    "    \n",
    "    for hotel_id in successful_sorted[:10]:\n",
    "        result = all_results[hotel_id]\n",
    "        cv_sum = result['cv_summary']\n",
    "        \n",
    "        print(f\"\\n{hotel_id.upper()}\")\n",
    "        print(\"-\"*140)\n",
    "        print(f\"Observations: {result['n_observations']}, Features: {result['n_features']}, CV Folds: {result['cv_folds']}\")\n",
    "        print()\n",
    "        print(f\"{'Fold':<6} {'Train Size':<12} {'Test Size':<11} \"\n",
    "              f\"{'Train R²':<11} {'Test R²':<11} {'Train RMSE':<12} {'Test RMSE':<12} \"\n",
    "              f\"{'Train MAE':<11} {'Test MAE':<11} {'Train MAPE%':<12} {'Test MAPE%':<12} {'Gap':<10}\")\n",
    "        print(\"-\"*140)\n",
    "        \n",
    "        for fold in result['fold_results']:\n",
    "            print(f\"{fold['fold']:<6} {fold['train_size']:<12} {fold['test_size']:<11} \"\n",
    "                  f\"{fold['train_r2']:>10.4f} {fold['test_r2']:>10.4f} \"\n",
    "                  f\"{fold['train_rmse']:>11.2f} {fold['test_rmse']:>11.2f} \"\n",
    "                  f\"{fold['train_mae']:>10.2f} {fold['test_mae']:>10.2f} \"\n",
    "                  f\"{fold['train_mape']:>11.2f} {fold['test_mape']:>11.2f} \"\n",
    "                  f\"{fold['overfitting_gap']:>9.4f}\")\n",
    "        \n",
    "        print()\n",
    "        print(f\"CV Summary: Mean Train R²={cv_sum['mean_train_r2']:.4f}, \"\n",
    "              f\"Mean Test R²={cv_sum['mean_test_r2']:.4f}, \"\n",
    "              f\"Std Test R²={cv_sum['std_test_r2']:.4f}, \"\n",
    "              f\"Mean Gap={cv_sum['mean_overfitting_gap']:.4f}\")\n",
    "    \n",
    "    # Summary table\n",
    "    print(\"\\n\" + \"=\"*140)\n",
    "    print(\"2. SUMMARY TABLE - ALL HOTELS\")\n",
    "    print(\"=\"*140)\n",
    "    print()\n",
    "    print(f\"{'Hotel':<12} {'Obs':<8} {'Features':<10} {'Folds':<7} \"\n",
    "          f\"{'Mean Train R²':<15} {'Mean Test R²':<15} {'Std Test R²':<13} {'Mean Gap':<12}\")\n",
    "    print(\"-\"*140)\n",
    "    \n",
    "    for hotel_id in successful_sorted:\n",
    "        result = all_results[hotel_id]\n",
    "        cv_sum = result['cv_summary']\n",
    "        \n",
    "        print(f\"{hotel_id:<12} {result['n_observations']:<8} {result['n_features']:<10} {result['cv_folds']:<7} \"\n",
    "              f\"{cv_sum['mean_train_r2']:>14.4f} {cv_sum['mean_test_r2']:>14.4f} \"\n",
    "              f\"{cv_sum['std_test_r2']:>12.4f} {cv_sum['mean_overfitting_gap']:>11.4f}\")\n",
    "    \n",
    "    # Performance distribution\n",
    "    print(\"\\n\" + \"=\"*140)\n",
    "    print(\"3. PERFORMANCE DISTRIBUTION\")\n",
    "    print(\"=\"*140)\n",
    "    \n",
    "    test_r2_values = [all_results[h]['cv_summary']['mean_test_r2'] for h in successful]\n",
    "    \n",
    "    excellent = sum(1 for r2 in test_r2_values if r2 > 0.40)\n",
    "    good = sum(1 for r2 in test_r2_values if 0.25 <= r2 <= 0.40)\n",
    "    acceptable = sum(1 for r2 in test_r2_values if 0.15 <= r2 < 0.25)\n",
    "    poor = sum(1 for r2 in test_r2_values if r2 < 0.15)\n",
    "    total = len(test_r2_values)\n",
    "    \n",
    "    print()\n",
    "    print(f\"{'Category':<20} {'Count':<10} {'Percentage':<12}\")\n",
    "    print(\"-\"*140)\n",
    "    print(f\"{'Excellent (R²>0.40)':<20} {excellent:<10} {100*excellent/total:>10.1f}%\")\n",
    "    print(f\"{'Good (0.25-0.40)':<20} {good:<10} {100*good/total:>10.1f}%\")\n",
    "    print(f\"{'Acceptable (0.15-0.25)':<20} {acceptable:<10} {100*acceptable/total:>10.1f}%\")\n",
    "    print(f\"{'Poor (R²<0.15)':<20} {poor:<10} {100*poor/total:>10.1f}%\")\n",
    "    print(f\"{'TOTAL':<20} {total:<10} {100.0:>10.1f}%\")\n",
    "    \n",
    "    # Aggregate statistics\n",
    "    print(\"\\n\" + \"=\"*140)\n",
    "    print(\"4. AGGREGATE STATISTICS\")\n",
    "    print(\"=\"*140)\n",
    "    \n",
    "    print(f\"\\nMean Test R²:     {np.mean(test_r2_values):.4f}\")\n",
    "    print(f\"Median Test R²:   {np.median(test_r2_values):.4f}\")\n",
    "    print(f\"Std Test R²:      {np.std(test_r2_values):.4f}\")\n",
    "    \n",
    "    train_r2_values = [all_results[h]['cv_summary']['mean_train_r2'] for h in successful]\n",
    "    print(f\"\\nMean Train R²:    {np.mean(train_r2_values):.4f}\")\n",
    "    print(f\"Median Train R²:  {np.median(train_r2_values):.4f}\")\n",
    "    \n",
    "    gap_values = [all_results[h]['cv_summary']['mean_overfitting_gap'] for h in successful]\n",
    "    print(f\"\\nMean Overfitting Gap: {np.mean(gap_values):.4f}\")\n",
    "    print(f\"Median Overfitting Gap: {np.median(gap_values):.4f}\")\n",
    "    \n",
    "    # Export to CSV\n",
    "    print(\"\\n\" + \"=\"*140)\n",
    "    print(\"5. EXPORTING RESULTS\")\n",
    "    print(\"=\"*140)\n",
    "    \n",
    "    # Hotel summary\n",
    "    summary_records = []\n",
    "    for hotel_id in successful:\n",
    "        result = all_results[hotel_id]\n",
    "        cv_sum = result['cv_summary']\n",
    "        \n",
    "        summary_records.append({\n",
    "            'hotel_id': hotel_id,\n",
    "            'n_observations': result['n_observations'],\n",
    "            'n_features': result['n_features'],\n",
    "            'cv_folds': result['cv_folds'],\n",
    "            'mean_train_r2': cv_sum['mean_train_r2'],\n",
    "            'mean_test_r2': cv_sum['mean_test_r2'],\n",
    "            'median_test_r2': cv_sum['median_test_r2'],\n",
    "            'std_test_r2': cv_sum['std_test_r2'],\n",
    "            'min_test_r2': cv_sum['min_test_r2'],\n",
    "            'max_test_r2': cv_sum['max_test_r2'],\n",
    "            'mean_overfitting_gap': cv_sum['mean_overfitting_gap'],\n",
    "            'mean_test_rmse': cv_sum['mean_test_rmse'],\n",
    "            'mean_test_mape': cv_sum['mean_test_mape']\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_records)\n",
    "    summary_df = summary_df.sort_values('mean_test_r2', ascending=False)\n",
    "    summary_df.to_csv(output_path / 'hotel_summary.csv', index=False)\n",
    "    \n",
    "    # Fold details\n",
    "    fold_records = []\n",
    "    for hotel_id in successful:\n",
    "        result = all_results[hotel_id]\n",
    "        for fold in result['fold_results']:\n",
    "            fold_records.append({\n",
    "                'hotel_id': hotel_id,\n",
    "                'fold': fold['fold'],\n",
    "                'train_size': fold['train_size'],\n",
    "                'test_size': fold['test_size'],\n",
    "                'train_r2': fold['train_r2'],\n",
    "                'train_rmse': fold['train_rmse'],\n",
    "                'train_mae': fold['train_mae'],\n",
    "                'train_mape': fold['train_mape'],\n",
    "                'test_r2': fold['test_r2'],\n",
    "                'test_rmse': fold['test_rmse'],\n",
    "                'test_mae': fold['test_mae'],\n",
    "                'test_mape': fold['test_mape'],\n",
    "                'overfitting_gap': fold['overfitting_gap']\n",
    "            })\n",
    "    \n",
    "    fold_df = pd.DataFrame(fold_records)\n",
    "    fold_df.to_csv(output_path / 'fold_details.csv', index=False)\n",
    "    \n",
    "    print(f\"\\n✓ Hotel summary: {output_path / 'hotel_summary.csv'}\")\n",
    "    print(f\"✓ Fold details: {output_path / 'fold_details.csv'}\")\n",
    "    print(f\"✓ Individual results: {output_path / '[hotel_id]_cv_results.json'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*140)\n",
    "print(\"PROCESSING COMPLETE\")\n",
    "print(\"=\"*140)\n",
    "print(f\"Successful: {len(successful)}/{len(hotel_list)} hotels\")\n",
    "print(f\"Results saved to: {output_path}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19b4cfe",
   "metadata": {},
   "source": [
    "## LR with past data - Iteration2 - Log transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ea198fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T06:37:08.269704Z",
     "start_time": "2025-10-21T06:37:01.616998Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================================================\n",
      "LINEAR + LOG + DETRENDING - NO OWN PRICE LAGS\n",
      "============================================================================================================================================\n",
      "\n",
      "Processing hotels...\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[44/44] Hotel_44...\n",
      "\n",
      "Successfully processed: 34/44 hotels\n",
      "\n",
      "============================================================================================================================================\n",
      "RESULTS\n",
      "============================================================================================================================================\n",
      "\n",
      "TOP 10 HOTELS\n",
      "============================================================================================================================================\n",
      "\n",
      "Hotel_35: Obs=393, Features=50, Folds=1\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.7960     0.7064       26.94       19.45    0.0895\n",
      "\n",
      "Summary: Mean Train R²=0.7960, Mean Test R²=0.7064, Gap=0.0895\n",
      "\n",
      "Hotel_27: Obs=425, Features=35, Folds=2\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.8160     0.6448       39.65       49.92    0.1712\n",
      "2      350          50              0.8507     0.7590       40.09       39.09    0.0916\n",
      "\n",
      "Summary: Mean Train R²=0.8333, Mean Test R²=0.7019, Gap=0.1314\n",
      "\n",
      "Hotel_06: Obs=373, Features=40, Folds=1\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.8170     0.6692       33.55       21.90    0.1478\n",
      "\n",
      "Summary: Mean Train R²=0.8170, Mean Test R²=0.6692, Gap=0.1478\n",
      "\n",
      "Hotel_40: Obs=441, Features=45, Folds=2\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.7364     0.5482       17.97       23.05    0.1881\n",
      "2      350          50              0.7737     0.7394       17.80       17.24    0.0344\n",
      "\n",
      "Summary: Mean Train R²=0.7550, Mean Test R²=0.6438, Gap=0.1112\n",
      "\n",
      "Hotel_41: Obs=425, Features=40, Folds=2\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.7840     0.4262       27.81       58.57    0.3578\n",
      "2      350          50              0.7771     0.7929       32.72       20.17   -0.0157\n",
      "\n",
      "Summary: Mean Train R²=0.7806, Mean Test R²=0.6095, Gap=0.1711\n",
      "\n",
      "Hotel_38: Obs=357, Features=45, Folds=1\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.8764     0.5295       38.32       47.41    0.3469\n",
      "\n",
      "Summary: Mean Train R²=0.8764, Mean Test R²=0.5295, Gap=0.3469\n",
      "\n",
      "Hotel_03: Obs=396, Features=55, Folds=1\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.8769     0.5293       58.21       53.51    0.3476\n",
      "\n",
      "Summary: Mean Train R²=0.8769, Mean Test R²=0.5293, Gap=0.3476\n",
      "\n",
      "Hotel_22: Obs=670, Features=55, Folds=7\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.6822     0.5623       17.01       12.43    0.1199\n",
      "2      350          50              0.6947     0.5556       16.36        9.80    0.1390\n",
      "3      400          50              0.6976     0.2359       15.59       11.77    0.4617\n",
      "4      450          50              0.7059     0.7234       14.91        7.08   -0.0174\n",
      "5      500          50              0.7152     0.6949       14.26        7.44    0.0203\n",
      "6      550          50              0.7192     0.2315       13.78       15.74    0.4878\n",
      "7      600          50              0.7141     0.5082       13.75       12.59    0.2059\n",
      "\n",
      "Summary: Mean Train R²=0.7041, Mean Test R²=0.5017, Gap=0.2025\n",
      "\n",
      "Hotel_02: Obs=425, Features=30, Folds=2\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.6673     0.4814        8.29        7.18    0.1859\n",
      "2      350          50              0.6738     0.4479        7.90       13.90    0.2259\n",
      "\n",
      "Summary: Mean Train R²=0.6706, Mean Test R²=0.4647, Gap=0.2059\n",
      "\n",
      "Hotel_05: Obs=675, Features=60, Folds=7\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.9125     0.6061       60.19       87.72    0.3064\n",
      "2      350          50              0.9053     0.8468       61.40       22.45    0.0584\n",
      "3      400          50              0.9113     0.1911       58.21       31.68    0.7202\n",
      "4      450          50              0.9105     0.1818       55.68       36.51    0.7288\n",
      "5      500          50              0.9079     0.8107       53.97       42.47    0.0971\n",
      "6      550          50              0.9064     0.4927       52.82       49.14    0.4138\n",
      "7      600          50              0.9293    -0.1766       52.25       53.33    1.1058\n",
      "\n",
      "Summary: Mean Train R²=0.9119, Mean Test R²=0.4218, Gap=0.4901\n",
      "\n",
      "============================================================================================================================================\n",
      "ALL HOTELS SUMMARY\n",
      "============================================================================================================================================\n",
      "Hotel        Features   Folds   Mean Train R²   Mean Test R²    Mean Gap    \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Hotel_35     50         1               0.7960         0.7064      0.0895\n",
      "Hotel_27     35         2               0.8333         0.7019      0.1314\n",
      "Hotel_06     40         1               0.8170         0.6692      0.1478\n",
      "Hotel_40     45         2               0.7550         0.6438      0.1112\n",
      "Hotel_41     40         2               0.7806         0.6095      0.1711\n",
      "Hotel_38     45         1               0.8764         0.5295      0.3469\n",
      "Hotel_03     55         1               0.8769         0.5293      0.3476\n",
      "Hotel_22     55         7               0.7041         0.5017      0.2025\n",
      "Hotel_02     30         2               0.6706         0.4647      0.2059\n",
      "Hotel_05     60         7               0.9119         0.4218      0.4901\n",
      "Hotel_37     35         1               0.6042         0.4161      0.1881\n",
      "Hotel_04     30         6               0.6087         0.3978      0.2108\n",
      "Hotel_12     55         2               0.4748         0.3930      0.0818\n",
      "Hotel_25     60         7               0.7683         0.3708      0.3975\n",
      "Hotel_33     40         7               0.4293         0.2940      0.1353\n",
      "Hotel_31     40         7               0.5712         0.2330      0.3382\n",
      "Hotel_18     40         1               0.4836         0.1980      0.2855\n",
      "Hotel_21     60         6               0.6096         0.1634      0.4463\n",
      "Hotel_07     50         7               0.7841         0.1411      0.6431\n",
      "Hotel_34     45         6               0.2933         0.1293      0.1639\n",
      "Hotel_32     35         5              -0.1473         0.0871     -0.2345\n",
      "Hotel_13     55         6               0.8608         0.0515      0.8093\n",
      "Hotel_10     55         6               0.7994         0.0014      0.7980\n",
      "Hotel_39     60         1               0.4796        -0.0412      0.5208\n",
      "Hotel_28     40         5               0.6588        -0.0891      0.7479\n",
      "Hotel_26     60         7               0.6986        -0.1660      0.8647\n",
      "Hotel_36     40         7               0.8823        -0.2217      1.1040\n",
      "Hotel_30     25         7               0.5311        -0.2351      0.7663\n",
      "Hotel_23     60         7               0.7209        -0.3153      1.0361\n",
      "Hotel_17     50         5               0.6536        -0.5816      1.2352\n",
      "Hotel_14     35         7               0.6668        -1.4053      2.0721\n",
      "Hotel_24     60         6               0.5851        -1.5353      2.1204\n",
      "Hotel_01     35         5               0.8935        -2.0831      2.9766\n",
      "Hotel_15     35         2               0.6015       -18.0882     18.6897\n",
      "\n",
      "STATISTICS\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Median Test R²: 0.1807\n",
      "Mean Test R²: -0.4738\n",
      "Excellent (R²>0.40): 11/34\n",
      "Poor (R²<0.15): 16/34\n",
      "\n",
      "Files saved to: ..\\data\\full-data\\linear_log_detrending_oos_cv_clean/\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "processed_data_path = Path('../data/full-data/processed')\n",
    "output_path = Path('../data/full-data/linear_log_detrending_oos_cv_clean')\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "mapping_df = pd.read_csv('../data/full-data/hotel_mapping.csv')\n",
    "hotel_list = mapping_df['masked_id'].tolist()\n",
    "\n",
    "MIN_TRAIN_DAYS = 300\n",
    "TEST_WINDOW = 50\n",
    "TREND_WINDOW = 30\n",
    "ALPHA = 100.0\n",
    "\n",
    "print(\"=\"*140)\n",
    "print(\"LINEAR + LOG + DETRENDING - NO OWN PRICE LAGS\")\n",
    "print(\"=\"*140)\n",
    "\n",
    "def detrend_series_log(series, window=30):\n",
    "    log_series = np.log1p(series.clip(lower=0))\n",
    "    trend = log_series.rolling(window=window, min_periods=1, center=False).mean()\n",
    "    detrended = log_series - trend\n",
    "    return detrended, trend\n",
    "\n",
    "def prepare_features(df):\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Competitor columns only\n",
    "    all_comp_cols = [col for col in df.columns \n",
    "                     if any(currency in col for currency in ['-USD', '-EUR', '-HKD', '-CNY'])]\n",
    "    \n",
    "    comp_base_cols = [col for col in all_comp_cols if '_lag_' not in col]\n",
    "    comp_lag_cols = [col for col in all_comp_cols if '_lag_' in col]\n",
    "    \n",
    "    # Log + Detrend competitors\n",
    "    for col in comp_base_cols:\n",
    "        if col in df_processed.columns:\n",
    "            detrended, _ = detrend_series_log(df_processed[col], window=TREND_WINDOW)\n",
    "            df_processed[f'{col}_log_detrended'] = detrended\n",
    "    \n",
    "    for col in comp_lag_cols:\n",
    "        if col in df_processed.columns:\n",
    "            detrended, _ = detrend_series_log(df_processed[col], window=TREND_WINDOW)\n",
    "            df_processed[f'{col}_log_detrended'] = detrended\n",
    "    \n",
    "    # Features\n",
    "    feature_cols = []\n",
    "    \n",
    "    log_detrended_comp_lags = [f'{col}_log_detrended' for col in comp_lag_cols \n",
    "                               if f'{col}_log_detrended' in df_processed.columns]\n",
    "    feature_cols.extend(log_detrended_comp_lags)\n",
    "    \n",
    "    temporal_cols = ['day_of_week', 'month', 'is_weekend', 'is_peak_season', \n",
    "                    'week_of_year', 'quarter', 'is_holiday_period', 'day_of_year',\n",
    "                    'sin_day_of_week', 'cos_day_of_week', 'sin_month', 'cos_month',\n",
    "                    'sin_day_of_year', 'cos_day_of_year']\n",
    "    temporal_cols = [col for col in temporal_cols if col in df_processed.columns]\n",
    "    feature_cols.extend(temporal_cols)\n",
    "    \n",
    "    # Target - log + detrend\n",
    "    y_original = df_processed['base_rate']\n",
    "    y_log_detrended, y_log_trend = detrend_series_log(y_original, window=TREND_WINDOW)\n",
    "    \n",
    "    X = df_processed[feature_cols]\n",
    "    \n",
    "    return X, y_log_detrended, y_log_trend, y_original, feature_cols\n",
    "\n",
    "def expanding_window_cv_splits(df, min_train_days, test_window):\n",
    "    n = len(df)\n",
    "    splits = []\n",
    "    train_end = min_train_days\n",
    "    \n",
    "    while train_end + test_window <= n:\n",
    "        splits.append({\n",
    "            'train_idx': list(range(0, train_end)),\n",
    "            'test_idx': list(range(train_end, min(train_end + test_window, n)))\n",
    "        })\n",
    "        train_end += test_window\n",
    "    \n",
    "    return splits\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    mask = y_true > 0\n",
    "    if mask.sum() > 0:\n",
    "        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    else:\n",
    "        mape = np.nan\n",
    "    \n",
    "    return {'r2': float(r2), 'rmse': float(rmse), 'mae': float(mae), 'mape': float(mape)}\n",
    "\n",
    "def train_and_evaluate(X_train, y_train_log_detrended, X_test, y_test_log_detrended,\n",
    "                       y_log_trend_train, y_log_trend_test,\n",
    "                       y_original_train, y_original_test, fold_num):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    model = Ridge(alpha=ALPHA, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train_log_detrended)\n",
    "    \n",
    "    # Train predictions\n",
    "    y_pred_train_log_detrended = model.predict(X_train_scaled)\n",
    "    y_pred_train_log = y_log_trend_train.values + y_pred_train_log_detrended\n",
    "    y_pred_train_absolute = np.expm1(y_pred_train_log)\n",
    "    train_metrics = calculate_metrics(y_original_train.values, y_pred_train_absolute)\n",
    "    \n",
    "    # Test predictions\n",
    "    y_pred_test_log_detrended = model.predict(X_test_scaled)\n",
    "    y_pred_test_log = y_log_trend_test.values + y_pred_test_log_detrended\n",
    "    y_pred_test_absolute = np.expm1(y_pred_test_log)\n",
    "    test_metrics = calculate_metrics(y_original_test.values, y_pred_test_absolute)\n",
    "    \n",
    "    return {\n",
    "        'fold': fold_num,\n",
    "        'train_size': len(X_train),\n",
    "        'test_size': len(X_test),\n",
    "        'train_r2': train_metrics['r2'],\n",
    "        'train_rmse': train_metrics['rmse'],\n",
    "        'train_mae': train_metrics['mae'],\n",
    "        'train_mape': train_metrics['mape'],\n",
    "        'test_r2': test_metrics['r2'],\n",
    "        'test_rmse': test_metrics['rmse'],\n",
    "        'test_mae': test_metrics['mae'],\n",
    "        'test_mape': test_metrics['mape'],\n",
    "        'overfitting_gap': train_metrics['r2'] - test_metrics['r2']\n",
    "    }\n",
    "\n",
    "def process_hotel(hotel_id):\n",
    "    try:\n",
    "        data_file = processed_data_path / f'{hotel_id}_lagged_dataset.csv'\n",
    "        \n",
    "        if not data_file.exists():\n",
    "            return {'hotel_id': hotel_id, 'status': 'missing_file'}\n",
    "        \n",
    "        df = pd.read_csv(data_file)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df.sort_values('date').reset_index(drop=True)\n",
    "        \n",
    "        if len(df) < MIN_TRAIN_DAYS + TEST_WINDOW:\n",
    "            return {'hotel_id': hotel_id, 'status': 'insufficient_data'}\n",
    "        \n",
    "        X_all, y_log_detrended, y_log_trend, y_original, feature_cols = prepare_features(df)\n",
    "        \n",
    "        if len(feature_cols) == 0:\n",
    "            return {'hotel_id': hotel_id, 'status': 'no_features'}\n",
    "        \n",
    "        cv_splits = expanding_window_cv_splits(df, MIN_TRAIN_DAYS, TEST_WINDOW)\n",
    "        \n",
    "        if len(cv_splits) == 0:\n",
    "            return {'hotel_id': hotel_id, 'status': 'insufficient_cv_data'}\n",
    "        \n",
    "        cv_results = []\n",
    "        for fold_idx, split in enumerate(cv_splits, 1):\n",
    "            X_train = X_all.iloc[split['train_idx']]\n",
    "            y_train = y_log_detrended.iloc[split['train_idx']]\n",
    "            X_test = X_all.iloc[split['test_idx']]\n",
    "            y_test = y_log_detrended.iloc[split['test_idx']]\n",
    "            y_log_trend_train = y_log_trend.iloc[split['train_idx']]\n",
    "            y_log_trend_test = y_log_trend.iloc[split['test_idx']]\n",
    "            y_original_train = y_original.iloc[split['train_idx']]\n",
    "            y_original_test = y_original.iloc[split['test_idx']]\n",
    "            \n",
    "            fold_result = train_and_evaluate(\n",
    "                X_train, y_train, X_test, y_test,\n",
    "                y_log_trend_train, y_log_trend_test,\n",
    "                y_original_train, y_original_test,\n",
    "                fold_idx\n",
    "            )\n",
    "            cv_results.append(fold_result)\n",
    "        \n",
    "        train_r2_scores = [r['train_r2'] for r in cv_results]\n",
    "        test_r2_scores = [r['test_r2'] for r in cv_results]\n",
    "        \n",
    "        cv_summary = {\n",
    "            'mean_train_r2': float(np.mean(train_r2_scores)),\n",
    "            'mean_test_r2': float(np.mean(test_r2_scores)),\n",
    "            'median_test_r2': float(np.median(test_r2_scores)),\n",
    "            'std_test_r2': float(np.std(test_r2_scores)),\n",
    "            'min_test_r2': float(np.min(test_r2_scores)),\n",
    "            'max_test_r2': float(np.max(test_r2_scores)),\n",
    "            'mean_overfitting_gap': float(np.mean([r['overfitting_gap'] for r in cv_results])),\n",
    "            'mean_test_rmse': float(np.mean([r['test_rmse'] for r in cv_results])),\n",
    "            'mean_test_mape': float(np.mean([r['test_mape'] for r in cv_results]))\n",
    "        }\n",
    "        \n",
    "        result = {\n",
    "            'hotel_id': hotel_id,\n",
    "            'status': 'success',\n",
    "            'n_features': len(feature_cols),\n",
    "            'n_observations': len(df),\n",
    "            'cv_folds': len(cv_results),\n",
    "            'fold_results': cv_results,\n",
    "            'cv_summary': cv_summary\n",
    "        }\n",
    "        \n",
    "        with open(output_path / f'{hotel_id}_cv_results.json', 'w') as f:\n",
    "            json.dump(result, f, indent=2)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {'hotel_id': hotel_id, 'status': 'error', 'error': str(e)}\n",
    "\n",
    "# Process all hotels\n",
    "print(\"\\nProcessing hotels...\")\n",
    "print(\"-\"*140)\n",
    "\n",
    "all_results = {}\n",
    "for idx, hotel_id in enumerate(hotel_list, 1):\n",
    "    print(f\"[{idx}/{len(hotel_list)}] {hotel_id}...\", end='\\r')\n",
    "    result = process_hotel(hotel_id)\n",
    "    all_results[hotel_id] = result\n",
    "\n",
    "successful = [h for h, r in all_results.items() if r.get('status') == 'success']\n",
    "print(f\"\\n\\nSuccessfully processed: {len(successful)}/{len(hotel_list)} hotels\")\n",
    "\n",
    "# Report\n",
    "print(\"\\n\" + \"=\"*140)\n",
    "print(\"RESULTS\")\n",
    "print(\"=\"*140)\n",
    "\n",
    "if len(successful) > 0:\n",
    "    successful_sorted = sorted(successful, \n",
    "                              key=lambda h: all_results[h]['cv_summary']['mean_test_r2'], \n",
    "                              reverse=True)\n",
    "    \n",
    "    print(\"\\nTOP 10 HOTELS\")\n",
    "    print(\"=\"*140)\n",
    "    \n",
    "    for hotel_id in successful_sorted[:10]:\n",
    "        result = all_results[hotel_id]\n",
    "        cv_sum = result['cv_summary']\n",
    "        \n",
    "        print(f\"\\n{hotel_id}: Obs={result['n_observations']}, Features={result['n_features']}, Folds={result['cv_folds']}\")\n",
    "        print(f\"{'Fold':<6} {'Train Size':<12} {'Test Size':<11} {'Train R²':<11} {'Test R²':<11} \"\n",
    "              f\"{'Train RMSE':<12} {'Test RMSE':<12} {'Gap':<10}\")\n",
    "        print(\"-\"*140)\n",
    "        \n",
    "        for fold in result['fold_results']:\n",
    "            print(f\"{fold['fold']:<6} {fold['train_size']:<12} {fold['test_size']:<11} \"\n",
    "                  f\"{fold['train_r2']:>10.4f} {fold['test_r2']:>10.4f} \"\n",
    "                  f\"{fold['train_rmse']:>11.2f} {fold['test_rmse']:>11.2f} \"\n",
    "                  f\"{fold['overfitting_gap']:>9.4f}\")\n",
    "        \n",
    "        print(f\"\\nSummary: Mean Train R²={cv_sum['mean_train_r2']:.4f}, \"\n",
    "              f\"Mean Test R²={cv_sum['mean_test_r2']:.4f}, Gap={cv_sum['mean_overfitting_gap']:.4f}\")\n",
    "    \n",
    "    # Summary table\n",
    "    print(\"\\n\" + \"=\"*140)\n",
    "    print(\"ALL HOTELS SUMMARY\")\n",
    "    print(\"=\"*140)\n",
    "    print(f\"{'Hotel':<12} {'Features':<10} {'Folds':<7} {'Mean Train R²':<15} \"\n",
    "          f\"{'Mean Test R²':<15} {'Mean Gap':<12}\")\n",
    "    print(\"-\"*140)\n",
    "    \n",
    "    for hotel_id in successful_sorted:\n",
    "        result = all_results[hotel_id]\n",
    "        cv_sum = result['cv_summary']\n",
    "        \n",
    "        print(f\"{hotel_id:<12} {result['n_features']:<10} {result['cv_folds']:<7} \"\n",
    "              f\"{cv_sum['mean_train_r2']:>14.4f} {cv_sum['mean_test_r2']:>14.4f} \"\n",
    "              f\"{cv_sum['mean_overfitting_gap']:>11.4f}\")\n",
    "    \n",
    "    # Stats\n",
    "    test_r2_values = [all_results[h]['cv_summary']['mean_test_r2'] for h in successful]\n",
    "    \n",
    "    print(\"\\nSTATISTICS\")\n",
    "    print(\"-\"*140)\n",
    "    print(f\"Median Test R²: {np.median(test_r2_values):.4f}\")\n",
    "    print(f\"Mean Test R²: {np.mean(test_r2_values):.4f}\")\n",
    "    \n",
    "    excellent = sum(1 for r2 in test_r2_values if r2 > 0.40)\n",
    "    poor = sum(1 for r2 in test_r2_values if r2 < 0.15)\n",
    "    print(f\"Excellent (R²>0.40): {excellent}/{len(successful)}\")\n",
    "    print(f\"Poor (R²<0.15): {poor}/{len(successful)}\")\n",
    "    \n",
    "    # Export\n",
    "    summary_records = []\n",
    "    fold_records = []\n",
    "    \n",
    "    for hotel_id in successful:\n",
    "        result = all_results[hotel_id]\n",
    "        cv_sum = result['cv_summary']\n",
    "        \n",
    "        summary_records.append({\n",
    "            'hotel_id': hotel_id,\n",
    "            'n_features': result['n_features'],\n",
    "            'cv_folds': result['cv_folds'],\n",
    "            'mean_train_r2': cv_sum['mean_train_r2'],\n",
    "            'mean_test_r2': cv_sum['mean_test_r2'],\n",
    "            'mean_overfitting_gap': cv_sum['mean_overfitting_gap']\n",
    "        })\n",
    "        \n",
    "        for fold in result['fold_results']:\n",
    "            fold_records.append({\n",
    "                'hotel_id': hotel_id,\n",
    "                'fold': fold['fold'],\n",
    "                'train_r2': fold['train_r2'],\n",
    "                'test_r2': fold['test_r2'],\n",
    "                'overfitting_gap': fold['overfitting_gap']\n",
    "            })\n",
    "    \n",
    "    pd.DataFrame(summary_records).to_csv(output_path / 'hotel_summary.csv', index=False)\n",
    "    pd.DataFrame(fold_records).to_csv(output_path / 'fold_details.csv', index=False)\n",
    "    \n",
    "    print(f\"\\nFiles saved to: {output_path}/\")\n",
    "\n",
    "print(\"\\nDONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c481c1",
   "metadata": {},
   "source": [
    "## LR with past data - Iteration3 - Quantile Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7a490c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T06:37:27.193532Z",
     "start_time": "2025-10-21T06:37:08.273709Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================================================\n",
      "LINEAR + QUANTILE + DETRENDING - NO OWN PRICE LAGS\n",
      "============================================================================================================================================\n",
      "\n",
      "Processing hotels...\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[44/44] Hotel_44...\n",
      "\n",
      "Successfully processed: 34/44 hotels\n",
      "\n",
      "============================================================================================================================================\n",
      "RESULTS\n",
      "============================================================================================================================================\n",
      "\n",
      "TOP 10 HOTELS\n",
      "============================================================================================================================================\n",
      "\n",
      "Hotel_35: Obs=393, Features=50, Folds=1\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.7796     0.6673       28.00       20.71    0.1123\n",
      "\n",
      "Summary: Mean Train R²=0.7796, Mean Test R²=0.6673, Gap=0.1123\n",
      "\n",
      "Hotel_40: Obs=441, Features=45, Folds=2\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.6996     0.5270       19.18       23.58    0.1726\n",
      "2      350          50              0.7461     0.6393       18.86       20.28    0.1067\n",
      "\n",
      "Summary: Mean Train R²=0.7228, Mean Test R²=0.5832, Gap=0.1396\n",
      "\n",
      "Hotel_27: Obs=425, Features=35, Folds=2\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.7989     0.5675       41.44       55.08    0.2314\n",
      "2      350          50              0.8307     0.5823       42.69       51.46    0.2484\n",
      "\n",
      "Summary: Mean Train R²=0.8148, Mean Test R²=0.5749, Gap=0.2399\n",
      "\n",
      "Hotel_41: Obs=425, Features=40, Folds=2\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.7578     0.3945       29.45       60.17    0.3633\n",
      "2      350          50              0.7561     0.7546       34.23       21.96    0.0015\n",
      "\n",
      "Summary: Mean Train R²=0.7569, Mean Test R²=0.5745, Gap=0.1824\n",
      "\n",
      "Hotel_06: Obs=373, Features=40, Folds=1\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.7952     0.5317       35.49       26.05    0.2635\n",
      "\n",
      "Summary: Mean Train R²=0.7952, Mean Test R²=0.5317, Gap=0.2635\n",
      "\n",
      "Hotel_02: Obs=425, Features=30, Folds=2\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.6177     0.5096        8.89        6.98    0.1081\n",
      "2      350          50              0.6212     0.3824        8.52       14.70    0.2387\n",
      "\n",
      "Summary: Mean Train R²=0.6195, Mean Test R²=0.4460, Gap=0.1734\n",
      "\n",
      "Hotel_37: Obs=393, Features=35, Folds=1\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.5660     0.3916       21.47       32.41    0.1744\n",
      "\n",
      "Summary: Mean Train R²=0.5660, Mean Test R²=0.3916, Gap=0.1744\n",
      "\n",
      "Hotel_38: Obs=357, Features=45, Folds=1\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.8381     0.3493       43.86       55.75    0.4888\n",
      "\n",
      "Summary: Mean Train R²=0.8381, Mean Test R²=0.3493, Gap=0.4888\n",
      "\n",
      "Hotel_04: Obs=620, Features=30, Folds=6\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.5997     0.2817       21.95       20.12    0.3180\n",
      "2      350          50              0.5932     0.1908       21.46       15.92    0.4024\n",
      "3      400          50              0.5987     0.0274       20.65        9.90    0.5713\n",
      "4      450          50              0.5935     0.3707       19.73       17.01    0.2229\n",
      "5      500          50              0.6010     0.6596       19.46       11.93   -0.0586\n",
      "6      550          50              0.6131     0.4219       18.76       27.71    0.1911\n",
      "\n",
      "Summary: Mean Train R²=0.5999, Mean Test R²=0.3253, Gap=0.2745\n",
      "\n",
      "Hotel_22: Obs=670, Features=55, Folds=7\n",
      "Fold   Train Size   Test Size   Train R²    Test R²     Train RMSE   Test RMSE    Gap       \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1      300          50              0.6721     0.3405       17.28       15.26    0.3316\n",
      "2      350          50              0.6795     0.6070       16.76        9.21    0.0725\n",
      "3      400          50              0.6822     0.2132       15.98       11.95    0.4691\n",
      "4      450          50              0.6874     0.4234       15.37       10.23    0.2639\n",
      "5      500          50              0.6943     0.6625       14.77        7.83    0.0318\n",
      "6      550          50              0.7005     0.2120       14.23       15.94    0.4885\n",
      "7      600          50              0.6974    -0.2779       14.14       20.30    0.9754\n",
      "\n",
      "Summary: Mean Train R²=0.6876, Mean Test R²=0.3115, Gap=0.3761\n",
      "\n",
      "============================================================================================================================================\n",
      "ALL HOTELS SUMMARY\n",
      "============================================================================================================================================\n",
      "Hotel        Features   Folds   Mean Train R²   Mean Test R²    Mean Gap    \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Hotel_35     50         1               0.7796         0.6673      0.1123\n",
      "Hotel_40     45         2               0.7228         0.5832      0.1396\n",
      "Hotel_27     35         2               0.8148         0.5749      0.2399\n",
      "Hotel_41     40         2               0.7569         0.5745      0.1824\n",
      "Hotel_06     40         1               0.7952         0.5317      0.2635\n",
      "Hotel_02     30         2               0.6195         0.4460      0.1734\n",
      "Hotel_37     35         1               0.5660         0.3916      0.1744\n",
      "Hotel_38     45         1               0.8381         0.3493      0.4888\n",
      "Hotel_04     30         6               0.5999         0.3253      0.2745\n",
      "Hotel_22     55         7               0.6876         0.3115      0.3761\n",
      "Hotel_18     40         1               0.4714         0.2801      0.1913\n",
      "Hotel_05     60         7               0.9138         0.2531      0.6607\n",
      "Hotel_12     55         2               0.5238         0.2463      0.2775\n",
      "Hotel_25     60         7               0.7696         0.1999      0.5697\n",
      "Hotel_07     50         7               0.7891         0.0419      0.7472\n",
      "Hotel_39     60         1               0.5565         0.0092      0.5473\n",
      "Hotel_33     40         7               0.4394        -0.0034      0.4428\n",
      "Hotel_36     40         7               0.8823        -0.0289      0.9112\n",
      "Hotel_21     60         6               0.5869        -0.0324      0.6193\n",
      "Hotel_34     45         6               0.7621        -0.0400      0.8021\n",
      "Hotel_32     35         5               0.5519        -0.0622      0.6141\n",
      "Hotel_03     55         1               0.8909        -0.0918      0.9827\n",
      "Hotel_15     35         2               0.9070        -0.1375      1.0446\n",
      "Hotel_10     55         6               0.8131        -0.1382      0.9513\n",
      "Hotel_26     60         7               0.6703        -0.2263      0.8966\n",
      "Hotel_13     55         6               0.8585        -0.2435      1.1020\n",
      "Hotel_31     40         7               0.5775        -0.3763      0.9538\n",
      "Hotel_23     60         7               0.7405        -0.4280      1.1685\n",
      "Hotel_17     50         5               0.6427        -0.8129      1.4556\n",
      "Hotel_30     25         7               0.5513        -0.9109      1.4622\n",
      "Hotel_24     60         6               0.5602        -2.0313      2.5915\n",
      "Hotel_28     40         5               0.6019        -2.1385      2.7404\n",
      "Hotel_14     35         7               0.6568        -2.7792      3.4360\n",
      "Hotel_01     35         5               0.8844        -4.2956      5.1799\n",
      "\n",
      "STATISTICS\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Median Test R²: -0.0162\n",
      "Mean Test R²: -0.2644\n",
      "Excellent (R²>0.40): 6/34\n",
      "Poor (R²<0.15): 20/34\n",
      "\n",
      "Files saved to: ..\\data\\full-data\\linear_quantile_detrending_oos_cv_clean/\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "processed_data_path = Path('../data/full-data/processed')\n",
    "output_path = Path('../data/full-data/linear_quantile_detrending_oos_cv_clean')\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "mapping_df = pd.read_csv('../data/full-data/hotel_mapping.csv')\n",
    "hotel_list = mapping_df['masked_id'].tolist()\n",
    "\n",
    "MIN_TRAIN_DAYS = 300\n",
    "TEST_WINDOW = 50\n",
    "TREND_WINDOW = 30\n",
    "ALPHA = 100.0\n",
    "\n",
    "print(\"=\"*140)\n",
    "print(\"LINEAR + QUANTILE + DETRENDING - NO OWN PRICE LAGS\")\n",
    "print(\"=\"*140)\n",
    "\n",
    "def detrend_series(series, window=30):\n",
    "    trend = series.rolling(window=window, min_periods=1, center=False).mean()\n",
    "    detrended = series - trend\n",
    "    return detrended, trend\n",
    "\n",
    "def prepare_features(df):\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Competitor columns only\n",
    "    all_comp_cols = [col for col in df.columns \n",
    "                     if any(currency in col for currency in ['-USD', '-EUR', '-HKD', '-CNY'])]\n",
    "    \n",
    "    comp_base_cols = [col for col in all_comp_cols if '_lag_' not in col]\n",
    "    comp_lag_cols = [col for col in all_comp_cols if '_lag_' in col]\n",
    "    \n",
    "    # Detrend competitors\n",
    "    for col in comp_base_cols:\n",
    "        if col in df_processed.columns:\n",
    "            detrended, _ = detrend_series(df_processed[col], window=TREND_WINDOW)\n",
    "            df_processed[f'{col}_detrended'] = detrended\n",
    "    \n",
    "    for col in comp_lag_cols:\n",
    "        if col in df_processed.columns:\n",
    "            detrended, _ = detrend_series(df_processed[col], window=TREND_WINDOW)\n",
    "            df_processed[f'{col}_detrended'] = detrended\n",
    "    \n",
    "    # Features\n",
    "    feature_cols = []\n",
    "    \n",
    "    detrended_comp_lags = [f'{col}_detrended' for col in comp_lag_cols \n",
    "                          if f'{col}_detrended' in df_processed.columns]\n",
    "    feature_cols.extend(detrended_comp_lags)\n",
    "    \n",
    "    temporal_cols = ['day_of_week', 'month', 'is_weekend', 'is_peak_season', \n",
    "                    'week_of_year', 'quarter', 'is_holiday_period', 'day_of_year',\n",
    "                    'sin_day_of_week', 'cos_day_of_week', 'sin_month', 'cos_month',\n",
    "                    'sin_day_of_year', 'cos_day_of_year']\n",
    "    temporal_cols = [col for col in temporal_cols if col in df_processed.columns]\n",
    "    feature_cols.extend(temporal_cols)\n",
    "    \n",
    "    # Target\n",
    "    y_original = df_processed['base_rate']\n",
    "    y_detrended, y_trend = detrend_series(y_original, window=TREND_WINDOW)\n",
    "    \n",
    "    X = df_processed[feature_cols]\n",
    "    \n",
    "    return X, y_detrended, y_trend, y_original, feature_cols\n",
    "\n",
    "def expanding_window_cv_splits(df, min_train_days, test_window):\n",
    "    n = len(df)\n",
    "    splits = []\n",
    "    train_end = min_train_days\n",
    "    \n",
    "    while train_end + test_window <= n:\n",
    "        splits.append({\n",
    "            'train_idx': list(range(0, train_end)),\n",
    "            'test_idx': list(range(train_end, min(train_end + test_window, n)))\n",
    "        })\n",
    "        train_end += test_window\n",
    "    \n",
    "    return splits\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    mask = y_true > 0\n",
    "    if mask.sum() > 0:\n",
    "        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    else:\n",
    "        mape = np.nan\n",
    "    \n",
    "    return {'r2': float(r2), 'rmse': float(rmse), 'mae': float(mae), 'mape': float(mape)}\n",
    "\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test, \n",
    "                       y_trend_train, y_trend_test, \n",
    "                       y_original_train, y_original_test, fold_num):\n",
    "    \n",
    "    # Quantile transform\n",
    "    quantile_transformer = QuantileTransformer(output_distribution='normal', random_state=42)\n",
    "    X_train_quantile = quantile_transformer.fit_transform(X_train)\n",
    "    X_test_quantile = quantile_transformer.transform(X_test)\n",
    "    \n",
    "    # Standardize after quantile\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_quantile)\n",
    "    X_test_scaled = scaler.transform(X_test_quantile)\n",
    "    \n",
    "    model = Ridge(alpha=ALPHA, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Train predictions\n",
    "    y_pred_train_detrended = model.predict(X_train_scaled)\n",
    "    y_pred_train_absolute = y_trend_train.values + y_pred_train_detrended\n",
    "    train_metrics = calculate_metrics(y_original_train.values, y_pred_train_absolute)\n",
    "    \n",
    "    # Test predictions\n",
    "    y_pred_test_detrended = model.predict(X_test_scaled)\n",
    "    y_pred_test_absolute = y_trend_test.values + y_pred_test_detrended\n",
    "    test_metrics = calculate_metrics(y_original_test.values, y_pred_test_absolute)\n",
    "    \n",
    "    return {\n",
    "        'fold': fold_num,\n",
    "        'train_size': len(X_train),\n",
    "        'test_size': len(X_test),\n",
    "        'train_r2': train_metrics['r2'],\n",
    "        'train_rmse': train_metrics['rmse'],\n",
    "        'train_mae': train_metrics['mae'],\n",
    "        'train_mape': train_metrics['mape'],\n",
    "        'test_r2': test_metrics['r2'],\n",
    "        'test_rmse': test_metrics['rmse'],\n",
    "        'test_mae': test_metrics['mae'],\n",
    "        'test_mape': test_metrics['mape'],\n",
    "        'overfitting_gap': train_metrics['r2'] - test_metrics['r2']\n",
    "    }\n",
    "\n",
    "def process_hotel(hotel_id):\n",
    "    try:\n",
    "        data_file = processed_data_path / f'{hotel_id}_lagged_dataset.csv'\n",
    "        \n",
    "        if not data_file.exists():\n",
    "            return {'hotel_id': hotel_id, 'status': 'missing_file'}\n",
    "        \n",
    "        df = pd.read_csv(data_file)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df.sort_values('date').reset_index(drop=True)\n",
    "        \n",
    "        if len(df) < MIN_TRAIN_DAYS + TEST_WINDOW:\n",
    "            return {'hotel_id': hotel_id, 'status': 'insufficient_data'}\n",
    "        \n",
    "        X_all, y_detrended, y_trend, y_original, feature_cols = prepare_features(df)\n",
    "        \n",
    "        if len(feature_cols) == 0:\n",
    "            return {'hotel_id': hotel_id, 'status': 'no_features'}\n",
    "        \n",
    "        cv_splits = expanding_window_cv_splits(df, MIN_TRAIN_DAYS, TEST_WINDOW)\n",
    "        \n",
    "        if len(cv_splits) == 0:\n",
    "            return {'hotel_id': hotel_id, 'status': 'insufficient_cv_data'}\n",
    "        \n",
    "        cv_results = []\n",
    "        for fold_idx, split in enumerate(cv_splits, 1):\n",
    "            X_train = X_all.iloc[split['train_idx']]\n",
    "            y_train = y_detrended.iloc[split['train_idx']]\n",
    "            X_test = X_all.iloc[split['test_idx']]\n",
    "            y_test = y_detrended.iloc[split['test_idx']]\n",
    "            y_trend_train = y_trend.iloc[split['train_idx']]\n",
    "            y_trend_test = y_trend.iloc[split['test_idx']]\n",
    "            y_original_train = y_original.iloc[split['train_idx']]\n",
    "            y_original_test = y_original.iloc[split['test_idx']]\n",
    "            \n",
    "            fold_result = train_and_evaluate(\n",
    "                X_train, y_train, X_test, y_test,\n",
    "                y_trend_train, y_trend_test,\n",
    "                y_original_train, y_original_test,\n",
    "                fold_idx\n",
    "            )\n",
    "            cv_results.append(fold_result)\n",
    "        \n",
    "        train_r2_scores = [r['train_r2'] for r in cv_results]\n",
    "        test_r2_scores = [r['test_r2'] for r in cv_results]\n",
    "        \n",
    "        cv_summary = {\n",
    "            'mean_train_r2': float(np.mean(train_r2_scores)),\n",
    "            'mean_test_r2': float(np.mean(test_r2_scores)),\n",
    "            'median_test_r2': float(np.median(test_r2_scores)),\n",
    "            'std_test_r2': float(np.std(test_r2_scores)),\n",
    "            'min_test_r2': float(np.min(test_r2_scores)),\n",
    "            'max_test_r2': float(np.max(test_r2_scores)),\n",
    "            'mean_overfitting_gap': float(np.mean([r['overfitting_gap'] for r in cv_results])),\n",
    "            'mean_test_rmse': float(np.mean([r['test_rmse'] for r in cv_results])),\n",
    "            'mean_test_mape': float(np.mean([r['test_mape'] for r in cv_results]))\n",
    "        }\n",
    "        \n",
    "        result = {\n",
    "            'hotel_id': hotel_id,\n",
    "            'status': 'success',\n",
    "            'n_features': len(feature_cols),\n",
    "            'n_observations': len(df),\n",
    "            'cv_folds': len(cv_results),\n",
    "            'fold_results': cv_results,\n",
    "            'cv_summary': cv_summary\n",
    "        }\n",
    "        \n",
    "        with open(output_path / f'{hotel_id}_cv_results.json', 'w') as f:\n",
    "            json.dump(result, f, indent=2)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {'hotel_id': hotel_id, 'status': 'error', 'error': str(e)}\n",
    "\n",
    "# Process all hotels\n",
    "print(\"\\nProcessing hotels...\")\n",
    "print(\"-\"*140)\n",
    "\n",
    "all_results = {}\n",
    "for idx, hotel_id in enumerate(hotel_list, 1):\n",
    "    print(f\"[{idx}/{len(hotel_list)}] {hotel_id}...\", end='\\r')\n",
    "    result = process_hotel(hotel_id)\n",
    "    all_results[hotel_id] = result\n",
    "\n",
    "successful = [h for h, r in all_results.items() if r.get('status') == 'success']\n",
    "print(f\"\\n\\nSuccessfully processed: {len(successful)}/{len(hotel_list)} hotels\")\n",
    "\n",
    "# Report\n",
    "print(\"\\n\" + \"=\"*140)\n",
    "print(\"RESULTS\")\n",
    "print(\"=\"*140)\n",
    "\n",
    "if len(successful) > 0:\n",
    "    successful_sorted = sorted(successful, \n",
    "                              key=lambda h: all_results[h]['cv_summary']['mean_test_r2'], \n",
    "                              reverse=True)\n",
    "    \n",
    "    print(\"\\nTOP 10 HOTELS\")\n",
    "    print(\"=\"*140)\n",
    "    \n",
    "    for hotel_id in successful_sorted[:10]:\n",
    "        result = all_results[hotel_id]\n",
    "        cv_sum = result['cv_summary']\n",
    "        \n",
    "        print(f\"\\n{hotel_id}: Obs={result['n_observations']}, Features={result['n_features']}, Folds={result['cv_folds']}\")\n",
    "        print(f\"{'Fold':<6} {'Train Size':<12} {'Test Size':<11} {'Train R²':<11} {'Test R²':<11} \"\n",
    "              f\"{'Train RMSE':<12} {'Test RMSE':<12} {'Gap':<10}\")\n",
    "        print(\"-\"*140)\n",
    "        \n",
    "        for fold in result['fold_results']:\n",
    "            print(f\"{fold['fold']:<6} {fold['train_size']:<12} {fold['test_size']:<11} \"\n",
    "                  f\"{fold['train_r2']:>10.4f} {fold['test_r2']:>10.4f} \"\n",
    "                  f\"{fold['train_rmse']:>11.2f} {fold['test_rmse']:>11.2f} \"\n",
    "                  f\"{fold['overfitting_gap']:>9.4f}\")\n",
    "        \n",
    "        print(f\"\\nSummary: Mean Train R²={cv_sum['mean_train_r2']:.4f}, \"\n",
    "              f\"Mean Test R²={cv_sum['mean_test_r2']:.4f}, Gap={cv_sum['mean_overfitting_gap']:.4f}\")\n",
    "    \n",
    "    # Summary table\n",
    "    print(\"\\n\" + \"=\"*140)\n",
    "    print(\"ALL HOTELS SUMMARY\")\n",
    "    print(\"=\"*140)\n",
    "    print(f\"{'Hotel':<12} {'Features':<10} {'Folds':<7} {'Mean Train R²':<15} \"\n",
    "          f\"{'Mean Test R²':<15} {'Mean Gap':<12}\")\n",
    "    print(\"-\"*140)\n",
    "    \n",
    "    for hotel_id in successful_sorted:\n",
    "        result = all_results[hotel_id]\n",
    "        cv_sum = result['cv_summary']\n",
    "        \n",
    "        print(f\"{hotel_id:<12} {result['n_features']:<10} {result['cv_folds']:<7} \"\n",
    "              f\"{cv_sum['mean_train_r2']:>14.4f} {cv_sum['mean_test_r2']:>14.4f} \"\n",
    "              f\"{cv_sum['mean_overfitting_gap']:>11.4f}\")\n",
    "    \n",
    "    # Stats\n",
    "    test_r2_values = [all_results[h]['cv_summary']['mean_test_r2'] for h in successful]\n",
    "    \n",
    "    print(\"\\nSTATISTICS\")\n",
    "    print(\"-\"*140)\n",
    "    print(f\"Median Test R²: {np.median(test_r2_values):.4f}\")\n",
    "    print(f\"Mean Test R²: {np.mean(test_r2_values):.4f}\")\n",
    "    \n",
    "    excellent = sum(1 for r2 in test_r2_values if r2 > 0.40)\n",
    "    poor = sum(1 for r2 in test_r2_values if r2 < 0.15)\n",
    "    print(f\"Excellent (R²>0.40): {excellent}/{len(successful)}\")\n",
    "    print(f\"Poor (R²<0.15): {poor}/{len(successful)}\")\n",
    "    \n",
    "    # Export\n",
    "    summary_records = []\n",
    "    fold_records = []\n",
    "    \n",
    "    for hotel_id in successful:\n",
    "        result = all_results[hotel_id]\n",
    "        cv_sum = result['cv_summary']\n",
    "        \n",
    "        summary_records.append({\n",
    "            'hotel_id': hotel_id,\n",
    "            'n_features': result['n_features'],\n",
    "            'cv_folds': result['cv_folds'],\n",
    "            'mean_train_r2': cv_sum['mean_train_r2'],\n",
    "            'mean_test_r2': cv_sum['mean_test_r2'],\n",
    "            'mean_overfitting_gap': cv_sum['mean_overfitting_gap']\n",
    "        })\n",
    "        \n",
    "        for fold in result['fold_results']:\n",
    "            fold_records.append({\n",
    "                'hotel_id': hotel_id,\n",
    "                'fold': fold['fold'],\n",
    "                'train_r2': fold['train_r2'],\n",
    "                'test_r2': fold['test_r2'],\n",
    "                'overfitting_gap': fold['overfitting_gap']\n",
    "            })\n",
    "    \n",
    "    pd.DataFrame(summary_records).to_csv(output_path / 'hotel_summary.csv', index=False)\n",
    "    pd.DataFrame(fold_records).to_csv(output_path / 'fold_details.csv', index=False)\n",
    "    \n",
    "    print(f\"\\nFiles saved to: {output_path}/\")\n",
    "\n",
    "print(\"\\nDONE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.319px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
