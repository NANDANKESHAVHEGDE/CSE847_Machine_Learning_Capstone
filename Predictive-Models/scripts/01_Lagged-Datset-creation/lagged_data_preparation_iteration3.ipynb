{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f2e338",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T23:48:55.482702Z",
     "start_time": "2025-10-07T23:48:54.516565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focal rows: 364\n",
      "Focal date range: 2025-09-16 00:00:00 to 2026-09-14 00:00:00\n",
      "Competitor matrix shape: (5, 364)\n",
      "Competitor date range: 2025-09-16 00:00:00 to 2026-09-14 00:00:00\n",
      "After merge: 364 rows\n",
      "Loaded dataset shape: (364, 11)\n",
      "Date range: 2025-09-16 00:00:00 to 2026-09-14 00:00:00\n",
      "\n",
      "Creating lagged features with lags: [1, 2, 3, 4, 5]\n",
      "Dataset shape after adding lags: (364, 46)\n",
      "Missing values after lagging: 105\n",
      "Final dataset shape after removing NaN: (359, 46)\n",
      "Data retention: 98.6%\n",
      "\n",
      "Dataset shape after adding temporal features: (359, 53)\n",
      "Temporal features added: ['sin_day_of_week', 'cos_day_of_week', 'sin_month', 'cos_month', 'sin_day_of_year', 'cos_day_of_year', 'is_weekend']\n",
      "\n",
      "Final dataset summary:\n",
      "  Observations: 359\n",
      "  Total features: 52\n",
      "  Lag features: 35\n",
      "  Temporal features: 7\n",
      "  Original features: 10\n",
      "  Data lost to lagging: 5 rows (1.4%)\n",
      "\n",
      "Dataset saved successfully!\n",
      "Files created:\n",
      "  - lagged_predictive_dataset_matrix_completion.csv\n",
      "  - lag_selection_metadata_matrix_completion.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MATRIX COMPLETION - LAGGED FEATURES CREATION\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_path = Path('../../../data/dataprocessed')\n",
    "\n",
    "# Load matrix completion results\n",
    "focal = pd.read_csv(data_path / 'focal_matrix_completion.csv')\n",
    "focal['date'] = pd.to_datetime(focal['date'])\n",
    "\n",
    "print(f\"Focal rows: {len(focal)}\")\n",
    "print(f\"Focal date range: {focal['date'].min()} to {focal['date'].max()}\")\n",
    "\n",
    "comp_matrix = pd.read_csv(data_path / 'competitor_price_matrix_matrix_completion.csv', index_col=0)\n",
    "comp_matrix.columns = pd.to_datetime(comp_matrix.columns)\n",
    "\n",
    "print(f\"Competitor matrix shape: {comp_matrix.shape}\")\n",
    "print(f\"Competitor date range: {comp_matrix.columns.min()} to {comp_matrix.columns.max()}\")\n",
    "\n",
    "# Merge focal with competitors in wide format\n",
    "merged_data = []\n",
    "for date in focal['date']:\n",
    "    row = {'date': date, 'base_rate': focal[focal['date'] == date]['base_rate'].values[0]}\n",
    "    if date in comp_matrix.columns:\n",
    "        for hotel in comp_matrix.index:\n",
    "            row[hotel] = comp_matrix.loc[hotel, date]\n",
    "    merged_data.append(row)\n",
    "\n",
    "df_final = pd.DataFrame(merged_data)\n",
    "\n",
    "print(f\"After merge: {len(df_final)} rows\")\n",
    "\n",
    "# Add temporal features that were in original data\n",
    "df_final['base_rate_normalized'] = df_final['base_rate']\n",
    "df_final['day_of_week'] = df_final['date'].dt.dayofweek\n",
    "df_final['month'] = df_final['date'].dt.month\n",
    "df_final['is_weekend'] = (df_final['day_of_week'] >= 5).astype(int)\n",
    "\n",
    "print(f\"Loaded dataset shape: {df_final.shape}\")\n",
    "print(f\"Date range: {df_final['date'].min()} to {df_final['date'].max()}\")\n",
    "\n",
    "# Identify price columns (everything except date and derived features)\n",
    "price_columns = [col for col in df_final.columns if col not in ['date', 'day_of_week', 'month', 'is_weekend']]\n",
    "\n",
    "# Create lagged features - EXACTLY like baseline\n",
    "final_lags = [1, 2, 3, 4, 5]\n",
    "\n",
    "def create_final_lagged_features(df, price_columns, selected_lags):\n",
    "    df_lagged = df.copy()\n",
    "    for col in price_columns:\n",
    "        for lag in selected_lags:\n",
    "            df_lagged[f'{col}_lag_{lag}'] = df_lagged[col].shift(lag)\n",
    "    return df_lagged\n",
    "\n",
    "print(f\"\\nCreating lagged features with lags: {final_lags}\")\n",
    "df_with_lags = create_final_lagged_features(df_final, price_columns, final_lags)\n",
    "\n",
    "print(f\"Dataset shape after adding lags: {df_with_lags.shape}\")\n",
    "print(f\"Missing values after lagging: {df_with_lags.isnull().sum().sum()}\")\n",
    "\n",
    "df_with_lags_clean = df_with_lags.dropna()\n",
    "print(f\"Final dataset shape after removing NaN: {df_with_lags_clean.shape}\")\n",
    "print(f\"Data retention: {len(df_with_lags_clean)/len(df_final)*100:.1f}%\")\n",
    "\n",
    "# Add temporal features - EXACTLY like baseline\n",
    "def add_temporal_features(df):\n",
    "    df_temporal = df.copy()\n",
    "    df_temporal['day_of_week'] = df_temporal['date'].dt.dayofweek\n",
    "    df_temporal['month'] = df_temporal['date'].dt.month\n",
    "    df_temporal['day_of_year'] = df_temporal['date'].dt.dayofyear\n",
    "    df_temporal['sin_day_of_week'] = np.sin(2 * np.pi * df_temporal['day_of_week'] / 7)\n",
    "    df_temporal['cos_day_of_week'] = np.cos(2 * np.pi * df_temporal['day_of_week'] / 7)\n",
    "    df_temporal['sin_month'] = np.sin(2 * np.pi * df_temporal['month'] / 12)\n",
    "    df_temporal['cos_month'] = np.cos(2 * np.pi * df_temporal['month'] / 12)\n",
    "    df_temporal['sin_day_of_year'] = np.sin(2 * np.pi * df_temporal['day_of_year'] / 365)\n",
    "    df_temporal['cos_day_of_year'] = np.cos(2 * np.pi * df_temporal['day_of_year'] / 365)\n",
    "    df_temporal['is_weekend'] = (df_temporal['day_of_week'] >= 5).astype(int)\n",
    "    return df_temporal\n",
    "\n",
    "df_with_temporal = add_temporal_features(df_with_lags_clean)\n",
    "print(f\"\\nDataset shape after adding temporal features: {df_with_temporal.shape}\")\n",
    "\n",
    "temporal_features = ['sin_day_of_week', 'cos_day_of_week', 'sin_month', 'cos_month', \n",
    "                    'sin_day_of_year', 'cos_day_of_year', 'is_weekend']\n",
    "print(f\"Temporal features added: {temporal_features}\")\n",
    "\n",
    "# Summary\n",
    "total_observations = len(df_with_temporal)\n",
    "total_features = len(df_with_temporal.columns) - 1\n",
    "lag_features = len([col for col in df_with_temporal.columns if 'lag' in col])\n",
    "temporal_features_count = len(temporal_features)\n",
    "\n",
    "print(f\"\\nFinal dataset summary:\")\n",
    "print(f\"  Observations: {total_observations}\")\n",
    "print(f\"  Total features: {total_features}\")\n",
    "print(f\"  Lag features: {lag_features}\")\n",
    "print(f\"  Temporal features: {temporal_features_count}\")\n",
    "print(f\"  Original features: {total_features - lag_features - temporal_features_count}\")\n",
    "print(f\"  Data lost to lagging: {len(df_final) - total_observations} rows ({(len(df_final) - total_observations)/len(df_final)*100:.1f}%)\")\n",
    "\n",
    "# Save\n",
    "df_with_temporal.to_csv(data_path / 'lagged_predictive_dataset_matrix_completion.csv', index=False)\n",
    "\n",
    "lag_metadata = {\n",
    "    'imputation_method': 'matrix_completion',\n",
    "    'selected_lags': final_lags,\n",
    "    'lag_selection_method': 'matched_baseline',\n",
    "    'focal_column': 'base_rate',\n",
    "    'total_lag_features': lag_features,\n",
    "    'temporal_features': temporal_features,\n",
    "    'final_observations': total_observations,\n",
    "    'data_retention_pct': round(len(df_with_temporal)/len(df_final)*100, 1),\n",
    "    'feature_summary': {\n",
    "        'total_features': total_features,\n",
    "        'lag_features': lag_features,\n",
    "        'temporal_features': temporal_features_count,\n",
    "        'original_features': total_features - lag_features - temporal_features_count\n",
    "    },\n",
    "    'data_quality': {\n",
    "        'imputation_correlation_preserved': 99.0,\n",
    "        'imputation_method': 'Matrix Completion (IterativeImputer)'\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(data_path / 'lag_selection_metadata_matrix_completion.json', 'w') as f:\n",
    "    json.dump(lag_metadata, f, indent=2)\n",
    "\n",
    "print(\"\\nDataset saved successfully!\")\n",
    "print(\"Files created:\")\n",
    "print(\"  - lagged_predictive_dataset_matrix_completion.csv\")\n",
    "print(\"  - lag_selection_metadata_matrix_completion.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
