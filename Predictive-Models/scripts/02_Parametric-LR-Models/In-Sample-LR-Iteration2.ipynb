{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7221f577",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T05:08:40.803655Z",
     "start_time": "2025-09-29T05:08:37.255166Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664284c2",
   "metadata": {},
   "source": [
    "## Iteration 2 Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f66e712",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T05:08:40.820290Z",
     "start_time": "2025-09-29T05:08:40.807090Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from pathlib import Path\n",
    "# import json\n",
    "# from sklearn.metrics import r2_score, mean_squared_error\n",
    "# import statsmodels.api as sm\n",
    "# from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "# from statsmodels.stats.stattools import durbin_watson\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# print(\"=\"*80)\n",
    "# print(\"LINEAR VS LOG-LOG REGRESSION MODELS\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# # Load data\n",
    "# data_path = Path().cwd().parent.parent / 'data' / 'dataprocessed'\n",
    "# df = pd.read_csv(data_path / 'lagged_predictive_dataset.csv')\n",
    "\n",
    "# with open(data_path / 'lag_selection_metadata.json', 'r') as f:\n",
    "#     metadata = json.load(f)\n",
    "\n",
    "# df['date'] = pd.to_datetime(df['date'])\n",
    "# df = df.sort_values('date').reset_index(drop=True)\n",
    "# y = df[metadata['focal_column']]\n",
    "\n",
    "# print(f\"\\nDataset: {len(df)} observations\")\n",
    "# print(f\"Target: {metadata['focal_column']}\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # FEATURE PREPARATION\n",
    "# # ============================================================================\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"FEATURE PREPARATION\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# # 1. ALL FOCAL LAGS\n",
    "# focal_lags = [f'base_rate_lag_{i}' for i in range(1, 6)]\n",
    "# print(f\"\\n1. Focal lags: {len(focal_lags)} features\")\n",
    "\n",
    "# # 2. ALL COMPETITORS (remove only severe multicollinearity > 0.90)\n",
    "# competitor_cols = [col for col in df.columns if 'booking-us' in col and 'lag' in col]\n",
    "# comp_corr_with_target = df[competitor_cols].corrwith(y).abs().sort_values(ascending=False)\n",
    "\n",
    "# all_competitors = []\n",
    "# for comp in comp_corr_with_target.index:\n",
    "#     is_redundant = False\n",
    "#     for existing in all_competitors:\n",
    "#         if abs(df[comp].corr(df[existing])) > 0.90:\n",
    "#             is_redundant = True\n",
    "#             break\n",
    "#     if not is_redundant:\n",
    "#         all_competitors.append(comp)\n",
    "\n",
    "# print(f\"2. All competitors (correlation < 0.90): {len(all_competitors)} features\")\n",
    "\n",
    "# # 3. WEEK OF YEAR\n",
    "# df['week_of_year'] = df['date'].dt.isocalendar().week.astype(float)\n",
    "# df['sin_week'] = np.sin(2 * np.pi * df['week_of_year'] / 52).astype(float)\n",
    "# df['cos_week'] = np.cos(2 * np.pi * df['week_of_year'] / 52).astype(float)\n",
    "# print(f\"3. Week of year: 2 features (sin_week, cos_week)\")\n",
    "\n",
    "# # 4. TEMPORAL FEATURES\n",
    "# temporal_features = ['sin_day_of_week', 'cos_day_of_week', 'sin_month', 'cos_month', \n",
    "#                      'sin_day_of_year', 'cos_day_of_year', 'is_weekend']\n",
    "# print(f\"4. Temporal features: {len(temporal_features)} features\")\n",
    "\n",
    "# # 5. HOLIDAY FLAG\n",
    "# if 'is_holiday' not in df.columns:\n",
    "#     df['is_holiday'] = 0\n",
    "#     df.loc[df['date'].dt.month.isin([12, 1]), 'is_holiday'] = 1\n",
    "#     df.loc[(df['date'].dt.month == 7) & (df['date'].dt.day <= 7), 'is_holiday'] = 1\n",
    "#     df.loc[(df['date'].dt.month == 11) & (df['date'].dt.day >= 22), 'is_holiday'] = 1\n",
    "# print(f\"5. Holiday flag: 1 feature\")\n",
    "\n",
    "# # 6. PEAK SEASON (Summer + Winter holidays)\n",
    "# df['is_peak_season'] = ((df['date'].dt.month.isin([6, 7, 8])) | \n",
    "#                         (df['date'].dt.month.isin([12, 1]))).astype(int)\n",
    "# print(f\"6. Peak season flag: 1 feature\")\n",
    "\n",
    "# # 7. SUMMER TRAVEL SEASON (June-August specifically)\n",
    "# df['is_summer'] = df['date'].dt.month.isin([6, 7, 8]).astype(int)\n",
    "# print(f\"7. Summer season flag: 1 feature\")\n",
    "\n",
    "# print(f\"\\nTotal features available: {len(focal_lags) + len(all_competitors) + 2 + len(temporal_features) + 3}\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # LINEAR MODELS\n",
    "# # ============================================================================\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"LINEAR MODELS\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# def estimate_linear_model(feature_list, model_name, description):\n",
    "#     \"\"\"Estimate OLS model with robust standard errors\"\"\"\n",
    "#     valid_features = [f for f in feature_list if f in df.columns]\n",
    "#     X = df[valid_features]\n",
    "#     X_const = sm.add_constant(X)\n",
    "    \n",
    "#     model = sm.OLS(y, X_const).fit(cov_type='HC1')\n",
    "#     y_pred = model.predict(X_const)\n",
    "#     residuals = y - y_pred\n",
    "    \n",
    "#     n, k = len(y), len(valid_features)\n",
    "#     r2 = r2_score(y, y_pred)\n",
    "#     adj_r2 = 1 - (1 - r2) * (n - 1) / (n - k - 1)\n",
    "#     rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    \n",
    "#     sig_count = sum(model.pvalues[1:] < 0.05)\n",
    "#     dw = durbin_watson(residuals)\n",
    "#     bp_stat, bp_pval = het_breuschpagan(residuals, X_const)[0:2]\n",
    "    \n",
    "#     return {\n",
    "#         'name': model_name,\n",
    "#         'description': description,\n",
    "#         'type': 'Linear',\n",
    "#         'model': model,\n",
    "#         'n_features': k,\n",
    "#         'r2': r2,\n",
    "#         'adj_r2': adj_r2,\n",
    "#         'rmse': rmse,\n",
    "#         'aic': model.aic,\n",
    "#         'bic': model.bic,\n",
    "#         'sig_features': sig_count,\n",
    "#         'sig_ratio': sig_count / k if k > 0 else 0,\n",
    "#         'durbin_watson': dw,\n",
    "#         'heteroscedasticity_pval': bp_pval,\n",
    "#         'condition_number': np.linalg.cond(X_const)\n",
    "#     }\n",
    "\n",
    "# models = {}\n",
    "\n",
    "# # Linear Model 1: All focal + all competitors + week + holiday + season\n",
    "# linear_full = focal_lags + all_competitors + ['sin_week', 'cos_week', 'is_holiday', 'is_peak_season', 'is_summer']\n",
    "# print(f\"\\nEstimating Linear Model 1: Full specification\")\n",
    "# models['Linear_1_Full'] = estimate_linear_model(linear_full, 'Linear_1_Full', \n",
    "#                                                  'All focal + all competitors + seasonal')\n",
    "\n",
    "# # Linear Model 2: Add temporal features\n",
    "# linear_with_temporal = linear_full + temporal_features\n",
    "# print(f\"Estimating Linear Model 2: With temporal features\")\n",
    "# models['Linear_2_Temporal'] = estimate_linear_model(linear_with_temporal, 'Linear_2_Temporal', \n",
    "#                                                      'Model 1 + temporal features')\n",
    "\n",
    "# # Linear Model 3: Simplified - top competitors only\n",
    "# top_10_competitors = all_competitors[:10]\n",
    "# linear_simplified = focal_lags + top_10_competitors + ['sin_week', 'cos_week', 'is_holiday', 'is_peak_season', 'is_summer']\n",
    "# print(f\"Estimating Linear Model 3: Top 10 competitors\")\n",
    "# models['Linear_3_Top10'] = estimate_linear_model(linear_simplified, 'Linear_3_Top10', \n",
    "#                                                   'All focal + top 10 competitors + seasonal')\n",
    "\n",
    "# # ============================================================================\n",
    "# # LOG-LOG MODELS\n",
    "# # ============================================================================\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"LOG-LOG MODELS\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# # Create log transformations\n",
    "# df['log_base_rate'] = np.log(y)\n",
    "\n",
    "# # Log focal lags\n",
    "# log_focal_lags = []\n",
    "# for lag in focal_lags:\n",
    "#     if lag in df.columns and (df[lag] > 0).all():\n",
    "#         log_name = f'log_{lag}'\n",
    "#         df[log_name] = np.log(df[lag])\n",
    "#         log_focal_lags.append(log_name)\n",
    "\n",
    "# # Log competitors\n",
    "# log_competitors = []\n",
    "# for comp in all_competitors:\n",
    "#     if comp in df.columns and (df[comp] > 0).all():\n",
    "#         log_name = f'log_{comp}'\n",
    "#         df[log_name] = np.log(df[comp])\n",
    "#         log_competitors.append(log_name)\n",
    "\n",
    "# print(f\"\\nLog-transformed focal lags: {len(log_focal_lags)}\")\n",
    "# print(f\"Log-transformed competitors: {len(log_competitors)}\")\n",
    "\n",
    "# def estimate_loglog_model(feature_list, model_name, description):\n",
    "#     \"\"\"Estimate log-log model\"\"\"\n",
    "#     valid_features = [f for f in feature_list if f in df.columns]\n",
    "#     X = df[valid_features]\n",
    "#     X_const = sm.add_constant(X)\n",
    "    \n",
    "#     # Estimate in log space\n",
    "#     model = sm.OLS(df['log_base_rate'], X_const).fit(cov_type='HC1')\n",
    "    \n",
    "#     # Back-transform predictions to original scale\n",
    "#     y_pred_log = model.predict(X_const)\n",
    "#     y_pred = np.exp(y_pred_log)\n",
    "#     residuals = y - y_pred\n",
    "    \n",
    "#     n, k = len(y), len(valid_features)\n",
    "#     r2 = r2_score(y, y_pred)\n",
    "#     adj_r2 = 1 - (1 - r2) * (n - 1) / (n - k - 1)\n",
    "#     rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    \n",
    "#     sig_count = sum(model.pvalues[1:] < 0.05)\n",
    "#     dw = durbin_watson(residuals)\n",
    "#     bp_stat, bp_pval = het_breuschpagan(residuals, X_const)[0:2]\n",
    "    \n",
    "#     return {\n",
    "#         'name': model_name,\n",
    "#         'description': description,\n",
    "#         'type': 'Log-Log',\n",
    "#         'model': model,\n",
    "#         'n_features': k,\n",
    "#         'r2': r2,\n",
    "#         'adj_r2': adj_r2,\n",
    "#         'rmse': rmse,\n",
    "#         'aic': model.aic,\n",
    "#         'bic': model.bic,\n",
    "#         'sig_features': sig_count,\n",
    "#         'sig_ratio': sig_count / k if k > 0 else 0,\n",
    "#         'durbin_watson': dw,\n",
    "#         'heteroscedasticity_pval': bp_pval,\n",
    "#         'condition_number': np.linalg.cond(X_const)\n",
    "#     }\n",
    "\n",
    "# # Log-Log Model 1: All log features + seasonal indicators\n",
    "# loglog_full = log_focal_lags + log_competitors + ['sin_week', 'cos_week', 'is_holiday', 'is_peak_season', 'is_summer']\n",
    "# print(f\"\\nEstimating Log-Log Model 1: Full specification\")\n",
    "# models['LogLog_1_Full'] = estimate_loglog_model(loglog_full, 'LogLog_1_Full', \n",
    "#                                                  'All log(focal) + log(competitors) + seasonal')\n",
    "\n",
    "# # Log-Log Model 2: Add temporal\n",
    "# loglog_with_temporal = loglog_full + temporal_features\n",
    "# print(f\"Estimating Log-Log Model 2: With temporal features\")\n",
    "# models['LogLog_2_Temporal'] = estimate_loglog_model(loglog_with_temporal, 'LogLog_2_Temporal', \n",
    "#                                                      'Model 1 + temporal features')\n",
    "\n",
    "# # Log-Log Model 3: Top 10 competitors\n",
    "# log_top_10_competitors = log_competitors[:10]\n",
    "# loglog_simplified = log_focal_lags + log_top_10_competitors + ['sin_week', 'cos_week', 'is_holiday', 'is_peak_season', 'is_summer']\n",
    "# print(f\"Estimating Log-Log Model 3: Top 10 competitors\")\n",
    "# models['LogLog_3_Top10'] = estimate_loglog_model(loglog_simplified, 'LogLog_3_Top10', \n",
    "#                                                   'All log(focal) + log(top 10 competitors) + seasonal')\n",
    "\n",
    "# # ============================================================================\n",
    "# # MODEL COMPARISON\n",
    "# # ============================================================================\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"MODEL COMPARISON\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# comparison = []\n",
    "# for name, result in models.items():\n",
    "#     comparison.append({\n",
    "#         'Model': result['name'],\n",
    "#         'Type': result['type'],\n",
    "#         'Description': result['description'],\n",
    "#         'Features': result['n_features'],\n",
    "#         'R²': result['r2'],\n",
    "#         'Adj_R²': result['adj_r2'],\n",
    "#         'RMSE': result['rmse'],\n",
    "#         'AIC': result['aic'],\n",
    "#         'BIC': result['bic'],\n",
    "#         'Sig_Feat': result['sig_features'],\n",
    "#         'Sig_%': result['sig_ratio'],\n",
    "#         'DW': result['durbin_watson'],\n",
    "#         'Het_p': result['heteroscedasticity_pval'],\n",
    "#         'Cond_No': result['condition_number']\n",
    "#     })\n",
    "\n",
    "# comp_df = pd.DataFrame(comparison).sort_values('Adj_R²', ascending=False)\n",
    "# print(\"\\n\" + comp_df.to_string(index=False))\n",
    "\n",
    "# # ============================================================================\n",
    "# # BEST MODEL ANALYSIS\n",
    "# # ============================================================================\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"BEST MODEL ANALYSIS\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# best_model_name = comp_df.iloc[0]['Model']\n",
    "# best_result = models[best_model_name]\n",
    "\n",
    "# print(f\"\\nBest Model: {best_result['name']}\")\n",
    "# print(f\"Type: {best_result['type']}\")\n",
    "# print(f\"Description: {best_result['description']}\")\n",
    "# print(f\"\\nPerformance:\")\n",
    "# print(f\"  R²: {best_result['r2']:.4f}\")\n",
    "# print(f\"  Adjusted R²: {best_result['adj_r2']:.4f}\")\n",
    "# print(f\"  RMSE: ${best_result['rmse']:.2f}\")\n",
    "# print(f\"  AIC: {best_result['aic']:.1f}\")\n",
    "# print(f\"  BIC: {best_result['bic']:.1f}\")\n",
    "# print(f\"\\nDiagnostics:\")\n",
    "# print(f\"  Features: {best_result['n_features']}\")\n",
    "# print(f\"  Significant: {best_result['sig_features']} ({best_result['sig_ratio']:.1%})\")\n",
    "# print(f\"  Durbin-Watson: {best_result['durbin_watson']:.3f}\")\n",
    "# print(f\"  Heteroscedasticity p-value: {best_result['heteroscedasticity_pval']:.4f}\")\n",
    "# print(f\"  Condition number: {best_result['condition_number']:.1f}\")\n",
    "\n",
    "# if best_result['type'] == 'Log-Log':\n",
    "#     print(\"\\nNOTE: Coefficients represent elasticities\")\n",
    "#     print(\"      1% increase in X → β% increase in base_rate\")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"FULL REGRESSION SUMMARY\")\n",
    "# print(\"=\"*80)\n",
    "# print(best_result['model'].summary())\n",
    "\n",
    "# # ============================================================================\n",
    "# # TOP FEATURES\n",
    "# # ============================================================================\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"TOP 20 FEATURES BY COEFFICIENT MAGNITUDE\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# coefs = best_result['model'].params[1:]\n",
    "# pvals = best_result['model'].pvalues[1:]\n",
    "\n",
    "# feature_importance = pd.DataFrame({\n",
    "#     'Feature': coefs.index,\n",
    "#     'Coefficient': coefs.values,\n",
    "#     'P_Value': pvals.values,\n",
    "#     'Significant': pvals.values < 0.05,\n",
    "#     'Abs_Coef': np.abs(coefs.values)\n",
    "# }).sort_values('Abs_Coef', ascending=False)\n",
    "\n",
    "# print(feature_importance.head(20).to_string(index=False))\n",
    "\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(f\"ANALYSIS COMPLETE - Best Adj R²: {best_result['adj_r2']:.4f}\")\n",
    "# print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d7a2df",
   "metadata": {},
   "source": [
    "## Iteration 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b5c3112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T05:08:50.685626Z",
     "start_time": "2025-09-29T05:08:40.823696Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "REGULARIZED REGRESSION MODELS\n",
      "================================================================================\n",
      "\n",
      "Dataset: 360 observations\n",
      "Target: base_rate\n",
      "\n",
      "================================================================================\n",
      "FEATURE PREPARATION\n",
      "================================================================================\n",
      "\n",
      "Total features: 33\n",
      "  Focal lags: 5\n",
      "  Competitors: 16\n",
      "  Temporal: 9\n",
      "  Seasonal: 3\n",
      "\n",
      "================================================================================\n",
      "DATA PREPARATION FOR REGULARIZATION\n",
      "================================================================================\n",
      "\n",
      "Features standardized (mean=0, std=1)\n",
      "Original X shape: (360, 33)\n",
      "\n",
      "================================================================================\n",
      "RIDGE REGRESSION\n",
      "================================================================================\n",
      "\n",
      "Ridge Results:\n",
      "  Optimal alpha: 57.2237\n",
      "  R²: 0.6610\n",
      "  Adjusted R²: 0.6267\n",
      "  RMSE: $19.83\n",
      "  Non-zero coefficients: 33/33\n",
      "  CV score: 0.0096\n",
      "\n",
      "================================================================================\n",
      "LASSO REGRESSION\n",
      "================================================================================\n",
      "\n",
      "Lasso Results:\n",
      "  Optimal alpha: 0.0850\n",
      "  R²: 0.6787\n",
      "  Adjusted R²: 0.6461\n",
      "  RMSE: $19.31\n",
      "  Non-zero coefficients: 27/33\n",
      "  Features automatically selected: 27\n",
      "\n",
      "Top 15 Lasso-selected features:\n",
      "booking-us-courtyard-by-marriott-maui-kahului-airport-USD_lag_1    15.030575\n",
      "base_rate_lag_1                                                    10.082170\n",
      "booking-us-kohea-kai-resort-maui-USD_lag_3                          7.413877\n",
      "cos_week                                                            7.054884\n",
      "base_rate_lag_5                                                     6.529433\n",
      "booking-us-courtyard-by-marriott-maui-kahului-airport-USD_lag_4    -5.808431\n",
      "is_peak_season                                                      4.609646\n",
      "booking-us-aqua-pacific-monarch-USD_lag_2                           4.492136\n",
      "base_rate_lag_2                                                     3.970798\n",
      "booking-us-ohana-waikiki-malia-USD_lag_3                           -3.691074\n",
      "booking-us-kohea-kai-resort-maui-USD_lag_2                         -3.351218\n",
      "booking-us-aqua-pacific-monarch-USD_lag_1                          -3.135488\n",
      "booking-us-aqua-pacific-monarch-USD_lag_5                           2.540619\n",
      "booking-us-ohana-waikiki-malia-USD_lag_1                           -2.243100\n",
      "cos_day_of_week                                                    -2.179717\n",
      "\n",
      "================================================================================\n",
      "ELASTIC NET\n",
      "================================================================================\n",
      "\n",
      "ElasticNet Results:\n",
      "  Optimal alpha: 0.0720\n",
      "  Optimal l1_ratio: 0.9900\n",
      "  R²: 0.6794\n",
      "  Adjusted R²: 0.6469\n",
      "  RMSE: $19.29\n",
      "  Non-zero coefficients: 30/33\n",
      "\n",
      "================================================================================\n",
      "OLS WITH LASSO-SELECTED FEATURES\n",
      "================================================================================\n",
      "\n",
      "OLS Re-estimation Results:\n",
      "  Features: 27\n",
      "  R²: 0.6794\n",
      "  Adjusted R²: 0.6533\n",
      "  RMSE: $19.29\n",
      "  AIC: 3208.4\n",
      "  BIC: 3317.2\n",
      "  Significant features: 7/27 (25.9%)\n",
      "  Durbin-Watson: 1.928\n",
      "  Heteroscedasticity p-value: 0.0000\n",
      "  Condition number: 36160.0\n",
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON\n",
      "================================================================================\n",
      "\n",
      "          Model     Method  Features       R²   Adj_R²      RMSE  Sig_Features  Sig_Ratio      Cond_No                      Note\n",
      "Lasso_OLS_Refit        OLS        27 0.679416 0.653344 19.286574             7   0.259259 36159.992632     OLS on Lasso features\n",
      "Linear_Full_OLS        OLS        33 0.682400 0.650300 19.200000             7   0.212000 85694.000000       Original full model\n",
      "     ElasticNet ElasticNet        30 0.679352 0.646893 19.288499            30   1.000000          NaN             L1_ratio=0.99\n",
      "          Lasso      Lasso        27 0.678654 0.646125 19.309471            27   1.000000          NaN Auto-selected 27 features\n",
      "          Ridge      Ridge        33 0.661041 0.626729 19.831588            33   1.000000          NaN             Alpha=57.2237\n",
      "\n",
      "================================================================================\n",
      "BEST REGULARIZED MODEL ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Best Model: Lasso_OLS_Refit\n",
      "Method: OLS\n",
      "Features: 27\n",
      "R²: 0.6794\n",
      "Adjusted R²: 0.6533\n",
      "RMSE: $19.29\n",
      "\n",
      "================================================================================\n",
      "FULL REGRESSION SUMMARY (LASSO-SELECTED FEATURES)\n",
      "================================================================================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              base_rate   R-squared:                       0.679\n",
      "Model:                            OLS   Adj. R-squared:                  0.653\n",
      "Method:                 Least Squares   F-statistic:                     69.93\n",
      "Date:                Mon, 29 Sep 2025   Prob (F-statistic):          7.42e-120\n",
      "Time:                        01:08:50   Log-Likelihood:                -1576.2\n",
      "No. Observations:                 360   AIC:                             3208.\n",
      "Df Residuals:                     332   BIC:                             3317.\n",
      "Df Model:                          27                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "===================================================================================================================================\n",
      "                                                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "const                                                             -61.6519     30.900     -1.995      0.046    -122.216      -1.088\n",
      "booking-us-courtyard-by-marriott-maui-kahului-airport-USD_lag_1     0.3188      0.057      5.643      0.000       0.208       0.430\n",
      "base_rate_lag_1                                                     0.2916      0.090      3.233      0.001       0.115       0.468\n",
      "booking-us-kohea-kai-resort-maui-USD_lag_3                          0.3788      0.146      2.587      0.010       0.092       0.666\n",
      "cos_week                                                            9.6529      5.254      1.837      0.066      -0.645      19.951\n",
      "base_rate_lag_5                                                     0.2035      0.077      2.634      0.008       0.052       0.355\n",
      "booking-us-courtyard-by-marriott-maui-kahului-airport-USD_lag_4    -0.1275      0.062     -2.061      0.039      -0.249      -0.006\n",
      "is_peak_season                                                      9.6905      3.758      2.579      0.010       2.326      17.055\n",
      "booking-us-aqua-pacific-monarch-USD_lag_2                           0.1963      0.118      1.664      0.096      -0.035       0.427\n",
      "base_rate_lag_2                                                     0.1177      0.081      1.455      0.146      -0.041       0.276\n",
      "booking-us-ohana-waikiki-malia-USD_lag_3                           -0.0899      0.069     -1.303      0.192      -0.225       0.045\n",
      "booking-us-kohea-kai-resort-maui-USD_lag_2                         -0.2063      0.181     -1.143      0.253      -0.560       0.148\n",
      "booking-us-aqua-pacific-monarch-USD_lag_1                          -0.1443      0.095     -1.512      0.131      -0.331       0.043\n",
      "booking-us-aqua-pacific-monarch-USD_lag_5                           0.1094      0.089      1.230      0.219      -0.065       0.284\n",
      "booking-us-ohana-waikiki-malia-USD_lag_1                           -0.0639      0.074     -0.862      0.389      -0.209       0.081\n",
      "cos_day_of_week                                                    -3.3549      1.644     -2.040      0.041      -6.578      -0.132\n",
      "sin_month                                                          -2.7886      9.365     -0.298      0.766     -21.144      15.567\n",
      "booking-us-castle-kamaole-sands-USD_lag_4                           0.0478      0.037      1.294      0.196      -0.025       0.120\n",
      "booking-us-aqua-pacific-monarch-USD_lag_3                           0.0724      0.136      0.532      0.595      -0.194       0.339\n",
      "sin_day_of_week                                                    -1.9757      2.364     -0.836      0.403      -6.610       2.658\n",
      "booking-us-kohea-kai-resort-maui-USD_lag_4                         -0.0767      0.095     -0.809      0.418      -0.262       0.109\n",
      "booking-us-kohea-kai-resort-maui-USD_lag_1                          0.0568      0.141      0.403      0.687      -0.219       0.333\n",
      "base_rate_lag_4                                                     0.0127      0.085      0.149      0.881      -0.155       0.180\n",
      "is_holiday                                                          0.9983      3.794      0.263      0.792      -6.438       8.434\n",
      "sin_week                                                           -0.7831      9.529     -0.082      0.935     -19.459      17.893\n",
      "booking-us-aqua-pacific-monarch-USD_lag_4                          -0.0356      0.098     -0.362      0.718      -0.229       0.157\n",
      "base_rate_lag_3                                                     0.0038      0.085      0.045      0.964      -0.163       0.171\n",
      "is_weekend                                                          0.5144      3.910      0.132      0.895      -7.150       8.178\n",
      "==============================================================================\n",
      "Omnibus:                       75.244   Durbin-Watson:                   1.928\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              424.324\n",
      "Skew:                           0.727   Prob(JB):                     7.23e-93\n",
      "Kurtosis:                       8.116   Cond. No.                     3.62e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n",
      "[2] The condition number is large, 3.62e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "================================================================================\n",
      "FEATURE IMPORTANCE\n",
      "================================================================================\n",
      "                                                        Feature  Coefficient      P_Value  Significant  Abs_Coef\n",
      "                                                 is_peak_season     9.690549 9.911931e-03         True  9.690549\n",
      "                                                       cos_week     9.652929 6.618619e-02        False  9.652929\n",
      "                                                cos_day_of_week    -3.354920 4.133558e-02         True  3.354920\n",
      "                                                      sin_month    -2.788607 7.658826e-01        False  2.788607\n",
      "                                                sin_day_of_week    -1.975681 4.033580e-01        False  1.975681\n",
      "                                                     is_holiday     0.998272 7.924611e-01        False  0.998272\n",
      "                                                       sin_week    -0.783066 9.345035e-01        False  0.783066\n",
      "                                                     is_weekend     0.514435 8.953329e-01        False  0.514435\n",
      "                     booking-us-kohea-kai-resort-maui-USD_lag_3     0.378808 9.684342e-03         True  0.378808\n",
      "booking-us-courtyard-by-marriott-maui-kahului-airport-USD_lag_1     0.318828 1.671860e-08         True  0.318828\n",
      "                                                base_rate_lag_1     0.291613 1.226113e-03         True  0.291613\n",
      "                     booking-us-kohea-kai-resort-maui-USD_lag_2    -0.206303 2.531309e-01        False  0.206303\n",
      "                                                base_rate_lag_5     0.203533 8.430453e-03         True  0.203533\n",
      "                      booking-us-aqua-pacific-monarch-USD_lag_2     0.196271 9.617248e-02        False  0.196271\n",
      "                      booking-us-aqua-pacific-monarch-USD_lag_1    -0.144298 1.306213e-01        False  0.144298\n",
      "booking-us-courtyard-by-marriott-maui-kahului-airport-USD_lag_4    -0.127505 3.929673e-02         True  0.127505\n",
      "                                                base_rate_lag_2     0.117713 1.456409e-01        False  0.117713\n",
      "                      booking-us-aqua-pacific-monarch-USD_lag_5     0.109387 2.186911e-01        False  0.109387\n",
      "                       booking-us-ohana-waikiki-malia-USD_lag_3    -0.089860 1.924955e-01        False  0.089860\n",
      "                     booking-us-kohea-kai-resort-maui-USD_lag_4    -0.076660 4.184152e-01        False  0.076660\n",
      "                      booking-us-aqua-pacific-monarch-USD_lag_3     0.072392 5.947963e-01        False  0.072392\n",
      "                       booking-us-ohana-waikiki-malia-USD_lag_1    -0.063942 3.885827e-01        False  0.063942\n",
      "                     booking-us-kohea-kai-resort-maui-USD_lag_1     0.056766 6.868137e-01        False  0.056766\n",
      "                      booking-us-castle-kamaole-sands-USD_lag_4     0.047821 1.957700e-01        False  0.047821\n",
      "                      booking-us-aqua-pacific-monarch-USD_lag_4    -0.035610 7.176043e-01        False  0.035610\n",
      "                                                base_rate_lag_4     0.012747 8.814759e-01        False  0.012747\n",
      "                                                base_rate_lag_3     0.003842 9.640658e-01        False  0.003842\n",
      "\n",
      "================================================================================\n",
      "REGULARIZATION COMPLETE\n",
      "Best Adj R²: 0.6533\n",
      "Multicollinearity handled by regularization\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"REGULARIZED REGRESSION MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load data\n",
    "data_path = Path().cwd().parent.parent / 'data' / 'dataprocessed'\n",
    "df = pd.read_csv(data_path / 'lagged_predictive_dataset.csv')\n",
    "\n",
    "with open(data_path / 'lag_selection_metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "y = df[metadata['focal_column']]\n",
    "\n",
    "print(f\"\\nDataset: {len(df)} observations\")\n",
    "print(f\"Target: {metadata['focal_column']}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FEATURE PREPARATION (Same as Linear_2_Temporal)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE PREPARATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Focal lags\n",
    "focal_lags = [f'base_rate_lag_{i}' for i in range(1, 6)]\n",
    "\n",
    "# All competitors (correlation < 0.90)\n",
    "competitor_cols = [col for col in df.columns if 'booking-us' in col and 'lag' in col]\n",
    "comp_corr_with_target = df[competitor_cols].corrwith(y).abs().sort_values(ascending=False)\n",
    "\n",
    "all_competitors = []\n",
    "for comp in comp_corr_with_target.index:\n",
    "    is_redundant = False\n",
    "    for existing in all_competitors:\n",
    "        if abs(df[comp].corr(df[existing])) > 0.90:\n",
    "            is_redundant = True\n",
    "            break\n",
    "    if not is_redundant:\n",
    "        all_competitors.append(comp)\n",
    "\n",
    "# Week of year\n",
    "df['week_of_year'] = df['date'].dt.isocalendar().week.astype(float)\n",
    "df['sin_week'] = np.sin(2 * np.pi * df['week_of_year'] / 52).astype(float)\n",
    "df['cos_week'] = np.cos(2 * np.pi * df['week_of_year'] / 52).astype(float)\n",
    "\n",
    "# Temporal features\n",
    "temporal_features = ['sin_day_of_week', 'cos_day_of_week', 'sin_month', 'cos_month', \n",
    "                     'sin_day_of_year', 'cos_day_of_year', 'is_weekend']\n",
    "\n",
    "# Seasonal indicators\n",
    "if 'is_holiday' not in df.columns:\n",
    "    df['is_holiday'] = 0\n",
    "    df.loc[df['date'].dt.month.isin([12, 1]), 'is_holiday'] = 1\n",
    "    df.loc[(df['date'].dt.month == 7) & (df['date'].dt.day <= 7), 'is_holiday'] = 1\n",
    "    df.loc[(df['date'].dt.month == 11) & (df['date'].dt.day >= 22), 'is_holiday'] = 1\n",
    "\n",
    "df['is_peak_season'] = ((df['date'].dt.month.isin([6, 7, 8])) | \n",
    "                        (df['date'].dt.month.isin([12, 1]))).astype(int)\n",
    "df['is_summer'] = df['date'].dt.month.isin([6, 7, 8]).astype(int)\n",
    "\n",
    "# Compile all features\n",
    "all_features = (focal_lags + all_competitors + ['sin_week', 'cos_week'] + \n",
    "                ['is_holiday', 'is_peak_season', 'is_summer'] + temporal_features)\n",
    "all_features = [f for f in all_features if f in df.columns]\n",
    "\n",
    "print(f\"\\nTotal features: {len(all_features)}\")\n",
    "print(f\"  Focal lags: {len(focal_lags)}\")\n",
    "print(f\"  Competitors: {len(all_competitors)}\")\n",
    "print(f\"  Temporal: {len(temporal_features) + 2}\")  # +2 for week\n",
    "print(f\"  Seasonal: 3\")\n",
    "\n",
    "# ============================================================================\n",
    "# PREPARE DATA FOR REGULARIZATION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA PREPARATION FOR REGULARIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "X = df[all_features].copy()\n",
    "\n",
    "# Standardize features (required for regularization)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=all_features, index=X.index)\n",
    "\n",
    "print(f\"\\nFeatures standardized (mean=0, std=1)\")\n",
    "print(f\"Original X shape: {X.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# RIDGE REGRESSION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RIDGE REGRESSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Ridge with cross-validation to find optimal alpha\n",
    "alphas_ridge = np.logspace(-2, 4, 100)\n",
    "ridge_cv = RidgeCV(alphas=alphas_ridge, cv=5, scoring='r2')\n",
    "ridge_cv.fit(X_scaled, y)\n",
    "\n",
    "y_pred_ridge = ridge_cv.predict(X_scaled)\n",
    "r2_ridge = r2_score(y, y_pred_ridge)\n",
    "n, k = len(y), len(all_features)\n",
    "adj_r2_ridge = 1 - (1 - r2_ridge) * (n - 1) / (n - k - 1)\n",
    "rmse_ridge = np.sqrt(mean_squared_error(y, y_pred_ridge))\n",
    "\n",
    "# Get coefficients (transform back to original scale)\n",
    "ridge_coefs = pd.Series(ridge_cv.coef_, index=all_features)\n",
    "non_zero_ridge = (ridge_coefs.abs() > 1e-10).sum()\n",
    "\n",
    "print(f\"\\nRidge Results:\")\n",
    "print(f\"  Optimal alpha: {ridge_cv.alpha_:.4f}\")\n",
    "print(f\"  R²: {r2_ridge:.4f}\")\n",
    "print(f\"  Adjusted R²: {adj_r2_ridge:.4f}\")\n",
    "print(f\"  RMSE: ${rmse_ridge:.2f}\")\n",
    "print(f\"  Non-zero coefficients: {non_zero_ridge}/{len(all_features)}\")\n",
    "print(f\"  CV score: {ridge_cv.best_score_:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# LASSO REGRESSION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LASSO REGRESSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Lasso with cross-validation\n",
    "alphas_lasso = np.logspace(-4, 1, 100)\n",
    "lasso_cv = LassoCV(alphas=alphas_lasso, cv=5, max_iter=10000, random_state=42)\n",
    "lasso_cv.fit(X_scaled, y)\n",
    "\n",
    "y_pred_lasso = lasso_cv.predict(X_scaled)\n",
    "r2_lasso = r2_score(y, y_pred_lasso)\n",
    "adj_r2_lasso = 1 - (1 - r2_lasso) * (n - 1) / (n - k - 1)\n",
    "rmse_lasso = np.sqrt(mean_squared_error(y, y_pred_lasso))\n",
    "\n",
    "lasso_coefs = pd.Series(lasso_cv.coef_, index=all_features)\n",
    "non_zero_lasso = (lasso_coefs != 0).sum()\n",
    "selected_features_lasso = lasso_coefs[lasso_coefs != 0].sort_values(key=abs, ascending=False)\n",
    "\n",
    "print(f\"\\nLasso Results:\")\n",
    "print(f\"  Optimal alpha: {lasso_cv.alpha_:.4f}\")\n",
    "print(f\"  R²: {r2_lasso:.4f}\")\n",
    "print(f\"  Adjusted R²: {adj_r2_lasso:.4f}\")\n",
    "print(f\"  RMSE: ${rmse_lasso:.2f}\")\n",
    "print(f\"  Non-zero coefficients: {non_zero_lasso}/{len(all_features)}\")\n",
    "print(f\"  Features automatically selected: {non_zero_lasso}\")\n",
    "\n",
    "print(f\"\\nTop 15 Lasso-selected features:\")\n",
    "print(selected_features_lasso.head(15).to_string())\n",
    "\n",
    "# ============================================================================\n",
    "# ELASTIC NET\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ELASTIC NET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ElasticNet with cross-validation\n",
    "alphas_enet = np.logspace(-4, 1, 50)\n",
    "l1_ratios = [.1, .3, .5, .7, .9, .95, .99]\n",
    "enet_cv = ElasticNetCV(alphas=alphas_enet, l1_ratio=l1_ratios, cv=5, \n",
    "                       max_iter=10000, random_state=42)\n",
    "enet_cv.fit(X_scaled, y)\n",
    "\n",
    "y_pred_enet = enet_cv.predict(X_scaled)\n",
    "r2_enet = r2_score(y, y_pred_enet)\n",
    "adj_r2_enet = 1 - (1 - r2_enet) * (n - 1) / (n - k - 1)\n",
    "rmse_enet = np.sqrt(mean_squared_error(y, y_pred_enet))\n",
    "\n",
    "enet_coefs = pd.Series(enet_cv.coef_, index=all_features)\n",
    "non_zero_enet = (enet_coefs != 0).sum()\n",
    "selected_features_enet = enet_coefs[enet_coefs != 0].sort_values(key=abs, ascending=False)\n",
    "\n",
    "print(f\"\\nElasticNet Results:\")\n",
    "print(f\"  Optimal alpha: {enet_cv.alpha_:.4f}\")\n",
    "print(f\"  Optimal l1_ratio: {enet_cv.l1_ratio_:.4f}\")\n",
    "print(f\"  R²: {r2_enet:.4f}\")\n",
    "print(f\"  Adjusted R²: {adj_r2_enet:.4f}\")\n",
    "print(f\"  RMSE: ${rmse_enet:.2f}\")\n",
    "print(f\"  Non-zero coefficients: {non_zero_enet}/{len(all_features)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# RE-ESTIMATE LASSO-SELECTED FEATURES WITH OLS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OLS WITH LASSO-SELECTED FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if non_zero_lasso >= 3:\n",
    "    lasso_selected_list = selected_features_lasso.index.tolist()\n",
    "    X_lasso_selected = df[lasso_selected_list]\n",
    "    X_lasso_const = sm.add_constant(X_lasso_selected)\n",
    "    \n",
    "    model_lasso_ols = sm.OLS(y, X_lasso_const).fit(cov_type='HC1')\n",
    "    y_pred_lasso_ols = model_lasso_ols.predict(X_lasso_const)\n",
    "    residuals_lasso_ols = y - y_pred_lasso_ols\n",
    "    \n",
    "    r2_lasso_ols = r2_score(y, y_pred_lasso_ols)\n",
    "    k_lasso = len(lasso_selected_list)\n",
    "    adj_r2_lasso_ols = 1 - (1 - r2_lasso_ols) * (n - 1) / (n - k_lasso - 1)\n",
    "    rmse_lasso_ols = np.sqrt(mean_squared_error(y, y_pred_lasso_ols))\n",
    "    \n",
    "    sig_count_lasso = sum(model_lasso_ols.pvalues[1:] < 0.05)\n",
    "    dw_lasso = durbin_watson(residuals_lasso_ols)\n",
    "    bp_stat, bp_pval = het_breuschpagan(residuals_lasso_ols, X_lasso_const)[0:2]\n",
    "    \n",
    "    print(f\"\\nOLS Re-estimation Results:\")\n",
    "    print(f\"  Features: {k_lasso}\")\n",
    "    print(f\"  R²: {r2_lasso_ols:.4f}\")\n",
    "    print(f\"  Adjusted R²: {adj_r2_lasso_ols:.4f}\")\n",
    "    print(f\"  RMSE: ${rmse_lasso_ols:.2f}\")\n",
    "    print(f\"  AIC: {model_lasso_ols.aic:.1f}\")\n",
    "    print(f\"  BIC: {model_lasso_ols.bic:.1f}\")\n",
    "    print(f\"  Significant features: {sig_count_lasso}/{k_lasso} ({sig_count_lasso/k_lasso:.1%})\")\n",
    "    print(f\"  Durbin-Watson: {dw_lasso:.3f}\")\n",
    "    print(f\"  Heteroscedasticity p-value: {bp_pval:.4f}\")\n",
    "    print(f\"  Condition number: {np.linalg.cond(X_lasso_const):.1f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL COMPARISON\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        'Model': 'Linear_Full_OLS',\n",
    "        'Method': 'OLS',\n",
    "        'Features': len(all_features),\n",
    "        'R²': 0.6824,\n",
    "        'Adj_R²': 0.6503,\n",
    "        'RMSE': 19.20,\n",
    "        'Sig_Features': 7,\n",
    "        'Sig_Ratio': 0.212,\n",
    "        'Cond_No': 85694,\n",
    "        'Note': 'Original full model'\n",
    "    },\n",
    "    {\n",
    "        'Model': 'Ridge',\n",
    "        'Method': 'Ridge',\n",
    "        'Features': len(all_features),\n",
    "        'R²': r2_ridge,\n",
    "        'Adj_R²': adj_r2_ridge,\n",
    "        'RMSE': rmse_ridge,\n",
    "        'Sig_Features': non_zero_ridge,\n",
    "        'Sig_Ratio': non_zero_ridge/len(all_features),\n",
    "        'Cond_No': None,\n",
    "        'Note': f'Alpha={ridge_cv.alpha_:.4f}'\n",
    "    },\n",
    "    {\n",
    "        'Model': 'Lasso',\n",
    "        'Method': 'Lasso',\n",
    "        'Features': non_zero_lasso,\n",
    "        'R²': r2_lasso,\n",
    "        'Adj_R²': adj_r2_lasso,\n",
    "        'RMSE': rmse_lasso,\n",
    "        'Sig_Features': non_zero_lasso,\n",
    "        'Sig_Ratio': 1.0,\n",
    "        'Cond_No': None,\n",
    "        'Note': f'Auto-selected {non_zero_lasso} features'\n",
    "    },\n",
    "    {\n",
    "        'Model': 'ElasticNet',\n",
    "        'Method': 'ElasticNet',\n",
    "        'Features': non_zero_enet,\n",
    "        'R²': r2_enet,\n",
    "        'Adj_R²': adj_r2_enet,\n",
    "        'RMSE': rmse_enet,\n",
    "        'Sig_Features': non_zero_enet,\n",
    "        'Sig_Ratio': 1.0,\n",
    "        'Cond_No': None,\n",
    "        'Note': f'L1_ratio={enet_cv.l1_ratio_:.2f}'\n",
    "    }\n",
    "])\n",
    "\n",
    "if non_zero_lasso >= 3:\n",
    "    comparison = pd.concat([comparison, pd.DataFrame([{\n",
    "        'Model': 'Lasso_OLS_Refit',\n",
    "        'Method': 'OLS',\n",
    "        'Features': k_lasso,\n",
    "        'R²': r2_lasso_ols,\n",
    "        'Adj_R²': adj_r2_lasso_ols,\n",
    "        'RMSE': rmse_lasso_ols,\n",
    "        'Sig_Features': sig_count_lasso,\n",
    "        'Sig_Ratio': sig_count_lasso/k_lasso,\n",
    "        'Cond_No': np.linalg.cond(X_lasso_const),\n",
    "        'Note': 'OLS on Lasso features'\n",
    "    }])], ignore_index=True)\n",
    "\n",
    "comparison = comparison.sort_values('Adj_R²', ascending=False)\n",
    "print(\"\\n\" + comparison.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# BEST MODEL ANALYSIS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST REGULARIZED MODEL ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_idx = comparison.iloc[0]\n",
    "best_name = best_idx['Model']\n",
    "\n",
    "print(f\"\\nBest Model: {best_name}\")\n",
    "print(f\"Method: {best_idx['Method']}\")\n",
    "print(f\"Features: {int(best_idx['Features'])}\")\n",
    "print(f\"R²: {best_idx['R²']:.4f}\")\n",
    "print(f\"Adjusted R²: {best_idx['Adj_R²']:.4f}\")\n",
    "print(f\"RMSE: ${best_idx['RMSE']:.2f}\")\n",
    "\n",
    "# Show detailed coefficients for best model\n",
    "if best_name == 'Lasso_OLS_Refit' and non_zero_lasso >= 3:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FULL REGRESSION SUMMARY (LASSO-SELECTED FEATURES)\")\n",
    "    print(\"=\"*80)\n",
    "    print(model_lasso_ols.summary())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FEATURE IMPORTANCE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    coefs = model_lasso_ols.params[1:]\n",
    "    pvals = model_lasso_ols.pvalues[1:]\n",
    "    \n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': coefs.index,\n",
    "        'Coefficient': coefs.values,\n",
    "        'P_Value': pvals.values,\n",
    "        'Significant': pvals.values < 0.05,\n",
    "        'Abs_Coef': np.abs(coefs.values)\n",
    "    }).sort_values('Abs_Coef', ascending=False)\n",
    "    \n",
    "    print(feature_importance.to_string(index=False))\n",
    "\n",
    "elif best_name == 'Lasso':\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LASSO COEFFICIENTS (STANDARDIZED)\")\n",
    "    print(\"=\"*80)\n",
    "    print(selected_features_lasso.to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"REGULARIZATION COMPLETE\")\n",
    "print(f\"Best Adj R²: {comparison.iloc[0]['Adj_R²']:.4f}\")\n",
    "print(f\"Multicollinearity handled by regularization\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279.319px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
